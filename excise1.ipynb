{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate 200 points randomly\n",
    "# x_data = np.linspace(-0.5,-.5,200) 1D\n",
    "x_data = np.linspace(-0.5,0.5,200)[:,np.newaxis]  # change t 2D x_data.shape = [200,1]\n",
    "noise = np.random.normal(0,0.02,x_data.shape)\n",
    "y_data = np.square(x_data) + noise\n",
    "\n",
    "#  define two placeholder\n",
    "x = tf.placeholder(tf.float32,[None,1])\n",
    "y = tf.placeholder(tf.float32,[None,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input x,pass the NN,output y_hat,y_hat is the predict,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noiiKDyoYFEVRFB9UMCiKoig+/D98s6jv/G6G1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20451d86cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20451e31fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the hidden layer,has 10 neurals\n",
    "W1 = tf.Variable(tf.random_normal([1,10]))\n",
    "b1 = tf.Variable(tf.zeros([1,10]))\n",
    "z1 = tf.add(tf.matmul(x,W1),b1)\n",
    "a1 = tf.nn.tanh(z1)\n",
    "\n",
    "# define output layer\n",
    "W2 = tf.Variable(tf.random_normal([10,1]))\n",
    "b2 = tf.Variable(tf.zeros([1,1]))\n",
    "z2 = tf.add(tf.matmul(a1,W2),b2)\n",
    "y_hat = tf.nn.tanh(z2)\n",
    "\n",
    "# define loss\n",
    "loss = tf.reduce_mean(tf.square(y-y_hat))\n",
    "# using GD\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for _ in range(2000):\n",
    "        sess.run(train_step,feed_dict = {x:x_data,y:y_data})\n",
    "        \n",
    "    # get the predict\n",
    "    y_predict = sess.run(y_hat,feed_dict = {x:x_data})\n",
    "    plt.figure()\n",
    "    plt.scatter(x_data,y_data)\n",
    "    plt.plot(x_data,y_predict,'r-',lw = 3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "two_node = tf.constant(2)\n",
    "print(two_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_3:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_two_node = tf.constant(2)\n",
    "two_node = tf.constant(2)\n",
    "tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Tensor(\"Const_4:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "two_node = tf.constant(2)\n",
    "another_pointer_at_two_node = two_node\n",
    "two_node = None\n",
    "print(two_node)\n",
    "print(another_pointer_at_two_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_node = tf.constant(2)\n",
    "three_node = tf.constant(3)\n",
    "sum_node = two_node + three_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(sum_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([two_node,three_node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 占位符和feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-976b580ef37f>\", line 1, in <module>\n    input_placeholder = tf.placeholder(tf.int32)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-976b580ef37f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-976b580ef37f>\", line 1, in <module>\n    input_placeholder = tf.placeholder(tf.int32)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "input_placeholder = tf.placeholder(tf.int32)\n",
    "sess.run(input_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(input_placeholder,feed_dict = {input_placeholder:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-976b580ef37f>\", line 1, in <module>\n    input_placeholder = tf.placeholder(tf.int32)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d6b2bcf11626>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msum_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_placeholder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mthree_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthree_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-976b580ef37f>\", line 1, in <module>\n    input_placeholder = tf.placeholder(tf.int32)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "sum_node = input_placeholder + three_node\n",
    "print(sess.run(three_node))\n",
    "print(sess.run(sum_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value count\n\t [[Node: _retval_count_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](count)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value count\n\t [[Node: _retval_count_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](count)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2b297ad05e60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcnt_variable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt_variable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value count\n\t [[Node: _retval_count_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](count)]]"
     ]
    }
   ],
   "source": [
    "cnt_variable = tf.get_variable(\"count\",[])\n",
    "sess.run(cnt_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 异常，首次创建变量节点时，它的值基本上为NULL，并且任何试图对它求值的操作都会引发这个异常，只能在将值放入后才能对其求值，主要有两种  \n",
    "将值放入变量的方法：初始化器和`tf.assign()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_node = tf.constant(0.)\n",
    "assign_node = tf.assign(cnt_variable,zero_node)\n",
    "sess.run(assign_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cnt_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 与之前的其它节点相比，`tf.assign(target,value)`有一些独特属性  \n",
    "  * 恒等运算。`tf.assign(target,value)`不做任何运算，通常与`value`相等  \n",
    "  * 副作用。当计算[流经]`assign_node`时，副作用发生在图中其它节点上，此时，副作用就是用存储在`zero_node`中值替换`cnt_variable`的值  \n",
    "  * 非依赖边。即使`cnt_variable`节点和`assign_node`在图中是相连的，但他们相互独立，意味着，计算任一节点，计算不会通过边回流，然而  \n",
    "  `assign_node`依赖于`zero_node`，它需要知道分配了什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [副作用]支撑着`TensorFlow` 深度学习工作流程，当我们调用`sess.run(assign_node)`时，计算路径会通过`assign_node`和`zero_node`  \n",
    "当计算流经图中的任何节点时，它还会执行该节点控制的任何副作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 初始化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable count already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a81a6d40e9af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconst_init_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcnt_variable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconst_init_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcnt_variable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1465\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1467\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1215\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    525\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    479\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    846\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 848\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable count already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Holly\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "const_init_node = tf.constant_initializer(0.)\n",
    "cnt_variable = tf.get_variable(\"count\",[],initializer=const_init_node)\n",
    "sess.run([cnt_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 为什么初始化器不工作？  \n",
    "  * 问题出现在会话和图之间的分离，我们已经将`get_variable()`的`initializer`属性设置为指向`const_init_node`,但它只是在变量和`cont_init_node`  之间添加了一个新的连接，并没有做任何解决异常根源的事：与变量节点（存储在会话中，而不是计算图中）相关联的内存仍设置为[null]，需要通过会话使  \n",
    "  `cont_init_node`去更新变量\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_init_node = tf.constant_initializer(0.)\n",
    "cnt_variable1 = tf.get_variable(\"count\",[],initializer= const_init_node)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)# 就是必须我们在使用时说的初始化\n",
    "sess.run(cnt_variable1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 上面，我们添加了一个特殊节点（初始化）：`init = tf.global_variables_initializer()`。与`tf.assign()`类似，这是一个带有副作用的节点，与  \n",
    "   `tf.assign()`相反，实际上，我们不需要指定它的输入是什么，`tf.global_variables_initializer()`将在其创建时查看全局图并自动将依赖关系添加到  \n",
    "   图中的每个`tf.initializer`.当我们在之后使用`sess.run(init)`对它求值时，它会告诉每个初始化程序执行变量初始化，并允许我们运行  \n",
    "   `sess.run(cnt_variable)`而不出错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 变量共享：不建议"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 典型的深度学习过程  \n",
    "  * 获取`input` 和`true_output`  \n",
    "  * 根据`input`和`parameters`计算`y_predict`  \n",
    "  * 计算loss:根据`y_predict`和`true_output`之间的差异  \n",
    "  * 迭代：根据`loss`的梯度更新`parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一个简单的线性回归问题  \n",
    "* 其实，线性回归就是一个单层的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th loss is : 2.29855\n",
      "1-th loss is : 2.06823\n",
      "2-th loss is : 1.40294\n",
      "3-th loss is : 1.36872\n",
      "4-th loss is : 1.999\n",
      "5-th loss is : 1.97484\n",
      "6-th loss is : 1.44492\n",
      "7-th loss is : 0.660672\n",
      "8-th loss is : 2.409\n",
      "9-th loss is : 1.77006\n",
      "10-th loss is : 2.28579\n",
      "11-th loss is : 2.16931\n",
      "12-th loss is : 2.86798\n",
      "13-th loss is : 2.79965\n",
      "14-th loss is : 1.22676\n",
      "15-th loss is : 2.57107\n",
      "16-th loss is : 2.26651\n",
      "17-th loss is : 0.623531\n",
      "18-th loss is : 2.33724\n",
      "19-th loss is : 1.10149\n",
      "20-th loss is : 1.27364\n",
      "21-th loss is : 0.752668\n",
      "22-th loss is : 0.809272\n",
      "23-th loss is : 1.83041\n",
      "24-th loss is : 2.12405\n",
      "25-th loss is : 0.614908\n",
      "26-th loss is : 2.71164\n",
      "27-th loss is : 2.41238\n",
      "28-th loss is : 1.25224\n",
      "29-th loss is : 2.09505\n",
      "30-th loss is : 1.67089\n",
      "31-th loss is : 1.13309\n",
      "32-th loss is : 1.31407\n",
      "33-th loss is : 0.860438\n",
      "34-th loss is : 1.03169\n",
      "35-th loss is : 2.31443\n",
      "36-th loss is : 2.26421\n",
      "37-th loss is : 2.3875\n",
      "38-th loss is : 1.58154\n",
      "39-th loss is : 0.66834\n",
      "40-th loss is : 0.912321\n",
      "41-th loss is : 1.29358\n",
      "42-th loss is : 1.16407\n",
      "43-th loss is : 0.900954\n",
      "44-th loss is : 2.46699\n",
      "45-th loss is : 1.66576\n",
      "46-th loss is : 1.61247\n",
      "47-th loss is : 1.7646\n",
      "48-th loss is : 2.6301\n",
      "49-th loss is : 1.80593\n",
      "50-th loss is : 0.751067\n",
      "51-th loss is : 1.74489\n",
      "52-th loss is : 1.60872\n",
      "53-th loss is : 2.24205\n",
      "54-th loss is : 2.46384\n",
      "55-th loss is : 1.22762\n",
      "56-th loss is : 1.25342\n",
      "57-th loss is : 1.07202\n",
      "58-th loss is : 2.2624\n",
      "59-th loss is : 2.71952\n",
      "60-th loss is : 0.72899\n",
      "61-th loss is : 0.663445\n",
      "62-th loss is : 0.612697\n",
      "63-th loss is : 1.02831\n",
      "64-th loss is : 0.926509\n",
      "65-th loss is : 0.827332\n",
      "66-th loss is : 0.676621\n",
      "67-th loss is : 1.64244\n",
      "68-th loss is : 0.91043\n",
      "69-th loss is : 0.882604\n",
      "70-th loss is : 2.28215\n",
      "71-th loss is : 1.28122\n",
      "72-th loss is : 1.869\n",
      "73-th loss is : 0.867278\n",
      "74-th loss is : 1.76987\n",
      "75-th loss is : 1.41785\n",
      "76-th loss is : 2.21441\n",
      "77-th loss is : 2.26077\n",
      "78-th loss is : 1.79076\n",
      "79-th loss is : 2.78177\n",
      "80-th loss is : 2.49209\n",
      "81-th loss is : 1.2986\n",
      "82-th loss is : 1.8222\n",
      "83-th loss is : 0.775536\n",
      "84-th loss is : 2.66427\n",
      "85-th loss is : 1.92321\n",
      "86-th loss is : 1.32012\n",
      "87-th loss is : 2.60634\n",
      "88-th loss is : 1.13561\n",
      "89-th loss is : 0.721388\n",
      "90-th loss is : 1.96247\n",
      "91-th loss is : 1.55155\n",
      "92-th loss is : 1.30387\n",
      "93-th loss is : 1.38156\n",
      "94-th loss is : 1.82565\n",
      "95-th loss is : 2.69897\n",
      "96-th loss is : 0.575956\n",
      "97-th loss is : 2.73007\n",
      "98-th loss is : 0.903914\n",
      "99-th loss is : 1.47785\n",
      "100-th loss is : 0.741886\n",
      "101-th loss is : 2.43512\n",
      "102-th loss is : 0.79278\n",
      "103-th loss is : 2.28353\n",
      "104-th loss is : 1.3372\n",
      "105-th loss is : 0.587376\n",
      "106-th loss is : 2.70173\n",
      "107-th loss is : 1.23815\n",
      "108-th loss is : 0.853291\n",
      "109-th loss is : 2.51505\n",
      "110-th loss is : 0.841839\n",
      "111-th loss is : 2.35089\n",
      "112-th loss is : 1.36409\n",
      "113-th loss is : 0.570308\n",
      "114-th loss is : 1.8268\n",
      "115-th loss is : 2.49403\n",
      "116-th loss is : 1.93413\n",
      "117-th loss is : 1.17307\n",
      "118-th loss is : 1.56235\n",
      "119-th loss is : 0.787752\n",
      "120-th loss is : 1.13571\n",
      "121-th loss is : 2.60292\n",
      "122-th loss is : 1.32689\n",
      "123-th loss is : 2.08605\n",
      "124-th loss is : 1.1618\n",
      "125-th loss is : 0.606761\n",
      "126-th loss is : 0.638116\n",
      "127-th loss is : 1.25957\n",
      "128-th loss is : 0.63099\n",
      "129-th loss is : 2.09239\n",
      "130-th loss is : 1.60278\n",
      "131-th loss is : 2.64121\n",
      "132-th loss is : 0.657793\n",
      "133-th loss is : 2.08543\n",
      "134-th loss is : 1.5392\n",
      "135-th loss is : 1.88247\n",
      "136-th loss is : 0.796857\n",
      "137-th loss is : 0.750033\n",
      "138-th loss is : 0.682224\n",
      "139-th loss is : 1.63737\n",
      "140-th loss is : 1.71772\n",
      "141-th loss is : 1.48814\n",
      "142-th loss is : 1.44837\n",
      "143-th loss is : 2.09912\n",
      "144-th loss is : 1.3464\n",
      "145-th loss is : 2.0184\n",
      "146-th loss is : 2.10219\n",
      "147-th loss is : 2.34229\n",
      "148-th loss is : 2.07497\n",
      "149-th loss is : 1.37387\n",
      "150-th loss is : 0.737795\n",
      "151-th loss is : 2.38956\n",
      "152-th loss is : 1.68618\n",
      "153-th loss is : 0.994439\n",
      "154-th loss is : 2.27886\n",
      "155-th loss is : 1.40555\n",
      "156-th loss is : 2.50211\n",
      "157-th loss is : 1.42726\n",
      "158-th loss is : 1.38461\n",
      "159-th loss is : 1.06746\n",
      "160-th loss is : 2.53977\n",
      "161-th loss is : 1.03128\n",
      "162-th loss is : 1.39115\n",
      "163-th loss is : 0.764158\n",
      "164-th loss is : 1.36647\n",
      "165-th loss is : 0.879652\n",
      "166-th loss is : 1.01136\n",
      "167-th loss is : 1.08473\n",
      "168-th loss is : 1.18204\n",
      "169-th loss is : 1.29046\n",
      "170-th loss is : 0.573907\n",
      "171-th loss is : 0.846481\n",
      "172-th loss is : 1.74106\n",
      "173-th loss is : 0.809093\n",
      "174-th loss is : 0.911122\n",
      "175-th loss is : 1.87331\n",
      "176-th loss is : 1.42569\n",
      "177-th loss is : 2.09615\n",
      "178-th loss is : 1.83789\n",
      "179-th loss is : 1.84129\n",
      "180-th loss is : 1.22493\n",
      "181-th loss is : 2.65517\n",
      "182-th loss is : 1.2863\n",
      "183-th loss is : 1.98791\n",
      "184-th loss is : 1.84197\n",
      "185-th loss is : 0.548985\n",
      "186-th loss is : 2.65596\n",
      "187-th loss is : 1.6718\n",
      "188-th loss is : 0.84257\n",
      "189-th loss is : 1.87331\n",
      "190-th loss is : 2.11264\n",
      "191-th loss is : 0.717888\n",
      "192-th loss is : 1.80681\n",
      "193-th loss is : 1.40417\n",
      "194-th loss is : 1.27577\n",
      "195-th loss is : 1.1725\n",
      "196-th loss is : 0.543907\n",
      "197-th loss is : 0.817915\n",
      "198-th loss is : 1.50381\n",
      "199-th loss is : 0.561416\n",
      "200-th loss is : 0.705199\n",
      "201-th loss is : 1.32668\n",
      "202-th loss is : 1.76542\n",
      "203-th loss is : 1.22118\n",
      "204-th loss is : 1.71011\n",
      "205-th loss is : 0.568618\n",
      "206-th loss is : 2.61246\n",
      "207-th loss is : 0.874507\n",
      "208-th loss is : 2.24295\n",
      "209-th loss is : 2.11521\n",
      "210-th loss is : 0.65994\n",
      "211-th loss is : 1.26965\n",
      "212-th loss is : 1.07346\n",
      "213-th loss is : 1.4193\n",
      "214-th loss is : 0.697712\n",
      "215-th loss is : 0.707802\n",
      "216-th loss is : 1.79557\n",
      "217-th loss is : 2.11209\n",
      "218-th loss is : 0.619077\n",
      "219-th loss is : 2.58417\n",
      "220-th loss is : 1.06775\n",
      "221-th loss is : 2.2419\n",
      "222-th loss is : 1.28996\n",
      "223-th loss is : 1.1275\n",
      "224-th loss is : 0.768474\n",
      "225-th loss is : 1.25096\n",
      "226-th loss is : 1.19566\n",
      "227-th loss is : 0.855777\n",
      "228-th loss is : 0.677824\n",
      "229-th loss is : 0.953896\n",
      "230-th loss is : 1.82471\n",
      "231-th loss is : 2.57435\n",
      "232-th loss is : 2.20329\n",
      "233-th loss is : 2.02621\n",
      "234-th loss is : 1.29526\n",
      "235-th loss is : 1.58382\n",
      "236-th loss is : 1.15382\n",
      "237-th loss is : 2.31008\n",
      "238-th loss is : 2.56211\n",
      "239-th loss is : 2.34232\n",
      "240-th loss is : 1.13913\n",
      "241-th loss is : 2.0926\n",
      "242-th loss is : 1.98343\n",
      "243-th loss is : 2.26139\n",
      "244-th loss is : 0.550024\n",
      "245-th loss is : 1.81555\n",
      "246-th loss is : 0.658374\n",
      "247-th loss is : 1.50756\n",
      "248-th loss is : 1.55189\n",
      "249-th loss is : 2.30089\n",
      "250-th loss is : 2.21802\n",
      "251-th loss is : 1.12224\n",
      "252-th loss is : 2.16722\n",
      "253-th loss is : 1.24849\n",
      "254-th loss is : 2.56231\n",
      "255-th loss is : 0.969178\n",
      "256-th loss is : 1.05105\n",
      "257-th loss is : 1.92389\n",
      "258-th loss is : 1.92607\n",
      "259-th loss is : 0.679456\n",
      "260-th loss is : 1.98876\n",
      "261-th loss is : 1.54797\n",
      "262-th loss is : 2.15256\n",
      "263-th loss is : 0.576103\n",
      "264-th loss is : 0.834717\n",
      "265-th loss is : 1.9943\n",
      "266-th loss is : 1.2942\n",
      "267-th loss is : 1.52877\n",
      "268-th loss is : 1.74017\n",
      "269-th loss is : 0.62738\n",
      "270-th loss is : 1.12286\n",
      "271-th loss is : 2.55506\n",
      "272-th loss is : 1.6154\n",
      "273-th loss is : 1.20893\n",
      "274-th loss is : 0.542716\n",
      "275-th loss is : 1.29686\n",
      "276-th loss is : 1.10105\n",
      "277-th loss is : 1.70669\n",
      "278-th loss is : 1.08878\n",
      "279-th loss is : 1.25399\n",
      "280-th loss is : 1.87602\n",
      "281-th loss is : 0.598123\n",
      "282-th loss is : 2.20015\n",
      "283-th loss is : 1.16106\n",
      "284-th loss is : 1.50057\n",
      "285-th loss is : 1.47326\n",
      "286-th loss is : 1.63576\n",
      "287-th loss is : 2.38716\n",
      "288-th loss is : 1.57024\n",
      "289-th loss is : 1.88325\n",
      "290-th loss is : 0.594017\n",
      "291-th loss is : 1.18119\n",
      "292-th loss is : 2.02598\n",
      "293-th loss is : 2.22297\n",
      "294-th loss is : 1.25367\n",
      "295-th loss is : 0.723533\n",
      "296-th loss is : 2.04723\n",
      "297-th loss is : 0.794921\n",
      "298-th loss is : 0.802359\n",
      "299-th loss is : 2.52075\n",
      "300-th loss is : 0.854955\n",
      "301-th loss is : 0.757865\n",
      "302-th loss is : 0.497843\n",
      "303-th loss is : 1.77688\n",
      "304-th loss is : 2.09691\n",
      "305-th loss is : 1.72169\n",
      "306-th loss is : 1.84451\n",
      "307-th loss is : 1.03923\n",
      "308-th loss is : 0.510009\n",
      "309-th loss is : 1.48782\n",
      "310-th loss is : 0.814944\n",
      "311-th loss is : 1.05189\n",
      "312-th loss is : 2.09889\n",
      "313-th loss is : 1.43529\n",
      "314-th loss is : 1.67233\n",
      "315-th loss is : 0.651865\n",
      "316-th loss is : 1.94479\n",
      "317-th loss is : 1.31129\n",
      "318-th loss is : 1.41658\n",
      "319-th loss is : 0.526834\n",
      "320-th loss is : 2.16612\n",
      "321-th loss is : 1.34736\n",
      "322-th loss is : 1.93801\n",
      "323-th loss is : 1.94497\n",
      "324-th loss is : 0.775802\n",
      "325-th loss is : 2.12654\n",
      "326-th loss is : 1.1273\n",
      "327-th loss is : 1.66011\n",
      "328-th loss is : 1.5657\n",
      "329-th loss is : 0.756302\n",
      "330-th loss is : 0.811501\n",
      "331-th loss is : 2.37232\n",
      "332-th loss is : 0.972699\n",
      "333-th loss is : 1.40039\n",
      "334-th loss is : 2.1501\n",
      "335-th loss is : 0.679826\n",
      "336-th loss is : 2.26148\n",
      "337-th loss is : 1.04029\n",
      "338-th loss is : 1.22336\n",
      "339-th loss is : 1.11122\n",
      "340-th loss is : 1.29979\n",
      "341-th loss is : 1.57795\n",
      "342-th loss is : 2.43934\n",
      "343-th loss is : 0.646445\n",
      "344-th loss is : 2.07361\n",
      "345-th loss is : 1.88358\n",
      "346-th loss is : 2.43203\n",
      "347-th loss is : 1.27202\n",
      "348-th loss is : 0.602121\n",
      "349-th loss is : 1.6261\n",
      "350-th loss is : 0.907249\n",
      "351-th loss is : 0.776824\n",
      "352-th loss is : 0.981018\n",
      "353-th loss is : 1.57895\n",
      "354-th loss is : 2.32781\n",
      "355-th loss is : 0.741235\n",
      "356-th loss is : 2.04694\n",
      "357-th loss is : 0.675144\n",
      "358-th loss is : 1.81472\n",
      "359-th loss is : 1.87525\n",
      "360-th loss is : 1.9749\n",
      "361-th loss is : 1.45805\n",
      "362-th loss is : 1.03658\n",
      "363-th loss is : 2.22315\n",
      "364-th loss is : 0.726029\n",
      "365-th loss is : 1.67768\n",
      "366-th loss is : 1.49023\n",
      "367-th loss is : 1.00734\n",
      "368-th loss is : 0.999352\n",
      "369-th loss is : 2.3589\n",
      "370-th loss is : 1.4966\n",
      "371-th loss is : 1.70298\n",
      "372-th loss is : 0.806511\n",
      "373-th loss is : 1.26946\n",
      "374-th loss is : 1.63833\n",
      "375-th loss is : 1.43208\n",
      "376-th loss is : 1.23295\n",
      "377-th loss is : 0.782506\n",
      "378-th loss is : 0.754601\n",
      "379-th loss is : 2.33216\n",
      "380-th loss is : 1.04217\n",
      "381-th loss is : 1.16817\n",
      "382-th loss is : 2.18498\n",
      "383-th loss is : 1.49802\n",
      "384-th loss is : 1.06215\n",
      "385-th loss is : 0.888178\n",
      "386-th loss is : 0.967483\n",
      "387-th loss is : 0.516493\n",
      "388-th loss is : 1.58386\n",
      "389-th loss is : 0.789528\n",
      "390-th loss is : 1.8422\n",
      "391-th loss is : 0.851875\n",
      "392-th loss is : 0.932113\n",
      "393-th loss is : 0.478751\n",
      "394-th loss is : 1.53723\n",
      "395-th loss is : 2.06974\n",
      "396-th loss is : 0.716609\n",
      "397-th loss is : 0.836655\n",
      "398-th loss is : 1.2341\n",
      "399-th loss is : 1.97785\n",
      "400-th loss is : 1.34306\n",
      "401-th loss is : 2.30349\n",
      "402-th loss is : 1.98263\n",
      "403-th loss is : 0.782046\n",
      "404-th loss is : 1.43805\n",
      "405-th loss is : 1.89472\n",
      "406-th loss is : 0.841281\n",
      "407-th loss is : 1.65168\n",
      "408-th loss is : 1.93876\n",
      "409-th loss is : 0.509214\n",
      "410-th loss is : 2.22137\n",
      "411-th loss is : 1.40968\n",
      "412-th loss is : 0.689488\n",
      "413-th loss is : 0.755511\n",
      "414-th loss is : 1.31487\n",
      "415-th loss is : 0.638198\n",
      "416-th loss is : 0.584414\n",
      "417-th loss is : 0.732289\n",
      "418-th loss is : 2.00853\n",
      "419-th loss is : 0.858982\n",
      "420-th loss is : 1.38334\n",
      "421-th loss is : 0.555489\n",
      "422-th loss is : 2.03784\n",
      "423-th loss is : 0.901919\n",
      "424-th loss is : 2.15493\n",
      "425-th loss is : 1.62894\n",
      "426-th loss is : 1.60425\n",
      "427-th loss is : 1.8264\n",
      "428-th loss is : 1.3757\n",
      "429-th loss is : 1.76187\n",
      "430-th loss is : 1.44423\n",
      "431-th loss is : 0.813274\n",
      "432-th loss is : 1.96301\n",
      "433-th loss is : 0.969698\n",
      "434-th loss is : 1.51236\n",
      "435-th loss is : 0.697567\n",
      "436-th loss is : 0.74476\n",
      "437-th loss is : 2.32895\n",
      "438-th loss is : 1.63932\n",
      "439-th loss is : 0.818128\n",
      "440-th loss is : 0.602\n",
      "441-th loss is : 1.54454\n",
      "442-th loss is : 0.948032\n",
      "443-th loss is : 0.89753\n",
      "444-th loss is : 1.39378\n",
      "445-th loss is : 1.09701\n",
      "446-th loss is : 0.530219\n",
      "447-th loss is : 0.991752\n",
      "448-th loss is : 1.03892\n",
      "449-th loss is : 0.62188\n",
      "450-th loss is : 1.6132\n",
      "451-th loss is : 0.481786\n",
      "452-th loss is : 0.503425\n",
      "453-th loss is : 1.30701\n",
      "454-th loss is : 2.30658\n",
      "455-th loss is : 1.36794\n",
      "456-th loss is : 1.13787\n",
      "457-th loss is : 0.643093\n",
      "458-th loss is : 1.37439\n",
      "459-th loss is : 0.592735\n",
      "460-th loss is : 2.1696\n",
      "461-th loss is : 1.8768\n",
      "462-th loss is : 0.833332\n",
      "463-th loss is : 0.497337\n",
      "464-th loss is : 0.493561\n",
      "465-th loss is : 1.18161\n",
      "466-th loss is : 2.14082\n",
      "467-th loss is : 1.84388\n",
      "468-th loss is : 0.761037\n",
      "469-th loss is : 0.733866\n",
      "470-th loss is : 0.965784\n",
      "471-th loss is : 2.07461\n",
      "472-th loss is : 1.49003\n",
      "473-th loss is : 2.14471\n",
      "474-th loss is : 0.557833\n",
      "475-th loss is : 0.640047\n",
      "476-th loss is : 0.978962\n",
      "477-th loss is : 1.02664\n",
      "478-th loss is : 1.06623\n",
      "479-th loss is : 0.659706\n",
      "480-th loss is : 2.27328\n",
      "481-th loss is : 0.495042\n",
      "482-th loss is : 0.592785\n",
      "483-th loss is : 0.902389\n",
      "484-th loss is : 1.31322\n",
      "485-th loss is : 2.32283\n",
      "486-th loss is : 0.998495\n",
      "487-th loss is : 0.741994\n",
      "488-th loss is : 1.92113\n",
      "489-th loss is : 0.476891\n",
      "490-th loss is : 2.078\n",
      "491-th loss is : 1.81526\n",
      "492-th loss is : 1.41108\n",
      "493-th loss is : 0.775268\n",
      "494-th loss is : 0.455583\n",
      "495-th loss is : 2.12866\n",
      "496-th loss is : 0.740927\n",
      "497-th loss is : 0.573699\n",
      "498-th loss is : 0.525068\n",
      "499-th loss is : 1.29003\n",
      "500-th loss is : 0.471314\n",
      "501-th loss is : 0.530948\n",
      "502-th loss is : 0.693479\n",
      "503-th loss is : 1.35919\n",
      "504-th loss is : 2.30539\n",
      "505-th loss is : 0.492667\n",
      "506-th loss is : 0.520451\n",
      "507-th loss is : 2.02452\n",
      "508-th loss is : 0.842841\n",
      "509-th loss is : 0.523611\n",
      "510-th loss is : 2.08389\n",
      "511-th loss is : 1.9291\n",
      "512-th loss is : 2.28015\n",
      "513-th loss is : 1.7272\n",
      "514-th loss is : 1.45424\n",
      "515-th loss is : 2.17027\n",
      "516-th loss is : 0.850293\n",
      "517-th loss is : 0.99958\n",
      "518-th loss is : 1.57762\n",
      "519-th loss is : 1.77941\n",
      "520-th loss is : 0.868546\n",
      "521-th loss is : 1.92597\n",
      "522-th loss is : 1.32409\n",
      "523-th loss is : 1.45174\n",
      "524-th loss is : 1.607\n",
      "525-th loss is : 1.9934\n",
      "526-th loss is : 0.767184\n",
      "527-th loss is : 0.789319\n",
      "528-th loss is : 0.889423\n",
      "529-th loss is : 1.68197\n",
      "530-th loss is : 0.46351\n",
      "531-th loss is : 1.16233\n",
      "532-th loss is : 0.541287\n",
      "533-th loss is : 0.690626\n",
      "534-th loss is : 1.38369\n",
      "535-th loss is : 1.44548\n",
      "536-th loss is : 1.21539\n",
      "537-th loss is : 1.48963\n",
      "538-th loss is : 0.441504\n",
      "539-th loss is : 2.00998\n",
      "540-th loss is : 1.45468\n",
      "541-th loss is : 1.0461\n",
      "542-th loss is : 0.431817\n",
      "543-th loss is : 0.453924\n",
      "544-th loss is : 1.37658\n",
      "545-th loss is : 1.94596\n",
      "546-th loss is : 0.645258\n",
      "547-th loss is : 0.985925\n",
      "548-th loss is : 1.66055\n",
      "549-th loss is : 0.892047\n",
      "550-th loss is : 0.445382\n",
      "551-th loss is : 1.35114\n",
      "552-th loss is : 1.42565\n",
      "553-th loss is : 1.12972\n",
      "554-th loss is : 0.871213\n",
      "555-th loss is : 0.777485\n",
      "556-th loss is : 0.91529\n",
      "557-th loss is : 1.23508\n",
      "558-th loss is : 0.820369\n",
      "559-th loss is : 0.905074\n",
      "560-th loss is : 0.500384\n",
      "561-th loss is : 0.503909\n",
      "562-th loss is : 0.595024\n",
      "563-th loss is : 2.14609\n",
      "564-th loss is : 0.783107\n",
      "565-th loss is : 0.821084\n",
      "566-th loss is : 1.6463\n",
      "567-th loss is : 1.65034\n",
      "568-th loss is : 0.633794\n",
      "569-th loss is : 0.497376\n",
      "570-th loss is : 1.3839\n",
      "571-th loss is : 1.66284\n",
      "572-th loss is : 2.04186\n",
      "573-th loss is : 0.728616\n",
      "574-th loss is : 1.3923\n",
      "575-th loss is : 0.868357\n",
      "576-th loss is : 1.5336\n",
      "577-th loss is : 0.852474\n",
      "578-th loss is : 1.67449\n",
      "579-th loss is : 1.96882\n",
      "580-th loss is : 0.739968\n",
      "581-th loss is : 0.622755\n",
      "582-th loss is : 1.82547\n",
      "583-th loss is : 1.6224\n",
      "584-th loss is : 1.32102\n",
      "585-th loss is : 1.06432\n",
      "586-th loss is : 1.49795\n",
      "587-th loss is : 0.550746\n",
      "588-th loss is : 1.94088\n",
      "589-th loss is : 1.68158\n",
      "590-th loss is : 1.98093\n",
      "591-th loss is : 1.08762\n",
      "592-th loss is : 0.467807\n",
      "593-th loss is : 0.98042\n",
      "594-th loss is : 0.843027\n",
      "595-th loss is : 1.47706\n",
      "596-th loss is : 0.880968\n",
      "597-th loss is : 0.745995\n",
      "598-th loss is : 1.49936\n",
      "599-th loss is : 1.05899\n",
      "600-th loss is : 0.835938\n",
      "601-th loss is : 1.05249\n",
      "602-th loss is : 1.73532\n",
      "603-th loss is : 1.35754\n",
      "604-th loss is : 0.51829\n",
      "605-th loss is : 0.671902\n",
      "606-th loss is : 0.982418\n",
      "607-th loss is : 0.62761\n",
      "608-th loss is : 0.91048\n",
      "609-th loss is : 1.81427\n",
      "610-th loss is : 0.416195\n",
      "611-th loss is : 0.529116\n",
      "612-th loss is : 0.892092\n",
      "613-th loss is : 0.995963\n",
      "614-th loss is : 0.697924\n",
      "615-th loss is : 1.31546\n",
      "616-th loss is : 1.75348\n",
      "617-th loss is : 0.436105\n",
      "618-th loss is : 1.16864\n",
      "619-th loss is : 2.06638\n",
      "620-th loss is : 0.655449\n",
      "621-th loss is : 1.63069\n",
      "622-th loss is : 1.19717\n",
      "623-th loss is : 1.57927\n",
      "624-th loss is : 1.3691\n",
      "625-th loss is : 0.461959\n",
      "626-th loss is : 0.662932\n",
      "627-th loss is : 0.994736\n",
      "628-th loss is : 1.47921\n",
      "629-th loss is : 1.29073\n",
      "630-th loss is : 1.14168\n",
      "631-th loss is : 0.750987\n",
      "632-th loss is : 1.54905\n",
      "633-th loss is : 1.9315\n",
      "634-th loss is : 1.16738\n",
      "635-th loss is : 0.998256\n",
      "636-th loss is : 1.62546\n",
      "637-th loss is : 0.899736\n",
      "638-th loss is : 1.63804\n",
      "639-th loss is : 1.07284\n",
      "640-th loss is : 0.7615\n",
      "641-th loss is : 1.69434\n",
      "642-th loss is : 2.17547\n",
      "643-th loss is : 1.11635\n",
      "644-th loss is : 2.13626\n",
      "645-th loss is : 1.30283\n",
      "646-th loss is : 1.66647\n",
      "647-th loss is : 1.35532\n",
      "648-th loss is : 2.03159\n",
      "649-th loss is : 1.22319\n",
      "650-th loss is : 1.21932\n",
      "651-th loss is : 1.14584\n",
      "652-th loss is : 1.71814\n",
      "653-th loss is : 0.847612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654-th loss is : 0.561024\n",
      "655-th loss is : 0.795184\n",
      "656-th loss is : 0.542249\n",
      "657-th loss is : 0.547373\n",
      "658-th loss is : 1.35641\n",
      "659-th loss is : 0.97656\n",
      "660-th loss is : 1.51983\n",
      "661-th loss is : 1.07941\n",
      "662-th loss is : 1.80053\n",
      "663-th loss is : 0.460529\n",
      "664-th loss is : 0.482983\n",
      "665-th loss is : 1.14792\n",
      "666-th loss is : 1.85234\n",
      "667-th loss is : 0.968935\n",
      "668-th loss is : 1.92609\n",
      "669-th loss is : 0.720466\n",
      "670-th loss is : 0.424199\n",
      "671-th loss is : 1.67712\n",
      "672-th loss is : 0.65728\n",
      "673-th loss is : 2.03632\n",
      "674-th loss is : 0.761863\n",
      "675-th loss is : 0.444925\n",
      "676-th loss is : 1.3121\n",
      "677-th loss is : 0.693417\n",
      "678-th loss is : 0.494442\n",
      "679-th loss is : 1.76126\n",
      "680-th loss is : 1.30364\n",
      "681-th loss is : 0.909464\n",
      "682-th loss is : 1.92334\n",
      "683-th loss is : 1.39746\n",
      "684-th loss is : 0.628245\n",
      "685-th loss is : 1.22267\n",
      "686-th loss is : 1.72127\n",
      "687-th loss is : 1.07248\n",
      "688-th loss is : 1.58163\n",
      "689-th loss is : 1.75445\n",
      "690-th loss is : 1.61313\n",
      "691-th loss is : 0.999679\n",
      "692-th loss is : 2.08171\n",
      "693-th loss is : 1.04725\n",
      "694-th loss is : 0.654202\n",
      "695-th loss is : 1.37506\n",
      "696-th loss is : 0.888808\n",
      "697-th loss is : 1.33571\n",
      "698-th loss is : 1.18553\n",
      "699-th loss is : 2.026\n",
      "700-th loss is : 1.53769\n",
      "701-th loss is : 1.8572\n",
      "702-th loss is : 2.00134\n",
      "703-th loss is : 1.10094\n",
      "704-th loss is : 0.459322\n",
      "705-th loss is : 1.96402\n",
      "706-th loss is : 0.534388\n",
      "707-th loss is : 0.407944\n",
      "708-th loss is : 1.47645\n",
      "709-th loss is : 0.694912\n",
      "710-th loss is : 0.820776\n",
      "711-th loss is : 1.53938\n",
      "712-th loss is : 0.459318\n",
      "713-th loss is : 0.491702\n",
      "714-th loss is : 0.719775\n",
      "715-th loss is : 0.586071\n",
      "716-th loss is : 0.71289\n",
      "717-th loss is : 0.500087\n",
      "718-th loss is : 0.768278\n",
      "719-th loss is : 0.909773\n",
      "720-th loss is : 0.388236\n",
      "721-th loss is : 0.677321\n",
      "722-th loss is : 1.53247\n",
      "723-th loss is : 1.04908\n",
      "724-th loss is : 0.503625\n",
      "725-th loss is : 1.37337\n",
      "726-th loss is : 0.547402\n",
      "727-th loss is : 0.464104\n",
      "728-th loss is : 1.08271\n",
      "729-th loss is : 0.553607\n",
      "730-th loss is : 1.09355\n",
      "731-th loss is : 0.683291\n",
      "732-th loss is : 1.21705\n",
      "733-th loss is : 1.1282\n",
      "734-th loss is : 1.15042\n",
      "735-th loss is : 1.05089\n",
      "736-th loss is : 0.90811\n",
      "737-th loss is : 0.844479\n",
      "738-th loss is : 0.592335\n",
      "739-th loss is : 0.622599\n",
      "740-th loss is : 1.76585\n",
      "741-th loss is : 1.12274\n",
      "742-th loss is : 0.535511\n",
      "743-th loss is : 1.27735\n",
      "744-th loss is : 1.44522\n",
      "745-th loss is : 0.848981\n",
      "746-th loss is : 1.53093\n",
      "747-th loss is : 1.06912\n",
      "748-th loss is : 0.681439\n",
      "749-th loss is : 1.67946\n",
      "750-th loss is : 0.703689\n",
      "751-th loss is : 1.84994\n",
      "752-th loss is : 1.12499\n",
      "753-th loss is : 1.54654\n",
      "754-th loss is : 1.22233\n",
      "755-th loss is : 0.465923\n",
      "756-th loss is : 1.06252\n",
      "757-th loss is : 1.57604\n",
      "758-th loss is : 0.456697\n",
      "759-th loss is : 1.50141\n",
      "760-th loss is : 0.807196\n",
      "761-th loss is : 1.78738\n",
      "762-th loss is : 1.39885\n",
      "763-th loss is : 1.38454\n",
      "764-th loss is : 1.5657\n",
      "765-th loss is : 1.82996\n",
      "766-th loss is : 1.39227\n",
      "767-th loss is : 1.42636\n",
      "768-th loss is : 1.72685\n",
      "769-th loss is : 1.58524\n",
      "770-th loss is : 1.4752\n",
      "771-th loss is : 0.773509\n",
      "772-th loss is : 0.749854\n",
      "773-th loss is : 1.46175\n",
      "774-th loss is : 1.55584\n",
      "775-th loss is : 1.54714\n",
      "776-th loss is : 1.75623\n",
      "777-th loss is : 1.24721\n",
      "778-th loss is : 0.846897\n",
      "779-th loss is : 0.972957\n",
      "780-th loss is : 0.908108\n",
      "781-th loss is : 1.5868\n",
      "782-th loss is : 1.52373\n",
      "783-th loss is : 1.3741\n",
      "784-th loss is : 1.1053\n",
      "785-th loss is : 1.22785\n",
      "786-th loss is : 0.856501\n",
      "787-th loss is : 0.647774\n",
      "788-th loss is : 1.45277\n",
      "789-th loss is : 1.08839\n",
      "790-th loss is : 0.641248\n",
      "791-th loss is : 0.647078\n",
      "792-th loss is : 0.368754\n",
      "793-th loss is : 1.12462\n",
      "794-th loss is : 1.533\n",
      "795-th loss is : 1.46724\n",
      "796-th loss is : 0.92669\n",
      "797-th loss is : 1.24063\n",
      "798-th loss is : 1.88384\n",
      "799-th loss is : 0.981151\n",
      "800-th loss is : 1.76364\n",
      "801-th loss is : 1.46729\n",
      "802-th loss is : 1.25298\n",
      "803-th loss is : 1.79014\n",
      "804-th loss is : 1.07922\n",
      "805-th loss is : 1.763\n",
      "806-th loss is : 1.63212\n",
      "807-th loss is : 1.28419\n",
      "808-th loss is : 1.86518\n",
      "809-th loss is : 0.405819\n",
      "810-th loss is : 0.926201\n",
      "811-th loss is : 1.2275\n",
      "812-th loss is : 0.748956\n",
      "813-th loss is : 0.693425\n",
      "814-th loss is : 0.989839\n",
      "815-th loss is : 0.378967\n",
      "816-th loss is : 0.733447\n",
      "817-th loss is : 1.25652\n",
      "818-th loss is : 1.62852\n",
      "819-th loss is : 0.628182\n",
      "820-th loss is : 1.04348\n",
      "821-th loss is : 1.85078\n",
      "822-th loss is : 1.18123\n",
      "823-th loss is : 0.470222\n",
      "824-th loss is : 0.82822\n",
      "825-th loss is : 0.796817\n",
      "826-th loss is : 1.52849\n",
      "827-th loss is : 1.86389\n",
      "828-th loss is : 0.491961\n",
      "829-th loss is : 0.42736\n",
      "830-th loss is : 0.523015\n",
      "831-th loss is : 1.10017\n",
      "832-th loss is : 0.551387\n",
      "833-th loss is : 0.398513\n",
      "834-th loss is : 1.65868\n",
      "835-th loss is : 0.747339\n",
      "836-th loss is : 1.7387\n",
      "837-th loss is : 1.21629\n",
      "838-th loss is : 1.70536\n",
      "839-th loss is : 1.37954\n",
      "840-th loss is : 0.434125\n",
      "841-th loss is : 1.23444\n",
      "842-th loss is : 1.05979\n",
      "843-th loss is : 0.355735\n",
      "844-th loss is : 0.453166\n",
      "845-th loss is : 1.02563\n",
      "846-th loss is : 1.41602\n",
      "847-th loss is : 1.15343\n",
      "848-th loss is : 1.16345\n",
      "849-th loss is : 1.54192\n",
      "850-th loss is : 1.22265\n",
      "851-th loss is : 0.549654\n",
      "852-th loss is : 1.19339\n",
      "853-th loss is : 0.718166\n",
      "854-th loss is : 0.41621\n",
      "855-th loss is : 1.63716\n",
      "856-th loss is : 1.62407\n",
      "857-th loss is : 1.97504\n",
      "858-th loss is : 1.12816\n",
      "859-th loss is : 1.03344\n",
      "860-th loss is : 0.388209\n",
      "861-th loss is : 1.12023\n",
      "862-th loss is : 0.384107\n",
      "863-th loss is : 1.45542\n",
      "864-th loss is : 1.51341\n",
      "865-th loss is : 0.741663\n",
      "866-th loss is : 0.782907\n",
      "867-th loss is : 0.867835\n",
      "868-th loss is : 0.665477\n",
      "869-th loss is : 1.08351\n",
      "870-th loss is : 0.703751\n",
      "871-th loss is : 0.507638\n",
      "872-th loss is : 0.344165\n",
      "873-th loss is : 0.922169\n",
      "874-th loss is : 1.47794\n",
      "875-th loss is : 1.84977\n",
      "876-th loss is : 1.4363\n",
      "877-th loss is : 0.822487\n",
      "878-th loss is : 1.45317\n",
      "879-th loss is : 1.07601\n",
      "880-th loss is : 0.391292\n",
      "881-th loss is : 1.11306\n",
      "882-th loss is : 0.43974\n",
      "883-th loss is : 0.948487\n",
      "884-th loss is : 0.821108\n",
      "885-th loss is : 1.38123\n",
      "886-th loss is : 1.89519\n",
      "887-th loss is : 0.87835\n",
      "888-th loss is : 1.44574\n",
      "889-th loss is : 0.472128\n",
      "890-th loss is : 0.643732\n",
      "891-th loss is : 0.760127\n",
      "892-th loss is : 0.805078\n",
      "893-th loss is : 1.41263\n",
      "894-th loss is : 0.716352\n",
      "895-th loss is : 1.36571\n",
      "896-th loss is : 1.72964\n",
      "897-th loss is : 0.949062\n",
      "898-th loss is : 1.65783\n",
      "899-th loss is : 0.902991\n",
      "900-th loss is : 0.403004\n",
      "901-th loss is : 0.365684\n",
      "902-th loss is : 1.38216\n",
      "903-th loss is : 0.4891\n",
      "904-th loss is : 1.00514\n",
      "905-th loss is : 0.641575\n",
      "906-th loss is : 1.04803\n",
      "907-th loss is : 0.931319\n",
      "908-th loss is : 0.338254\n",
      "909-th loss is : 0.64236\n",
      "910-th loss is : 1.39151\n",
      "911-th loss is : 1.0876\n",
      "912-th loss is : 1.68489\n",
      "913-th loss is : 1.32255\n",
      "914-th loss is : 1.33335\n",
      "915-th loss is : 1.28366\n",
      "916-th loss is : 1.42562\n",
      "917-th loss is : 0.902343\n",
      "918-th loss is : 0.424975\n",
      "919-th loss is : 1.3849\n",
      "920-th loss is : 0.949609\n",
      "921-th loss is : 1.28222\n",
      "922-th loss is : 1.6415\n",
      "923-th loss is : 0.935203\n",
      "924-th loss is : 1.69945\n",
      "925-th loss is : 0.94985\n",
      "926-th loss is : 0.416413\n",
      "927-th loss is : 0.873687\n",
      "928-th loss is : 0.646144\n",
      "929-th loss is : 1.3018\n",
      "930-th loss is : 0.51047\n",
      "931-th loss is : 0.361845\n",
      "932-th loss is : 0.380504\n",
      "933-th loss is : 1.02966\n",
      "934-th loss is : 1.71057\n",
      "935-th loss is : 1.16346\n",
      "936-th loss is : 0.527001\n",
      "937-th loss is : 0.73535\n",
      "938-th loss is : 1.2456\n",
      "939-th loss is : 1.61968\n",
      "940-th loss is : 1.64755\n",
      "941-th loss is : 1.67326\n",
      "942-th loss is : 0.416213\n",
      "943-th loss is : 1.00248\n",
      "944-th loss is : 0.752094\n",
      "945-th loss is : 1.16949\n",
      "946-th loss is : 0.592986\n",
      "947-th loss is : 0.744455\n",
      "948-th loss is : 1.02323\n",
      "949-th loss is : 0.390369\n",
      "950-th loss is : 1.13543\n",
      "951-th loss is : 0.653625\n",
      "952-th loss is : 0.858005\n",
      "953-th loss is : 1.13331\n",
      "954-th loss is : 0.457044\n",
      "955-th loss is : 0.954806\n",
      "956-th loss is : 0.432583\n",
      "957-th loss is : 1.21566\n",
      "958-th loss is : 0.364666\n",
      "959-th loss is : 1.7912\n",
      "960-th loss is : 0.653377\n",
      "961-th loss is : 1.66212\n",
      "962-th loss is : 0.527654\n",
      "963-th loss is : 1.15224\n",
      "964-th loss is : 0.704742\n",
      "965-th loss is : 0.34828\n",
      "966-th loss is : 1.77531\n",
      "967-th loss is : 1.15311\n",
      "968-th loss is : 1.80892\n",
      "969-th loss is : 1.05369\n",
      "970-th loss is : 0.775027\n",
      "971-th loss is : 0.69138\n",
      "972-th loss is : 1.66676\n",
      "973-th loss is : 0.964672\n",
      "974-th loss is : 0.336335\n",
      "975-th loss is : 0.42499\n",
      "976-th loss is : 0.773354\n",
      "977-th loss is : 0.519804\n",
      "978-th loss is : 0.954895\n",
      "979-th loss is : 0.616976\n",
      "980-th loss is : 1.37486\n",
      "981-th loss is : 1.34251\n",
      "982-th loss is : 0.663517\n",
      "983-th loss is : 0.418289\n",
      "984-th loss is : 0.575517\n",
      "985-th loss is : 0.583607\n",
      "986-th loss is : 1.7038\n",
      "987-th loss is : 1.40232\n",
      "988-th loss is : 1.80929\n",
      "989-th loss is : 1.29675\n",
      "990-th loss is : 0.83726\n",
      "991-th loss is : 1.83439\n",
      "992-th loss is : 0.381561\n",
      "993-th loss is : 1.44689\n",
      "994-th loss is : 1.32913\n",
      "995-th loss is : 0.401388\n",
      "996-th loss is : 0.467177\n",
      "997-th loss is : 0.515002\n",
      "998-th loss is : 0.807913\n",
      "999-th loss is : 1.60804\n",
      "1000-th loss is : 1.01455\n",
      "1001-th loss is : 0.359863\n",
      "1002-th loss is : 0.980522\n",
      "1003-th loss is : 1.19744\n",
      "1004-th loss is : 0.771633\n",
      "1005-th loss is : 0.956486\n",
      "1006-th loss is : 0.486473\n",
      "1007-th loss is : 1.54523\n",
      "1008-th loss is : 0.362325\n",
      "1009-th loss is : 0.785948\n",
      "1010-th loss is : 0.311022\n",
      "1011-th loss is : 1.17798\n",
      "1012-th loss is : 0.34259\n",
      "1013-th loss is : 0.349202\n",
      "1014-th loss is : 0.927849\n",
      "1015-th loss is : 1.48409\n",
      "1016-th loss is : 0.457114\n",
      "1017-th loss is : 0.419567\n",
      "1018-th loss is : 1.36329\n",
      "1019-th loss is : 1.3038\n",
      "1020-th loss is : 0.430525\n",
      "1021-th loss is : 1.47318\n",
      "1022-th loss is : 0.489656\n",
      "1023-th loss is : 1.20879\n",
      "1024-th loss is : 1.45909\n",
      "1025-th loss is : 1.05218\n",
      "1026-th loss is : 1.29109\n",
      "1027-th loss is : 0.52299\n",
      "1028-th loss is : 0.776363\n",
      "1029-th loss is : 1.61329\n",
      "1030-th loss is : 0.78622\n",
      "1031-th loss is : 0.585666\n",
      "1032-th loss is : 0.781841\n",
      "1033-th loss is : 1.11829\n",
      "1034-th loss is : 0.994105\n",
      "1035-th loss is : 0.574055\n",
      "1036-th loss is : 0.950863\n",
      "1037-th loss is : 0.505158\n",
      "1038-th loss is : 0.360792\n",
      "1039-th loss is : 0.656222\n",
      "1040-th loss is : 0.58765\n",
      "1041-th loss is : 0.62258\n",
      "1042-th loss is : 0.958532\n",
      "1043-th loss is : 0.426839\n",
      "1044-th loss is : 1.20261\n",
      "1045-th loss is : 0.443956\n",
      "1046-th loss is : 0.391911\n",
      "1047-th loss is : 0.35471\n",
      "1048-th loss is : 0.537227\n",
      "1049-th loss is : 0.877729\n",
      "1050-th loss is : 1.69307\n",
      "1051-th loss is : 0.638789\n",
      "1052-th loss is : 0.941026\n",
      "1053-th loss is : 1.34649\n",
      "1054-th loss is : 0.68327\n",
      "1055-th loss is : 0.468763\n",
      "1056-th loss is : 0.35297\n",
      "1057-th loss is : 0.607234\n",
      "1058-th loss is : 1.54067\n",
      "1059-th loss is : 1.03363\n",
      "1060-th loss is : 0.855003\n",
      "1061-th loss is : 1.46943\n",
      "1062-th loss is : 0.614234\n",
      "1063-th loss is : 1.49988\n",
      "1064-th loss is : 0.629033\n",
      "1065-th loss is : 1.666\n",
      "1066-th loss is : 0.335036\n",
      "1067-th loss is : 1.06743\n",
      "1068-th loss is : 0.551905\n",
      "1069-th loss is : 0.527344\n",
      "1070-th loss is : 0.299695\n",
      "1071-th loss is : 1.3117\n",
      "1072-th loss is : 1.13209\n",
      "1073-th loss is : 0.498872\n",
      "1074-th loss is : 1.21937\n",
      "1075-th loss is : 0.367163\n",
      "1076-th loss is : 0.817271\n",
      "1077-th loss is : 0.926186\n",
      "1078-th loss is : 0.294218\n",
      "1079-th loss is : 1.57876\n",
      "1080-th loss is : 0.424567\n",
      "1081-th loss is : 1.21446\n",
      "1082-th loss is : 1.55147\n",
      "1083-th loss is : 1.43466\n",
      "1084-th loss is : 1.78576\n",
      "1085-th loss is : 1.69128\n",
      "1086-th loss is : 1.15728\n",
      "1087-th loss is : 0.477302\n",
      "1088-th loss is : 0.449259\n",
      "1089-th loss is : 0.663804\n",
      "1090-th loss is : 0.716804\n",
      "1091-th loss is : 0.321594\n",
      "1092-th loss is : 0.347691\n",
      "1093-th loss is : 1.18922\n",
      "1094-th loss is : 0.575544\n",
      "1095-th loss is : 1.63161\n",
      "1096-th loss is : 1.33305\n",
      "1097-th loss is : 0.310933\n",
      "1098-th loss is : 0.562993\n",
      "1099-th loss is : 0.628182\n",
      "1100-th loss is : 1.026\n",
      "1101-th loss is : 0.77932\n",
      "1102-th loss is : 0.345698\n",
      "1103-th loss is : 0.491565\n",
      "1104-th loss is : 1.26647\n",
      "1105-th loss is : 0.341052\n",
      "1106-th loss is : 0.529777\n",
      "1107-th loss is : 0.508921\n",
      "1108-th loss is : 0.533248\n",
      "1109-th loss is : 1.08751\n",
      "1110-th loss is : 1.00044\n",
      "1111-th loss is : 1.3989\n",
      "1112-th loss is : 1.65502\n",
      "1113-th loss is : 0.881677\n",
      "1114-th loss is : 0.861108\n",
      "1115-th loss is : 0.500716\n",
      "1116-th loss is : 0.776527\n",
      "1117-th loss is : 1.66831\n",
      "1118-th loss is : 1.76746\n",
      "1119-th loss is : 0.652587\n",
      "1120-th loss is : 0.29177\n",
      "1121-th loss is : 1.42623\n",
      "1122-th loss is : 1.21849\n",
      "1123-th loss is : 1.41522\n",
      "1124-th loss is : 0.90783\n",
      "1125-th loss is : 0.363832\n",
      "1126-th loss is : 0.342633\n",
      "1127-th loss is : 0.915927\n",
      "1128-th loss is : 0.441593\n",
      "1129-th loss is : 0.817439\n",
      "1130-th loss is : 0.744055\n",
      "1131-th loss is : 0.353563\n",
      "1132-th loss is : 0.925901\n",
      "1133-th loss is : 1.17453\n",
      "1134-th loss is : 1.09261\n",
      "1135-th loss is : 1.09974\n",
      "1136-th loss is : 0.668413\n",
      "1137-th loss is : 0.352782\n",
      "1138-th loss is : 0.733799\n",
      "1139-th loss is : 0.282657\n",
      "1140-th loss is : 0.934093\n",
      "1141-th loss is : 0.881884\n",
      "1142-th loss is : 1.54629\n",
      "1143-th loss is : 0.389436\n",
      "1144-th loss is : 0.283154\n",
      "1145-th loss is : 1.42126\n",
      "1146-th loss is : 1.30433\n",
      "1147-th loss is : 1.17621\n",
      "1148-th loss is : 1.71971\n",
      "1149-th loss is : 0.430067\n",
      "1150-th loss is : 0.92313\n",
      "1151-th loss is : 0.626607\n",
      "1152-th loss is : 1.02538\n",
      "1153-th loss is : 0.442569\n",
      "1154-th loss is : 1.67873\n",
      "1155-th loss is : 1.12651\n",
      "1156-th loss is : 0.317889\n",
      "1157-th loss is : 0.595216\n",
      "1158-th loss is : 0.603395\n",
      "1159-th loss is : 0.451747\n",
      "1160-th loss is : 1.71808\n",
      "1161-th loss is : 1.21991\n",
      "1162-th loss is : 0.965377\n",
      "1163-th loss is : 1.08412\n",
      "1164-th loss is : 0.503759\n",
      "1165-th loss is : 0.666438\n",
      "1166-th loss is : 0.301298\n",
      "1167-th loss is : 1.28424\n",
      "1168-th loss is : 1.61664\n",
      "1169-th loss is : 1.39699\n",
      "1170-th loss is : 0.471747\n",
      "1171-th loss is : 0.319912\n",
      "1172-th loss is : 1.35806\n",
      "1173-th loss is : 1.47553\n",
      "1174-th loss is : 1.20122\n",
      "1175-th loss is : 0.679738\n",
      "1176-th loss is : 0.804335\n",
      "1177-th loss is : 1.18434\n",
      "1178-th loss is : 0.730778\n",
      "1179-th loss is : 0.728645\n",
      "1180-th loss is : 0.314244\n",
      "1181-th loss is : 1.65151\n",
      "1182-th loss is : 1.66114\n",
      "1183-th loss is : 0.408933\n",
      "1184-th loss is : 0.278963\n",
      "1185-th loss is : 1.45409\n",
      "1186-th loss is : 0.96966\n",
      "1187-th loss is : 0.655368\n",
      "1188-th loss is : 0.865831\n",
      "1189-th loss is : 0.642457\n",
      "1190-th loss is : 1.11479\n",
      "1191-th loss is : 0.38171\n",
      "1192-th loss is : 1.08715\n",
      "1193-th loss is : 0.72997\n",
      "1194-th loss is : 1.36092\n",
      "1195-th loss is : 0.592757\n",
      "1196-th loss is : 0.285655\n",
      "1197-th loss is : 1.28352\n",
      "1198-th loss is : 0.708493\n",
      "1199-th loss is : 0.420426\n",
      "1200-th loss is : 1.46906\n",
      "1201-th loss is : 0.316856\n",
      "1202-th loss is : 1.28777\n",
      "1203-th loss is : 0.989117\n",
      "1204-th loss is : 0.286353\n",
      "1205-th loss is : 0.673697\n",
      "1206-th loss is : 1.44786\n",
      "1207-th loss is : 0.4114\n",
      "1208-th loss is : 0.728755\n",
      "1209-th loss is : 0.420302\n",
      "1210-th loss is : 0.279156\n",
      "1211-th loss is : 0.640908\n",
      "1212-th loss is : 0.930822\n",
      "1213-th loss is : 0.324185\n",
      "1214-th loss is : 0.569154\n",
      "1215-th loss is : 0.749898\n",
      "1216-th loss is : 1.19074\n",
      "1217-th loss is : 0.710184\n",
      "1218-th loss is : 1.53239\n",
      "1219-th loss is : 0.878829\n",
      "1220-th loss is : 0.942099\n",
      "1221-th loss is : 0.445136\n",
      "1222-th loss is : 1.44607\n",
      "1223-th loss is : 1.21682\n",
      "1224-th loss is : 0.526157\n",
      "1225-th loss is : 0.445983\n",
      "1226-th loss is : 1.26514\n",
      "1227-th loss is : 1.44018\n",
      "1228-th loss is : 0.71174\n",
      "1229-th loss is : 0.41476\n",
      "1230-th loss is : 0.680509\n",
      "1231-th loss is : 0.814715\n",
      "1232-th loss is : 0.764391\n",
      "1233-th loss is : 1.45579\n",
      "1234-th loss is : 0.702532\n",
      "1235-th loss is : 0.693521\n",
      "1236-th loss is : 0.822933\n",
      "1237-th loss is : 0.454466\n",
      "1238-th loss is : 0.920937\n",
      "1239-th loss is : 0.601138\n",
      "1240-th loss is : 0.891391\n",
      "1241-th loss is : 1.04876\n",
      "1242-th loss is : 0.552501\n",
      "1243-th loss is : 0.691802\n",
      "1244-th loss is : 1.11469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245-th loss is : 0.44813\n",
      "1246-th loss is : 0.506463\n",
      "1247-th loss is : 1.27612\n",
      "1248-th loss is : 1.29266\n",
      "1249-th loss is : 0.772476\n",
      "1250-th loss is : 0.747594\n",
      "1251-th loss is : 1.57312\n",
      "1252-th loss is : 1.01483\n",
      "1253-th loss is : 0.457808\n",
      "1254-th loss is : 0.36467\n",
      "1255-th loss is : 1.18564\n",
      "1256-th loss is : 0.645699\n",
      "1257-th loss is : 0.348941\n",
      "1258-th loss is : 0.351166\n",
      "1259-th loss is : 0.5255\n",
      "1260-th loss is : 1.62406\n",
      "1261-th loss is : 0.51112\n",
      "1262-th loss is : 0.899167\n",
      "1263-th loss is : 1.59329\n",
      "1264-th loss is : 0.384901\n",
      "1265-th loss is : 0.331706\n",
      "1266-th loss is : 0.893038\n",
      "1267-th loss is : 1.18173\n",
      "1268-th loss is : 1.2928\n",
      "1269-th loss is : 1.05296\n",
      "1270-th loss is : 0.695664\n",
      "1271-th loss is : 0.438704\n",
      "1272-th loss is : 0.93733\n",
      "1273-th loss is : 0.573758\n",
      "1274-th loss is : 0.678834\n",
      "1275-th loss is : 0.306492\n",
      "1276-th loss is : 0.373575\n",
      "1277-th loss is : 0.727306\n",
      "1278-th loss is : 0.658997\n",
      "1279-th loss is : 1.53899\n",
      "1280-th loss is : 0.989115\n",
      "1281-th loss is : 0.958384\n",
      "1282-th loss is : 1.52974\n",
      "1283-th loss is : 0.555489\n",
      "1284-th loss is : 1.01872\n",
      "1285-th loss is : 0.528033\n",
      "1286-th loss is : 1.07074\n",
      "1287-th loss is : 1.5307\n",
      "1288-th loss is : 0.55817\n",
      "1289-th loss is : 1.15784\n",
      "1290-th loss is : 0.561141\n",
      "1291-th loss is : 1.13895\n",
      "1292-th loss is : 0.98968\n",
      "1293-th loss is : 0.476019\n",
      "1294-th loss is : 0.913688\n",
      "1295-th loss is : 0.703357\n",
      "1296-th loss is : 0.643571\n",
      "1297-th loss is : 0.354247\n",
      "1298-th loss is : 0.546297\n",
      "1299-th loss is : 0.377836\n",
      "1300-th loss is : 1.19948\n",
      "1301-th loss is : 1.08442\n",
      "1302-th loss is : 0.604192\n",
      "1303-th loss is : 0.499369\n",
      "1304-th loss is : 1.08999\n",
      "1305-th loss is : 0.475019\n",
      "1306-th loss is : 1.06369\n",
      "1307-th loss is : 0.660195\n",
      "1308-th loss is : 0.850322\n",
      "1309-th loss is : 0.856795\n",
      "1310-th loss is : 0.355428\n",
      "1311-th loss is : 0.472983\n",
      "1312-th loss is : 1.08585\n",
      "1313-th loss is : 0.389989\n",
      "1314-th loss is : 0.45564\n",
      "1315-th loss is : 0.500261\n",
      "1316-th loss is : 0.982215\n",
      "1317-th loss is : 1.37013\n",
      "1318-th loss is : 1.31768\n",
      "1319-th loss is : 0.522925\n",
      "1320-th loss is : 1.50163\n",
      "1321-th loss is : 0.486639\n",
      "1322-th loss is : 1.06625\n",
      "1323-th loss is : 0.610516\n",
      "1324-th loss is : 0.383732\n",
      "1325-th loss is : 0.255938\n",
      "1326-th loss is : 1.36874\n",
      "1327-th loss is : 0.247593\n",
      "1328-th loss is : 1.2269\n",
      "1329-th loss is : 1.14374\n",
      "1330-th loss is : 0.457449\n",
      "1331-th loss is : 0.794643\n",
      "1332-th loss is : 0.567731\n",
      "1333-th loss is : 0.270256\n",
      "1334-th loss is : 0.790793\n",
      "1335-th loss is : 0.413835\n",
      "1336-th loss is : 0.349456\n",
      "1337-th loss is : 1.17226\n",
      "1338-th loss is : 0.923424\n",
      "1339-th loss is : 0.365391\n",
      "1340-th loss is : 0.837667\n",
      "1341-th loss is : 0.40532\n",
      "1342-th loss is : 1.59151\n",
      "1343-th loss is : 1.00972\n",
      "1344-th loss is : 0.502454\n",
      "1345-th loss is : 0.869527\n",
      "1346-th loss is : 0.961387\n",
      "1347-th loss is : 1.39067\n",
      "1348-th loss is : 1.14962\n",
      "1349-th loss is : 0.277343\n",
      "1350-th loss is : 1.39318\n",
      "1351-th loss is : 0.63849\n",
      "1352-th loss is : 0.304894\n",
      "1353-th loss is : 0.423507\n",
      "1354-th loss is : 0.263557\n",
      "1355-th loss is : 0.747266\n",
      "1356-th loss is : 0.373102\n",
      "1357-th loss is : 0.700867\n",
      "1358-th loss is : 1.25329\n",
      "1359-th loss is : 0.282101\n",
      "1360-th loss is : 0.651549\n",
      "1361-th loss is : 0.928207\n",
      "1362-th loss is : 0.7555\n",
      "1363-th loss is : 0.881855\n",
      "1364-th loss is : 0.354547\n",
      "1365-th loss is : 1.49485\n",
      "1366-th loss is : 1.48387\n",
      "1367-th loss is : 0.741842\n",
      "1368-th loss is : 0.760735\n",
      "1369-th loss is : 1.29532\n",
      "1370-th loss is : 1.41303\n",
      "1371-th loss is : 0.277102\n",
      "1372-th loss is : 0.75631\n",
      "1373-th loss is : 1.18963\n",
      "1374-th loss is : 0.290512\n",
      "1375-th loss is : 1.08466\n",
      "1376-th loss is : 0.66848\n",
      "1377-th loss is : 0.388765\n",
      "1378-th loss is : 0.423738\n",
      "1379-th loss is : 0.871056\n",
      "1380-th loss is : 1.40111\n",
      "1381-th loss is : 1.12185\n",
      "1382-th loss is : 0.264532\n",
      "1383-th loss is : 0.322864\n",
      "1384-th loss is : 1.12464\n",
      "1385-th loss is : 0.71875\n",
      "1386-th loss is : 0.310093\n",
      "1387-th loss is : 1.52177\n",
      "1388-th loss is : 0.568281\n",
      "1389-th loss is : 1.27953\n",
      "1390-th loss is : 0.539082\n",
      "1391-th loss is : 0.248424\n",
      "1392-th loss is : 0.878907\n",
      "1393-th loss is : 1.04998\n",
      "1394-th loss is : 0.675651\n",
      "1395-th loss is : 1.1607\n",
      "1396-th loss is : 0.361726\n",
      "1397-th loss is : 1.26324\n",
      "1398-th loss is : 0.446003\n",
      "1399-th loss is : 0.425387\n",
      "1400-th loss is : 1.37215\n",
      "1401-th loss is : 0.730155\n",
      "1402-th loss is : 1.50692\n",
      "1403-th loss is : 0.411916\n",
      "1404-th loss is : 1.068\n",
      "1405-th loss is : 1.47848\n",
      "1406-th loss is : 0.606351\n",
      "1407-th loss is : 0.966571\n",
      "1408-th loss is : 0.460882\n",
      "1409-th loss is : 1.0765\n",
      "1410-th loss is : 1.10576\n",
      "1411-th loss is : 0.243142\n",
      "1412-th loss is : 0.4071\n",
      "1413-th loss is : 0.514948\n",
      "1414-th loss is : 0.7138\n",
      "1415-th loss is : 1.10418\n",
      "1416-th loss is : 0.882223\n",
      "1417-th loss is : 0.267283\n",
      "1418-th loss is : 0.984693\n",
      "1419-th loss is : 0.883182\n",
      "1420-th loss is : 0.65741\n",
      "1421-th loss is : 1.51618\n",
      "1422-th loss is : 1.04179\n",
      "1423-th loss is : 1.52897\n",
      "1424-th loss is : 1.21925\n",
      "1425-th loss is : 0.645073\n",
      "1426-th loss is : 0.536583\n",
      "1427-th loss is : 0.255711\n",
      "1428-th loss is : 0.301528\n",
      "1429-th loss is : 0.96826\n",
      "1430-th loss is : 0.588141\n",
      "1431-th loss is : 0.332972\n",
      "1432-th loss is : 1.50684\n",
      "1433-th loss is : 1.28718\n",
      "1434-th loss is : 0.236615\n",
      "1435-th loss is : 0.28192\n",
      "1436-th loss is : 0.257277\n",
      "1437-th loss is : 1.28513\n",
      "1438-th loss is : 1.37156\n",
      "1439-th loss is : 0.301464\n",
      "1440-th loss is : 0.818394\n",
      "1441-th loss is : 0.606584\n",
      "1442-th loss is : 1.53653\n",
      "1443-th loss is : 0.646734\n",
      "1444-th loss is : 1.06513\n",
      "1445-th loss is : 0.23396\n",
      "1446-th loss is : 1.08665\n",
      "1447-th loss is : 0.401877\n",
      "1448-th loss is : 0.472017\n",
      "1449-th loss is : 1.21207\n",
      "1450-th loss is : 0.989103\n",
      "1451-th loss is : 0.927564\n",
      "1452-th loss is : 0.407502\n",
      "1453-th loss is : 0.497985\n",
      "1454-th loss is : 0.744324\n",
      "1455-th loss is : 1.13761\n",
      "1456-th loss is : 0.557981\n",
      "1457-th loss is : 1.32812\n",
      "1458-th loss is : 0.837921\n",
      "1459-th loss is : 0.88248\n",
      "1460-th loss is : 0.405329\n",
      "1461-th loss is : 1.51029\n",
      "1462-th loss is : 1.31051\n",
      "1463-th loss is : 0.693041\n",
      "1464-th loss is : 1.39206\n",
      "1465-th loss is : 0.857995\n",
      "1466-th loss is : 0.813011\n",
      "1467-th loss is : 0.674101\n",
      "1468-th loss is : 0.768314\n",
      "1469-th loss is : 0.594994\n",
      "1470-th loss is : 0.714754\n",
      "1471-th loss is : 0.826905\n",
      "1472-th loss is : 0.233642\n",
      "1473-th loss is : 0.798018\n",
      "1474-th loss is : 1.35424\n",
      "1475-th loss is : 1.47183\n",
      "1476-th loss is : 0.692671\n",
      "1477-th loss is : 0.799378\n",
      "1478-th loss is : 0.367842\n",
      "1479-th loss is : 0.642878\n",
      "1480-th loss is : 0.474822\n",
      "1481-th loss is : 0.998837\n",
      "1482-th loss is : 1.21034\n",
      "1483-th loss is : 1.49073\n",
      "1484-th loss is : 0.274745\n",
      "1485-th loss is : 0.912373\n",
      "1486-th loss is : 1.1901\n",
      "1487-th loss is : 0.279554\n",
      "1488-th loss is : 1.50705\n",
      "1489-th loss is : 0.219954\n",
      "1490-th loss is : 0.829895\n",
      "1491-th loss is : 0.36081\n",
      "1492-th loss is : 1.14675\n",
      "1493-th loss is : 0.533513\n",
      "1494-th loss is : 0.303061\n",
      "1495-th loss is : 0.379958\n",
      "1496-th loss is : 1.17626\n",
      "1497-th loss is : 0.533709\n",
      "1498-th loss is : 0.488915\n",
      "1499-th loss is : 0.348403\n",
      "1500-th loss is : 0.367551\n",
      "1501-th loss is : 0.349814\n",
      "1502-th loss is : 0.973824\n",
      "1503-th loss is : 0.232189\n",
      "1504-th loss is : 0.606177\n",
      "1505-th loss is : 0.481273\n",
      "1506-th loss is : 0.367098\n",
      "1507-th loss is : 0.756702\n",
      "1508-th loss is : 0.413209\n",
      "1509-th loss is : 0.889927\n",
      "1510-th loss is : 1.11366\n",
      "1511-th loss is : 0.891224\n",
      "1512-th loss is : 1.34081\n",
      "1513-th loss is : 1.21069\n",
      "1514-th loss is : 0.320908\n",
      "1515-th loss is : 0.672385\n",
      "1516-th loss is : 1.12817\n",
      "1517-th loss is : 1.31681\n",
      "1518-th loss is : 1.20877\n",
      "1519-th loss is : 0.379232\n",
      "1520-th loss is : 1.45419\n",
      "1521-th loss is : 0.352366\n",
      "1522-th loss is : 0.259377\n",
      "1523-th loss is : 1.2288\n",
      "1524-th loss is : 1.22954\n",
      "1525-th loss is : 0.566439\n",
      "1526-th loss is : 1.47737\n",
      "1527-th loss is : 0.264379\n",
      "1528-th loss is : 1.45376\n",
      "1529-th loss is : 0.253113\n",
      "1530-th loss is : 0.888702\n",
      "1531-th loss is : 0.804013\n",
      "1532-th loss is : 0.923764\n",
      "1533-th loss is : 1.29254\n",
      "1534-th loss is : 1.00107\n",
      "1535-th loss is : 0.742753\n",
      "1536-th loss is : 0.705974\n",
      "1537-th loss is : 1.28596\n",
      "1538-th loss is : 1.4442\n",
      "1539-th loss is : 0.340421\n",
      "1540-th loss is : 0.279341\n",
      "1541-th loss is : 0.780612\n",
      "1542-th loss is : 0.685471\n",
      "1543-th loss is : 0.606451\n",
      "1544-th loss is : 0.358621\n",
      "1545-th loss is : 0.899211\n",
      "1546-th loss is : 0.766094\n",
      "1547-th loss is : 0.372615\n",
      "1548-th loss is : 0.463854\n",
      "1549-th loss is : 1.22958\n",
      "1550-th loss is : 0.927566\n",
      "1551-th loss is : 0.741598\n",
      "1552-th loss is : 0.561123\n",
      "1553-th loss is : 0.983359\n",
      "1554-th loss is : 0.743823\n",
      "1555-th loss is : 1.10603\n",
      "1556-th loss is : 1.12102\n",
      "1557-th loss is : 1.37147\n",
      "1558-th loss is : 0.290724\n",
      "1559-th loss is : 1.37589\n",
      "1560-th loss is : 0.531261\n",
      "1561-th loss is : 0.493326\n",
      "1562-th loss is : 1.24436\n",
      "1563-th loss is : 0.520649\n",
      "1564-th loss is : 1.14233\n",
      "1565-th loss is : 1.23454\n",
      "1566-th loss is : 1.39094\n",
      "1567-th loss is : 0.271974\n",
      "1568-th loss is : 0.35261\n",
      "1569-th loss is : 0.538118\n",
      "1570-th loss is : 1.25527\n",
      "1571-th loss is : 0.376718\n",
      "1572-th loss is : 1.04172\n",
      "1573-th loss is : 0.327606\n",
      "1574-th loss is : 0.320869\n",
      "1575-th loss is : 0.422216\n",
      "1576-th loss is : 0.848682\n",
      "1577-th loss is : 0.835672\n",
      "1578-th loss is : 0.933319\n",
      "1579-th loss is : 1.09129\n",
      "1580-th loss is : 0.288143\n",
      "1581-th loss is : 0.280375\n",
      "1582-th loss is : 0.561749\n",
      "1583-th loss is : 0.703714\n",
      "1584-th loss is : 1.37467\n",
      "1585-th loss is : 1.18126\n",
      "1586-th loss is : 0.296642\n",
      "1587-th loss is : 0.523468\n",
      "1588-th loss is : 0.733329\n",
      "1589-th loss is : 1.13063\n",
      "1590-th loss is : 0.541843\n",
      "1591-th loss is : 0.310487\n",
      "1592-th loss is : 1.32169\n",
      "1593-th loss is : 0.762125\n",
      "1594-th loss is : 0.669475\n",
      "1595-th loss is : 1.03751\n",
      "1596-th loss is : 0.883246\n",
      "1597-th loss is : 1.13911\n",
      "1598-th loss is : 0.833249\n",
      "1599-th loss is : 1.2285\n",
      "1600-th loss is : 0.284343\n",
      "1601-th loss is : 0.57778\n",
      "1602-th loss is : 0.884179\n",
      "1603-th loss is : 0.549852\n",
      "1604-th loss is : 0.259475\n",
      "1605-th loss is : 0.500323\n",
      "1606-th loss is : 0.872639\n",
      "1607-th loss is : 1.34639\n",
      "1608-th loss is : 0.660647\n",
      "1609-th loss is : 1.36742\n",
      "1610-th loss is : 0.269536\n",
      "1611-th loss is : 0.223943\n",
      "1612-th loss is : 0.80562\n",
      "1613-th loss is : 0.401416\n",
      "1614-th loss is : 0.569507\n",
      "1615-th loss is : 0.422912\n",
      "1616-th loss is : 0.739569\n",
      "1617-th loss is : 1.25779\n",
      "1618-th loss is : 0.556398\n",
      "1619-th loss is : 0.787289\n",
      "1620-th loss is : 1.23621\n",
      "1621-th loss is : 0.300998\n",
      "1622-th loss is : 0.719343\n",
      "1623-th loss is : 0.984882\n",
      "1624-th loss is : 0.528666\n",
      "1625-th loss is : 0.602016\n",
      "1626-th loss is : 0.3215\n",
      "1627-th loss is : 0.429546\n",
      "1628-th loss is : 0.840362\n",
      "1629-th loss is : 1.33572\n",
      "1630-th loss is : 0.245918\n",
      "1631-th loss is : 0.747892\n",
      "1632-th loss is : 0.792512\n",
      "1633-th loss is : 0.625516\n",
      "1634-th loss is : 1.07617\n",
      "1635-th loss is : 0.230788\n",
      "1636-th loss is : 1.14322\n",
      "1637-th loss is : 0.720824\n",
      "1638-th loss is : 0.510302\n",
      "1639-th loss is : 0.940783\n",
      "1640-th loss is : 0.78137\n",
      "1641-th loss is : 0.754871\n",
      "1642-th loss is : 1.32163\n",
      "1643-th loss is : 0.227317\n",
      "1644-th loss is : 1.18701\n",
      "1645-th loss is : 0.351622\n",
      "1646-th loss is : 1.03668\n",
      "1647-th loss is : 0.833787\n",
      "1648-th loss is : 1.311\n",
      "1649-th loss is : 0.261769\n",
      "1650-th loss is : 0.700329\n",
      "1651-th loss is : 0.371706\n",
      "1652-th loss is : 0.743422\n",
      "1653-th loss is : 0.595612\n",
      "1654-th loss is : 1.25754\n",
      "1655-th loss is : 0.554386\n",
      "1656-th loss is : 1.35373\n",
      "1657-th loss is : 0.556131\n",
      "1658-th loss is : 0.655048\n",
      "1659-th loss is : 0.342185\n",
      "1660-th loss is : 0.253765\n",
      "1661-th loss is : 0.212607\n",
      "1662-th loss is : 0.518171\n",
      "1663-th loss is : 0.896542\n",
      "1664-th loss is : 0.267012\n",
      "1665-th loss is : 0.209116\n",
      "1666-th loss is : 1.0681\n",
      "1667-th loss is : 0.772856\n",
      "1668-th loss is : 1.1982\n",
      "1669-th loss is : 0.471289\n",
      "1670-th loss is : 0.94732\n",
      "1671-th loss is : 1.03123\n",
      "1672-th loss is : 0.818926\n",
      "1673-th loss is : 0.663778\n",
      "1674-th loss is : 0.422549\n",
      "1675-th loss is : 0.828885\n",
      "1676-th loss is : 0.849198\n",
      "1677-th loss is : 0.777594\n",
      "1678-th loss is : 1.08443\n",
      "1679-th loss is : 0.462084\n",
      "1680-th loss is : 0.198049\n",
      "1681-th loss is : 0.300458\n",
      "1682-th loss is : 0.3701\n",
      "1683-th loss is : 0.199349\n",
      "1684-th loss is : 0.527367\n",
      "1685-th loss is : 0.236345\n",
      "1686-th loss is : 0.755277\n",
      "1687-th loss is : 0.680928\n",
      "1688-th loss is : 0.376082\n",
      "1689-th loss is : 1.05762\n",
      "1690-th loss is : 0.843065\n",
      "1691-th loss is : 1.25118\n",
      "1692-th loss is : 0.462024\n",
      "1693-th loss is : 1.28053\n",
      "1694-th loss is : 0.47599\n",
      "1695-th loss is : 0.192119\n",
      "1696-th loss is : 0.497977\n",
      "1697-th loss is : 0.371325\n",
      "1698-th loss is : 0.653846\n",
      "1699-th loss is : 0.38848\n",
      "1700-th loss is : 0.257257\n",
      "1701-th loss is : 1.11638\n",
      "1702-th loss is : 0.674224\n",
      "1703-th loss is : 1.33388\n",
      "1704-th loss is : 1.34598\n",
      "1705-th loss is : 0.807884\n",
      "1706-th loss is : 0.417727\n",
      "1707-th loss is : 0.548302\n",
      "1708-th loss is : 0.502162\n",
      "1709-th loss is : 0.778395\n",
      "1710-th loss is : 0.986193\n",
      "1711-th loss is : 0.942612\n",
      "1712-th loss is : 0.244667\n",
      "1713-th loss is : 0.494162\n",
      "1714-th loss is : 0.385012\n",
      "1715-th loss is : 0.269652\n",
      "1716-th loss is : 1.283\n",
      "1717-th loss is : 1.16499\n",
      "1718-th loss is : 0.977493\n",
      "1719-th loss is : 1.1439\n",
      "1720-th loss is : 0.770703\n",
      "1721-th loss is : 0.659357\n",
      "1722-th loss is : 0.671689\n",
      "1723-th loss is : 0.268954\n",
      "1724-th loss is : 0.524482\n",
      "1725-th loss is : 0.227306\n",
      "1726-th loss is : 0.509986\n",
      "1727-th loss is : 1.05382\n",
      "1728-th loss is : 1.27137\n",
      "1729-th loss is : 0.467865\n",
      "1730-th loss is : 1.13522\n",
      "1731-th loss is : 0.307029\n",
      "1732-th loss is : 0.806292\n",
      "1733-th loss is : 0.700676\n",
      "1734-th loss is : 0.346561\n",
      "1735-th loss is : 1.28024\n",
      "1736-th loss is : 1.17875\n",
      "1737-th loss is : 0.649008\n",
      "1738-th loss is : 0.730497\n",
      "1739-th loss is : 1.02957\n",
      "1740-th loss is : 0.698565\n",
      "1741-th loss is : 0.317006\n",
      "1742-th loss is : 1.14369\n",
      "1743-th loss is : 0.197755\n",
      "1744-th loss is : 0.839488\n",
      "1745-th loss is : 0.87146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1746-th loss is : 0.672693\n",
      "1747-th loss is : 1.17485\n",
      "1748-th loss is : 0.814681\n",
      "1749-th loss is : 0.44023\n",
      "1750-th loss is : 0.24807\n",
      "1751-th loss is : 1.30432\n",
      "1752-th loss is : 0.75862\n",
      "1753-th loss is : 0.898025\n",
      "1754-th loss is : 0.75521\n",
      "1755-th loss is : 0.414681\n",
      "1756-th loss is : 0.538499\n",
      "1757-th loss is : 1.30646\n",
      "1758-th loss is : 0.401806\n",
      "1759-th loss is : 0.888631\n",
      "1760-th loss is : 0.882691\n",
      "1761-th loss is : 0.563394\n",
      "1762-th loss is : 0.473005\n",
      "1763-th loss is : 0.434443\n",
      "1764-th loss is : 0.911231\n",
      "1765-th loss is : 1.24944\n",
      "1766-th loss is : 0.470202\n",
      "1767-th loss is : 1.16774\n",
      "1768-th loss is : 0.568337\n",
      "1769-th loss is : 0.939418\n",
      "1770-th loss is : 0.774902\n",
      "1771-th loss is : 1.04967\n",
      "1772-th loss is : 0.76625\n",
      "1773-th loss is : 0.719468\n",
      "1774-th loss is : 0.46224\n",
      "1775-th loss is : 0.815955\n",
      "1776-th loss is : 0.521322\n",
      "1777-th loss is : 0.223682\n",
      "1778-th loss is : 0.780826\n",
      "1779-th loss is : 0.893865\n",
      "1780-th loss is : 1.25256\n",
      "1781-th loss is : 0.190832\n",
      "1782-th loss is : 0.528726\n",
      "1783-th loss is : 0.231991\n",
      "1784-th loss is : 0.51274\n",
      "1785-th loss is : 0.462951\n",
      "1786-th loss is : 0.902888\n",
      "1787-th loss is : 0.875768\n",
      "1788-th loss is : 0.182872\n",
      "1789-th loss is : 1.08864\n",
      "1790-th loss is : 1.31777\n",
      "1791-th loss is : 0.428265\n",
      "1792-th loss is : 1.05354\n",
      "1793-th loss is : 0.734306\n",
      "1794-th loss is : 0.288984\n",
      "1795-th loss is : 1.22237\n",
      "1796-th loss is : 1.02956\n",
      "1797-th loss is : 0.415469\n",
      "1798-th loss is : 0.713261\n",
      "1799-th loss is : 0.419017\n",
      "1800-th loss is : 0.438768\n",
      "1801-th loss is : 0.398332\n",
      "1802-th loss is : 0.782219\n",
      "1803-th loss is : 0.256158\n",
      "1804-th loss is : 0.698047\n",
      "1805-th loss is : 0.428659\n",
      "1806-th loss is : 0.560317\n",
      "1807-th loss is : 0.184406\n",
      "1808-th loss is : 0.219747\n",
      "1809-th loss is : 0.247927\n",
      "1810-th loss is : 0.364113\n",
      "1811-th loss is : 0.387825\n",
      "1812-th loss is : 1.05346\n",
      "1813-th loss is : 0.585358\n",
      "1814-th loss is : 0.343706\n",
      "1815-th loss is : 1.12314\n",
      "1816-th loss is : 0.224424\n",
      "1817-th loss is : 1.21694\n",
      "1818-th loss is : 0.226316\n",
      "1819-th loss is : 0.464092\n",
      "1820-th loss is : 0.924699\n",
      "1821-th loss is : 1.02919\n",
      "1822-th loss is : 1.21131\n",
      "1823-th loss is : 0.621425\n",
      "1824-th loss is : 0.17944\n",
      "1825-th loss is : 0.29989\n",
      "1826-th loss is : 0.386221\n",
      "1827-th loss is : 0.464048\n",
      "1828-th loss is : 0.238086\n",
      "1829-th loss is : 0.99654\n",
      "1830-th loss is : 0.404349\n",
      "1831-th loss is : 0.526136\n",
      "1832-th loss is : 0.833071\n",
      "1833-th loss is : 1.2632\n",
      "1834-th loss is : 0.30321\n",
      "1835-th loss is : 0.989823\n",
      "1836-th loss is : 1.06082\n",
      "1837-th loss is : 0.355598\n",
      "1838-th loss is : 0.945226\n",
      "1839-th loss is : 0.20772\n",
      "1840-th loss is : 0.391637\n",
      "1841-th loss is : 0.745391\n",
      "1842-th loss is : 0.17832\n",
      "1843-th loss is : 0.407033\n",
      "1844-th loss is : 1.22716\n",
      "1845-th loss is : 0.290739\n",
      "1846-th loss is : 0.334202\n",
      "1847-th loss is : 1.23946\n",
      "1848-th loss is : 0.627594\n",
      "1849-th loss is : 0.542621\n",
      "1850-th loss is : 0.585116\n",
      "1851-th loss is : 0.56543\n",
      "1852-th loss is : 0.33246\n",
      "1853-th loss is : 0.621232\n",
      "1854-th loss is : 0.185249\n",
      "1855-th loss is : 0.270222\n",
      "1856-th loss is : 0.859668\n",
      "1857-th loss is : 0.576349\n",
      "1858-th loss is : 0.770221\n",
      "1859-th loss is : 0.175437\n",
      "1860-th loss is : 1.24882\n",
      "1861-th loss is : 0.41643\n",
      "1862-th loss is : 0.476296\n",
      "1863-th loss is : 0.303386\n",
      "1864-th loss is : 0.272816\n",
      "1865-th loss is : 0.338353\n",
      "1866-th loss is : 0.466679\n",
      "1867-th loss is : 0.634173\n",
      "1868-th loss is : 0.727399\n",
      "1869-th loss is : 1.00122\n",
      "1870-th loss is : 0.649013\n",
      "1871-th loss is : 0.866907\n",
      "1872-th loss is : 0.411603\n",
      "1873-th loss is : 0.786543\n",
      "1874-th loss is : 0.436033\n",
      "1875-th loss is : 1.06442\n",
      "1876-th loss is : 0.363696\n",
      "1877-th loss is : 0.292999\n",
      "1878-th loss is : 0.432132\n",
      "1879-th loss is : 0.250894\n",
      "1880-th loss is : 1.01276\n",
      "1881-th loss is : 0.824428\n",
      "1882-th loss is : 0.21762\n",
      "1883-th loss is : 0.800579\n",
      "1884-th loss is : 0.989731\n",
      "1885-th loss is : 0.412392\n",
      "1886-th loss is : 0.55401\n",
      "1887-th loss is : 0.613077\n",
      "1888-th loss is : 0.869561\n",
      "1889-th loss is : 0.997094\n",
      "1890-th loss is : 0.36869\n",
      "1891-th loss is : 0.434362\n",
      "1892-th loss is : 0.476053\n",
      "1893-th loss is : 0.228428\n",
      "1894-th loss is : 0.293372\n",
      "1895-th loss is : 0.716047\n",
      "1896-th loss is : 0.207891\n",
      "1897-th loss is : 0.2545\n",
      "1898-th loss is : 0.678471\n",
      "1899-th loss is : 0.293968\n",
      "1900-th loss is : 1.21024\n",
      "1901-th loss is : 0.95228\n",
      "1902-th loss is : 1.07893\n",
      "1903-th loss is : 0.975953\n",
      "1904-th loss is : 0.922266\n",
      "1905-th loss is : 0.187553\n",
      "1906-th loss is : 0.239525\n",
      "1907-th loss is : 1.11451\n",
      "1908-th loss is : 0.738604\n",
      "1909-th loss is : 0.313194\n",
      "1910-th loss is : 1.02585\n",
      "1911-th loss is : 0.513367\n",
      "1912-th loss is : 1.2192\n",
      "1913-th loss is : 0.365586\n",
      "1914-th loss is : 0.771929\n",
      "1915-th loss is : 0.260757\n",
      "1916-th loss is : 1.17407\n",
      "1917-th loss is : 0.236791\n",
      "1918-th loss is : 0.623416\n",
      "1919-th loss is : 0.284444\n",
      "1920-th loss is : 0.788801\n",
      "1921-th loss is : 0.4391\n",
      "1922-th loss is : 0.396232\n",
      "1923-th loss is : 0.550852\n",
      "1924-th loss is : 0.582471\n",
      "1925-th loss is : 0.857005\n",
      "1926-th loss is : 0.811677\n",
      "1927-th loss is : 0.432172\n",
      "1928-th loss is : 0.224869\n",
      "1929-th loss is : 0.288568\n",
      "1930-th loss is : 0.717425\n",
      "1931-th loss is : 0.252266\n",
      "1932-th loss is : 0.234651\n",
      "1933-th loss is : 0.754782\n",
      "1934-th loss is : 1.21773\n",
      "1935-th loss is : 0.612679\n",
      "1936-th loss is : 0.614548\n",
      "1937-th loss is : 1.23048\n",
      "1938-th loss is : 0.943349\n",
      "1939-th loss is : 0.427301\n",
      "1940-th loss is : 0.226906\n",
      "1941-th loss is : 0.187051\n",
      "1942-th loss is : 0.195458\n",
      "1943-th loss is : 0.71209\n",
      "1944-th loss is : 0.925883\n",
      "1945-th loss is : 0.249362\n",
      "1946-th loss is : 0.383319\n",
      "1947-th loss is : 1.22891\n",
      "1948-th loss is : 0.39947\n",
      "1949-th loss is : 0.703122\n",
      "1950-th loss is : 1.11319\n",
      "1951-th loss is : 0.447872\n",
      "1952-th loss is : 0.728839\n",
      "1953-th loss is : 0.559286\n",
      "1954-th loss is : 0.494019\n",
      "1955-th loss is : 0.812522\n",
      "1956-th loss is : 0.2608\n",
      "1957-th loss is : 0.228123\n",
      "1958-th loss is : 0.941631\n",
      "1959-th loss is : 0.891262\n",
      "1960-th loss is : 0.632784\n",
      "1961-th loss is : 0.356325\n",
      "1962-th loss is : 0.236002\n",
      "1963-th loss is : 0.531817\n",
      "1964-th loss is : 0.605664\n",
      "1965-th loss is : 0.427416\n",
      "1966-th loss is : 0.38995\n",
      "1967-th loss is : 0.460817\n",
      "1968-th loss is : 0.421123\n",
      "1969-th loss is : 0.285147\n",
      "1970-th loss is : 0.454728\n",
      "1971-th loss is : 0.785381\n",
      "1972-th loss is : 0.304837\n",
      "1973-th loss is : 0.274379\n",
      "1974-th loss is : 0.517586\n",
      "1975-th loss is : 0.159287\n",
      "1976-th loss is : 0.284829\n",
      "1977-th loss is : 0.191206\n",
      "1978-th loss is : 0.785377\n",
      "1979-th loss is : 0.985845\n",
      "1980-th loss is : 0.245275\n",
      "1981-th loss is : 0.232268\n",
      "1982-th loss is : 0.173684\n",
      "1983-th loss is : 0.697362\n",
      "1984-th loss is : 0.304109\n",
      "1985-th loss is : 0.217159\n",
      "1986-th loss is : 0.312157\n",
      "1987-th loss is : 0.240347\n",
      "1988-th loss is : 0.192062\n",
      "1989-th loss is : 0.214328\n",
      "1990-th loss is : 0.221445\n",
      "1991-th loss is : 0.710341\n",
      "1992-th loss is : 0.260944\n",
      "1993-th loss is : 0.220201\n",
      "1994-th loss is : 1.05403\n",
      "1995-th loss is : 0.567944\n",
      "1996-th loss is : 0.258059\n",
      "1997-th loss is : 0.656451\n",
      "1998-th loss is : 0.496924\n",
      "1999-th loss is : 0.19049\n",
      "2000-th loss is : 0.949101\n",
      "2001-th loss is : 0.635694\n",
      "2002-th loss is : 1.18218\n",
      "2003-th loss is : 0.931988\n",
      "2004-th loss is : 1.12043\n",
      "2005-th loss is : 0.583593\n",
      "2006-th loss is : 0.594613\n",
      "2007-th loss is : 0.618381\n",
      "2008-th loss is : 1.18649\n",
      "2009-th loss is : 0.462878\n",
      "2010-th loss is : 0.446169\n",
      "2011-th loss is : 0.803438\n",
      "2012-th loss is : 0.50165\n",
      "2013-th loss is : 0.923269\n",
      "2014-th loss is : 0.809813\n",
      "2015-th loss is : 0.40558\n",
      "2016-th loss is : 0.245524\n",
      "2017-th loss is : 0.773311\n",
      "2018-th loss is : 1.13827\n",
      "2019-th loss is : 0.9482\n",
      "2020-th loss is : 0.262618\n",
      "2021-th loss is : 0.622662\n",
      "2022-th loss is : 0.721193\n",
      "2023-th loss is : 0.449556\n",
      "2024-th loss is : 0.683294\n",
      "2025-th loss is : 0.522612\n",
      "2026-th loss is : 0.379828\n",
      "2027-th loss is : 1.17532\n",
      "2028-th loss is : 0.483749\n",
      "2029-th loss is : 1.09577\n",
      "2030-th loss is : 0.754412\n",
      "2031-th loss is : 0.308933\n",
      "2032-th loss is : 0.378954\n",
      "2033-th loss is : 0.953832\n",
      "2034-th loss is : 1.02165\n",
      "2035-th loss is : 0.343788\n",
      "2036-th loss is : 0.968335\n",
      "2037-th loss is : 0.848819\n",
      "2038-th loss is : 0.781003\n",
      "2039-th loss is : 0.401\n",
      "2040-th loss is : 0.351682\n",
      "2041-th loss is : 0.724245\n",
      "2042-th loss is : 0.515429\n",
      "2043-th loss is : 0.364787\n",
      "2044-th loss is : 1.07983\n",
      "2045-th loss is : 0.14866\n",
      "2046-th loss is : 0.394956\n",
      "2047-th loss is : 0.405618\n",
      "2048-th loss is : 0.250346\n",
      "2049-th loss is : 0.492491\n",
      "2050-th loss is : 0.183771\n",
      "2051-th loss is : 0.478352\n",
      "2052-th loss is : 0.268357\n",
      "2053-th loss is : 1.00961\n",
      "2054-th loss is : 0.441656\n",
      "2055-th loss is : 0.350584\n",
      "2056-th loss is : 0.597195\n",
      "2057-th loss is : 0.592005\n",
      "2058-th loss is : 0.483144\n",
      "2059-th loss is : 0.447603\n",
      "2060-th loss is : 0.32541\n",
      "2061-th loss is : 0.598006\n",
      "2062-th loss is : 0.456767\n",
      "2063-th loss is : 0.535601\n",
      "2064-th loss is : 0.515881\n",
      "2065-th loss is : 0.346084\n",
      "2066-th loss is : 0.969096\n",
      "2067-th loss is : 0.359255\n",
      "2068-th loss is : 0.890346\n",
      "2069-th loss is : 0.404304\n",
      "2070-th loss is : 0.156858\n",
      "2071-th loss is : 0.823175\n",
      "2072-th loss is : 0.95472\n",
      "2073-th loss is : 0.445404\n",
      "2074-th loss is : 0.706047\n",
      "2075-th loss is : 0.392826\n",
      "2076-th loss is : 0.4361\n",
      "2077-th loss is : 0.795834\n",
      "2078-th loss is : 0.200004\n",
      "2079-th loss is : 0.298375\n",
      "2080-th loss is : 0.692579\n",
      "2081-th loss is : 1.02322\n",
      "2082-th loss is : 0.214312\n",
      "2083-th loss is : 0.414529\n",
      "2084-th loss is : 1.02674\n",
      "2085-th loss is : 1.10989\n",
      "2086-th loss is : 1.01606\n",
      "2087-th loss is : 0.16502\n",
      "2088-th loss is : 0.215763\n",
      "2089-th loss is : 0.390703\n",
      "2090-th loss is : 0.308334\n",
      "2091-th loss is : 0.751259\n",
      "2092-th loss is : 0.422827\n",
      "2093-th loss is : 0.391398\n",
      "2094-th loss is : 0.656205\n",
      "2095-th loss is : 0.389391\n",
      "2096-th loss is : 0.348136\n",
      "2097-th loss is : 0.148015\n",
      "2098-th loss is : 1.05309\n",
      "2099-th loss is : 0.169909\n",
      "2100-th loss is : 0.363338\n",
      "2101-th loss is : 0.149958\n",
      "2102-th loss is : 0.735969\n",
      "2103-th loss is : 0.225184\n",
      "2104-th loss is : 0.217726\n",
      "2105-th loss is : 0.152868\n",
      "2106-th loss is : 0.22532\n",
      "2107-th loss is : 0.384752\n",
      "2108-th loss is : 0.284007\n",
      "2109-th loss is : 0.385451\n",
      "2110-th loss is : 0.14368\n",
      "2111-th loss is : 0.236904\n",
      "2112-th loss is : 1.08168\n",
      "2113-th loss is : 0.29269\n",
      "2114-th loss is : 0.776695\n",
      "2115-th loss is : 0.251037\n",
      "2116-th loss is : 0.41922\n",
      "2117-th loss is : 0.787176\n",
      "2118-th loss is : 0.386848\n",
      "2119-th loss is : 0.150591\n",
      "2120-th loss is : 0.532751\n",
      "2121-th loss is : 0.704513\n",
      "2122-th loss is : 0.272199\n",
      "2123-th loss is : 0.433564\n",
      "2124-th loss is : 0.219686\n",
      "2125-th loss is : 0.302694\n",
      "2126-th loss is : 0.341103\n",
      "2127-th loss is : 0.393223\n",
      "2128-th loss is : 0.351216\n",
      "2129-th loss is : 0.247098\n",
      "2130-th loss is : 0.669694\n",
      "2131-th loss is : 1.12557\n",
      "2132-th loss is : 0.898578\n",
      "2133-th loss is : 0.660962\n",
      "2134-th loss is : 0.184547\n",
      "2135-th loss is : 0.650822\n",
      "2136-th loss is : 0.235442\n",
      "2137-th loss is : 0.644107\n",
      "2138-th loss is : 0.440257\n",
      "2139-th loss is : 0.40034\n",
      "2140-th loss is : 0.656358\n",
      "2141-th loss is : 1.09398\n",
      "2142-th loss is : 0.296963\n",
      "2143-th loss is : 0.202779\n",
      "2144-th loss is : 0.315264\n",
      "2145-th loss is : 0.954374\n",
      "2146-th loss is : 0.310399\n",
      "2147-th loss is : 0.593035\n",
      "2148-th loss is : 0.279668\n",
      "2149-th loss is : 0.798681\n",
      "2150-th loss is : 0.172966\n",
      "2151-th loss is : 0.560231\n",
      "2152-th loss is : 0.243802\n",
      "2153-th loss is : 0.615092\n",
      "2154-th loss is : 1.03578\n",
      "2155-th loss is : 0.612885\n",
      "2156-th loss is : 0.317775\n",
      "2157-th loss is : 0.330023\n",
      "2158-th loss is : 0.591077\n",
      "2159-th loss is : 0.142989\n",
      "2160-th loss is : 0.849248\n",
      "2161-th loss is : 1.0337\n",
      "2162-th loss is : 0.811449\n",
      "2163-th loss is : 0.412412\n",
      "2164-th loss is : 0.470611\n",
      "2165-th loss is : 0.146238\n",
      "2166-th loss is : 0.163868\n",
      "2167-th loss is : 0.631464\n",
      "2168-th loss is : 0.676536\n",
      "2169-th loss is : 0.392375\n",
      "2170-th loss is : 0.328125\n",
      "2171-th loss is : 0.21858\n",
      "2172-th loss is : 0.956113\n",
      "2173-th loss is : 0.61887\n",
      "2174-th loss is : 0.621062\n",
      "2175-th loss is : 0.322667\n",
      "2176-th loss is : 0.733458\n",
      "2177-th loss is : 0.588921\n",
      "2178-th loss is : 0.342494\n",
      "2179-th loss is : 0.144759\n",
      "2180-th loss is : 1.02544\n",
      "2181-th loss is : 0.36492\n",
      "2182-th loss is : 0.505373\n",
      "2183-th loss is : 0.607151\n",
      "2184-th loss is : 1.05316\n",
      "2185-th loss is : 0.515127\n",
      "2186-th loss is : 0.293679\n",
      "2187-th loss is : 0.851667\n",
      "2188-th loss is : 0.327361\n",
      "2189-th loss is : 0.449355\n",
      "2190-th loss is : 0.401262\n",
      "2191-th loss is : 0.983272\n",
      "2192-th loss is : 0.826704\n",
      "2193-th loss is : 0.928926\n",
      "2194-th loss is : 0.445539\n",
      "2195-th loss is : 0.319193\n",
      "2196-th loss is : 0.436521\n",
      "2197-th loss is : 0.667985\n",
      "2198-th loss is : 0.427782\n",
      "2199-th loss is : 0.45444\n",
      "2200-th loss is : 0.760144\n",
      "2201-th loss is : 0.189295\n",
      "2202-th loss is : 0.606302\n",
      "2203-th loss is : 0.316336\n",
      "2204-th loss is : 0.321346\n",
      "2205-th loss is : 0.784764\n",
      "2206-th loss is : 0.185776\n",
      "2207-th loss is : 0.251648\n",
      "2208-th loss is : 0.152459\n",
      "2209-th loss is : 0.757041\n",
      "2210-th loss is : 0.858249\n",
      "2211-th loss is : 0.675579\n",
      "2212-th loss is : 0.226371\n",
      "2213-th loss is : 1.08129\n",
      "2214-th loss is : 0.611268\n",
      "2215-th loss is : 1.10354\n",
      "2216-th loss is : 0.240713\n",
      "2217-th loss is : 0.314065\n",
      "2218-th loss is : 0.881072\n",
      "2219-th loss is : 0.568551\n",
      "2220-th loss is : 0.261355\n",
      "2221-th loss is : 0.375076\n",
      "2222-th loss is : 0.237725\n",
      "2223-th loss is : 0.817147\n",
      "2224-th loss is : 0.95042\n",
      "2225-th loss is : 0.555362\n",
      "2226-th loss is : 0.846649\n",
      "2227-th loss is : 0.276505\n",
      "2228-th loss is : 0.904896\n",
      "2229-th loss is : 0.519515\n",
      "2230-th loss is : 0.261444\n",
      "2231-th loss is : 0.527573\n",
      "2232-th loss is : 0.527822\n",
      "2233-th loss is : 0.386771\n",
      "2234-th loss is : 0.301218\n",
      "2235-th loss is : 0.759927\n",
      "2236-th loss is : 0.295351\n",
      "2237-th loss is : 0.21022\n",
      "2238-th loss is : 0.155398\n",
      "2239-th loss is : 0.171972\n",
      "2240-th loss is : 0.272226\n",
      "2241-th loss is : 0.57107\n",
      "2242-th loss is : 0.256158\n",
      "2243-th loss is : 0.776747\n",
      "2244-th loss is : 0.559391\n",
      "2245-th loss is : 0.601875\n",
      "2246-th loss is : 0.133477\n",
      "2247-th loss is : 0.672628\n",
      "2248-th loss is : 0.236097\n",
      "2249-th loss is : 0.80147\n",
      "2250-th loss is : 0.418726\n",
      "2251-th loss is : 0.923638\n",
      "2252-th loss is : 0.270928\n",
      "2253-th loss is : 0.194323\n",
      "2254-th loss is : 0.826383\n",
      "2255-th loss is : 0.502967\n",
      "2256-th loss is : 0.510515\n",
      "2257-th loss is : 0.276361\n",
      "2258-th loss is : 1.02199\n",
      "2259-th loss is : 0.32223\n",
      "2260-th loss is : 0.331475\n",
      "2261-th loss is : 0.168078\n",
      "2262-th loss is : 0.874371\n",
      "2263-th loss is : 0.905174\n",
      "2264-th loss is : 0.632703\n",
      "2265-th loss is : 0.289305\n",
      "2266-th loss is : 0.911256\n",
      "2267-th loss is : 1.05671\n",
      "2268-th loss is : 0.189391\n",
      "2269-th loss is : 0.487534\n",
      "2270-th loss is : 0.822646\n",
      "2271-th loss is : 0.141417\n",
      "2272-th loss is : 0.124887\n",
      "2273-th loss is : 0.39655\n",
      "2274-th loss is : 0.332861\n",
      "2275-th loss is : 0.598436\n",
      "2276-th loss is : 1.00154\n",
      "2277-th loss is : 0.669748\n",
      "2278-th loss is : 0.797134\n",
      "2279-th loss is : 0.167529\n",
      "2280-th loss is : 0.776729\n",
      "2281-th loss is : 0.940677\n",
      "2282-th loss is : 0.127751\n",
      "2283-th loss is : 1.04342\n",
      "2284-th loss is : 0.423273\n",
      "2285-th loss is : 0.287879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2286-th loss is : 0.179204\n",
      "2287-th loss is : 0.195879\n",
      "2288-th loss is : 0.271404\n",
      "2289-th loss is : 0.25616\n",
      "2290-th loss is : 0.198241\n",
      "2291-th loss is : 0.390734\n",
      "2292-th loss is : 0.353508\n",
      "2293-th loss is : 0.356937\n",
      "2294-th loss is : 0.158635\n",
      "2295-th loss is : 0.273306\n",
      "2296-th loss is : 0.647458\n",
      "2297-th loss is : 0.668687\n",
      "2298-th loss is : 0.168082\n",
      "2299-th loss is : 0.213822\n",
      "2300-th loss is : 0.757901\n",
      "2301-th loss is : 0.597232\n",
      "2302-th loss is : 0.182911\n",
      "2303-th loss is : 1.03966\n",
      "2304-th loss is : 0.977577\n",
      "2305-th loss is : 0.23217\n",
      "2306-th loss is : 0.160374\n",
      "2307-th loss is : 0.414988\n",
      "2308-th loss is : 0.461139\n",
      "2309-th loss is : 0.192692\n",
      "2310-th loss is : 0.251031\n",
      "2311-th loss is : 0.278342\n",
      "2312-th loss is : 0.395081\n",
      "2313-th loss is : 0.453717\n",
      "2314-th loss is : 1.02144\n",
      "2315-th loss is : 0.519891\n",
      "2316-th loss is : 0.884761\n",
      "2317-th loss is : 0.180982\n",
      "2318-th loss is : 0.29892\n",
      "2319-th loss is : 0.439334\n",
      "2320-th loss is : 0.47563\n",
      "2321-th loss is : 0.561461\n",
      "2322-th loss is : 0.142988\n",
      "2323-th loss is : 0.241722\n",
      "2324-th loss is : 0.152673\n",
      "2325-th loss is : 0.896317\n",
      "2326-th loss is : 0.442859\n",
      "2327-th loss is : 0.968017\n",
      "2328-th loss is : 0.420435\n",
      "2329-th loss is : 0.328887\n",
      "2330-th loss is : 0.129944\n",
      "2331-th loss is : 0.418306\n",
      "2332-th loss is : 0.341298\n",
      "2333-th loss is : 0.178198\n",
      "2334-th loss is : 0.276617\n",
      "2335-th loss is : 0.380203\n",
      "2336-th loss is : 0.434872\n",
      "2337-th loss is : 0.475489\n",
      "2338-th loss is : 0.400198\n",
      "2339-th loss is : 0.2162\n",
      "2340-th loss is : 0.398918\n",
      "2341-th loss is : 0.669726\n",
      "2342-th loss is : 0.664336\n",
      "2343-th loss is : 0.747998\n",
      "2344-th loss is : 0.325641\n",
      "2345-th loss is : 0.389301\n",
      "2346-th loss is : 0.211963\n",
      "2347-th loss is : 0.159743\n",
      "2348-th loss is : 0.754262\n",
      "2349-th loss is : 0.316548\n",
      "2350-th loss is : 0.538348\n",
      "2351-th loss is : 0.637012\n",
      "2352-th loss is : 0.931527\n",
      "2353-th loss is : 0.23564\n",
      "2354-th loss is : 0.699937\n",
      "2355-th loss is : 0.146701\n",
      "2356-th loss is : 0.44139\n",
      "2357-th loss is : 0.224818\n",
      "2358-th loss is : 0.596729\n",
      "2359-th loss is : 0.160114\n",
      "2360-th loss is : 0.30947\n",
      "2361-th loss is : 0.187041\n",
      "2362-th loss is : 0.666785\n",
      "2363-th loss is : 0.77631\n",
      "2364-th loss is : 0.126321\n",
      "2365-th loss is : 0.840272\n",
      "2366-th loss is : 0.474098\n",
      "2367-th loss is : 0.637907\n",
      "2368-th loss is : 0.842244\n",
      "2369-th loss is : 0.342383\n",
      "2370-th loss is : 0.804063\n",
      "2371-th loss is : 0.53762\n",
      "2372-th loss is : 0.718265\n",
      "2373-th loss is : 0.858335\n",
      "2374-th loss is : 0.765657\n",
      "2375-th loss is : 0.236425\n",
      "2376-th loss is : 0.739519\n",
      "2377-th loss is : 0.153436\n",
      "2378-th loss is : 0.77383\n",
      "2379-th loss is : 0.336843\n",
      "2380-th loss is : 0.337237\n",
      "2381-th loss is : 0.128552\n",
      "2382-th loss is : 0.128447\n",
      "2383-th loss is : 0.480945\n",
      "2384-th loss is : 0.272764\n",
      "2385-th loss is : 0.689152\n",
      "2386-th loss is : 0.228052\n",
      "2387-th loss is : 0.474859\n",
      "2388-th loss is : 0.265856\n",
      "2389-th loss is : 0.294555\n",
      "2390-th loss is : 0.928374\n",
      "2391-th loss is : 0.768945\n",
      "2392-th loss is : 0.26238\n",
      "2393-th loss is : 0.36542\n",
      "2394-th loss is : 0.327512\n",
      "2395-th loss is : 0.888636\n",
      "2396-th loss is : 0.377928\n",
      "2397-th loss is : 0.19441\n",
      "2398-th loss is : 0.760921\n",
      "2399-th loss is : 0.470958\n",
      "2400-th loss is : 0.742931\n",
      "2401-th loss is : 0.113452\n",
      "2402-th loss is : 0.112076\n",
      "2403-th loss is : 0.412979\n",
      "2404-th loss is : 0.993514\n",
      "2405-th loss is : 0.373913\n",
      "2406-th loss is : 0.956889\n",
      "2407-th loss is : 0.159763\n",
      "2408-th loss is : 0.407082\n",
      "2409-th loss is : 0.310553\n",
      "2410-th loss is : 0.542076\n",
      "2411-th loss is : 0.182802\n",
      "2412-th loss is : 0.340143\n",
      "2413-th loss is : 0.611401\n",
      "2414-th loss is : 0.111014\n",
      "2415-th loss is : 0.301915\n",
      "2416-th loss is : 0.252298\n",
      "2417-th loss is : 0.347609\n",
      "2418-th loss is : 0.825737\n",
      "2419-th loss is : 0.339907\n",
      "2420-th loss is : 0.521198\n",
      "2421-th loss is : 0.458384\n",
      "2422-th loss is : 0.120663\n",
      "2423-th loss is : 0.112732\n",
      "2424-th loss is : 0.550128\n",
      "2425-th loss is : 0.176276\n",
      "2426-th loss is : 0.266295\n",
      "2427-th loss is : 0.455311\n",
      "2428-th loss is : 0.148531\n",
      "2429-th loss is : 0.215149\n",
      "2430-th loss is : 0.738141\n",
      "2431-th loss is : 0.311956\n",
      "2432-th loss is : 0.949535\n",
      "2433-th loss is : 0.897417\n",
      "2434-th loss is : 0.602303\n",
      "2435-th loss is : 0.581011\n",
      "2436-th loss is : 0.542317\n",
      "2437-th loss is : 0.995067\n",
      "2438-th loss is : 0.557566\n",
      "2439-th loss is : 0.291493\n",
      "2440-th loss is : 0.779809\n",
      "2441-th loss is : 0.486052\n",
      "2442-th loss is : 0.538729\n",
      "2443-th loss is : 0.317007\n",
      "2444-th loss is : 0.82857\n",
      "2445-th loss is : 0.307525\n",
      "2446-th loss is : 0.569541\n",
      "2447-th loss is : 0.916949\n",
      "2448-th loss is : 0.60366\n",
      "2449-th loss is : 0.239145\n",
      "2450-th loss is : 0.816271\n",
      "2451-th loss is : 0.157299\n",
      "2452-th loss is : 1.00331\n",
      "2453-th loss is : 0.976812\n",
      "2454-th loss is : 0.762561\n",
      "2455-th loss is : 0.202417\n",
      "2456-th loss is : 0.842266\n",
      "2457-th loss is : 0.638615\n",
      "2458-th loss is : 0.2176\n",
      "2459-th loss is : 0.534875\n",
      "2460-th loss is : 0.49506\n",
      "2461-th loss is : 0.161416\n",
      "2462-th loss is : 0.762761\n",
      "2463-th loss is : 0.146622\n",
      "2464-th loss is : 0.277911\n",
      "2465-th loss is : 0.952759\n",
      "2466-th loss is : 0.160487\n",
      "2467-th loss is : 0.702283\n",
      "2468-th loss is : 0.157939\n",
      "2469-th loss is : 0.155256\n",
      "2470-th loss is : 0.61575\n",
      "2471-th loss is : 0.118511\n",
      "2472-th loss is : 0.276973\n",
      "2473-th loss is : 0.689494\n",
      "2474-th loss is : 0.727561\n",
      "2475-th loss is : 0.819572\n",
      "2476-th loss is : 0.173022\n",
      "2477-th loss is : 0.300453\n",
      "2478-th loss is : 0.443813\n",
      "2479-th loss is : 0.205389\n",
      "2480-th loss is : 0.448984\n",
      "2481-th loss is : 0.946567\n",
      "2482-th loss is : 0.381047\n",
      "2483-th loss is : 0.709597\n",
      "2484-th loss is : 0.234982\n",
      "2485-th loss is : 0.679093\n",
      "2486-th loss is : 0.931293\n",
      "2487-th loss is : 0.405953\n",
      "2488-th loss is : 0.121175\n",
      "2489-th loss is : 0.617269\n",
      "2490-th loss is : 0.76446\n",
      "2491-th loss is : 0.617279\n",
      "2492-th loss is : 0.17402\n",
      "2493-th loss is : 0.292491\n",
      "2494-th loss is : 0.559602\n",
      "2495-th loss is : 0.304351\n",
      "2496-th loss is : 0.760991\n",
      "2497-th loss is : 0.197071\n",
      "2498-th loss is : 0.854139\n",
      "2499-th loss is : 0.769987\n",
      "2500-th loss is : 0.318033\n",
      "2501-th loss is : 0.715083\n",
      "2502-th loss is : 0.159287\n",
      "2503-th loss is : 0.385713\n",
      "2504-th loss is : 0.541036\n",
      "2505-th loss is : 0.186434\n",
      "2506-th loss is : 0.863144\n",
      "2507-th loss is : 0.176354\n",
      "2508-th loss is : 0.602778\n",
      "2509-th loss is : 0.531007\n",
      "2510-th loss is : 0.280291\n",
      "2511-th loss is : 0.775694\n",
      "2512-th loss is : 0.483541\n",
      "2513-th loss is : 0.179012\n",
      "2514-th loss is : 0.21409\n",
      "2515-th loss is : 0.656882\n",
      "2516-th loss is : 0.560366\n",
      "2517-th loss is : 0.122154\n",
      "2518-th loss is : 0.595211\n",
      "2519-th loss is : 0.386997\n",
      "2520-th loss is : 0.623131\n",
      "2521-th loss is : 0.743859\n",
      "2522-th loss is : 0.123518\n",
      "2523-th loss is : 0.843241\n",
      "2524-th loss is : 0.240668\n",
      "2525-th loss is : 0.104511\n",
      "2526-th loss is : 0.220201\n",
      "2527-th loss is : 0.937175\n",
      "2528-th loss is : 0.289971\n",
      "2529-th loss is : 0.290152\n",
      "2530-th loss is : 0.170774\n",
      "2531-th loss is : 0.726847\n",
      "2532-th loss is : 0.59596\n",
      "2533-th loss is : 0.182756\n",
      "2534-th loss is : 0.775821\n",
      "2535-th loss is : 0.190477\n",
      "2536-th loss is : 0.275583\n",
      "2537-th loss is : 0.303061\n",
      "2538-th loss is : 0.447527\n",
      "2539-th loss is : 0.189492\n",
      "2540-th loss is : 0.14619\n",
      "2541-th loss is : 0.658387\n",
      "2542-th loss is : 0.427664\n",
      "2543-th loss is : 0.292415\n",
      "2544-th loss is : 0.183807\n",
      "2545-th loss is : 0.682787\n",
      "2546-th loss is : 0.197125\n",
      "2547-th loss is : 0.820931\n",
      "2548-th loss is : 0.168925\n",
      "2549-th loss is : 0.133072\n",
      "2550-th loss is : 0.269368\n",
      "2551-th loss is : 0.706018\n",
      "2552-th loss is : 0.962695\n",
      "2553-th loss is : 0.676655\n",
      "2554-th loss is : 0.477838\n",
      "2555-th loss is : 0.874468\n",
      "2556-th loss is : 0.444547\n",
      "2557-th loss is : 0.894519\n",
      "2558-th loss is : 0.218556\n",
      "2559-th loss is : 0.600869\n",
      "2560-th loss is : 0.564614\n",
      "2561-th loss is : 0.813301\n",
      "2562-th loss is : 0.854523\n",
      "2563-th loss is : 0.93286\n",
      "2564-th loss is : 0.186435\n",
      "2565-th loss is : 0.23395\n",
      "2566-th loss is : 0.763708\n",
      "2567-th loss is : 0.537222\n",
      "2568-th loss is : 0.534603\n",
      "2569-th loss is : 0.2891\n",
      "2570-th loss is : 0.891468\n",
      "2571-th loss is : 0.18211\n",
      "2572-th loss is : 0.127535\n",
      "2573-th loss is : 0.289501\n",
      "2574-th loss is : 0.385931\n",
      "2575-th loss is : 0.565244\n",
      "2576-th loss is : 0.720773\n",
      "2577-th loss is : 0.0992688\n",
      "2578-th loss is : 0.237301\n",
      "2579-th loss is : 0.263087\n",
      "2580-th loss is : 0.33812\n",
      "2581-th loss is : 0.862005\n",
      "2582-th loss is : 0.294852\n",
      "2583-th loss is : 0.768652\n",
      "2584-th loss is : 0.327117\n",
      "2585-th loss is : 0.218909\n",
      "2586-th loss is : 0.604279\n",
      "2587-th loss is : 0.790375\n",
      "2588-th loss is : 0.228421\n",
      "2589-th loss is : 0.411295\n",
      "2590-th loss is : 0.411609\n",
      "2591-th loss is : 0.177704\n",
      "2592-th loss is : 0.345874\n",
      "2593-th loss is : 0.196686\n",
      "2594-th loss is : 0.74427\n",
      "2595-th loss is : 0.575085\n",
      "2596-th loss is : 0.196784\n",
      "2597-th loss is : 0.175467\n",
      "2598-th loss is : 0.899298\n",
      "2599-th loss is : 0.297331\n",
      "2600-th loss is : 0.45083\n",
      "2601-th loss is : 0.190766\n",
      "2602-th loss is : 0.694158\n",
      "2603-th loss is : 0.231777\n",
      "2604-th loss is : 0.387906\n",
      "2605-th loss is : 0.739349\n",
      "2606-th loss is : 0.17598\n",
      "2607-th loss is : 0.358603\n",
      "2608-th loss is : 0.712317\n",
      "2609-th loss is : 0.497776\n",
      "2610-th loss is : 0.14567\n",
      "2611-th loss is : 0.197946\n",
      "2612-th loss is : 0.312393\n",
      "2613-th loss is : 0.616934\n",
      "2614-th loss is : 0.162586\n",
      "2615-th loss is : 0.222037\n",
      "2616-th loss is : 0.10722\n",
      "2617-th loss is : 0.514449\n",
      "2618-th loss is : 0.809338\n",
      "2619-th loss is : 0.504486\n",
      "2620-th loss is : 0.664895\n",
      "2621-th loss is : 0.425532\n",
      "2622-th loss is : 0.604099\n",
      "2623-th loss is : 0.78519\n",
      "2624-th loss is : 0.166839\n",
      "2625-th loss is : 0.204901\n",
      "2626-th loss is : 0.216222\n",
      "2627-th loss is : 0.324524\n",
      "2628-th loss is : 0.122279\n",
      "2629-th loss is : 0.378482\n",
      "2630-th loss is : 0.264499\n",
      "2631-th loss is : 0.300329\n",
      "2632-th loss is : 0.255153\n",
      "2633-th loss is : 0.848307\n",
      "2634-th loss is : 0.102848\n",
      "2635-th loss is : 0.718263\n",
      "2636-th loss is : 0.255789\n",
      "2637-th loss is : 0.92646\n",
      "2638-th loss is : 0.230806\n",
      "2639-th loss is : 0.759368\n",
      "2640-th loss is : 0.14087\n",
      "2641-th loss is : 0.151773\n",
      "2642-th loss is : 0.491744\n",
      "2643-th loss is : 0.153573\n",
      "2644-th loss is : 0.124144\n",
      "2645-th loss is : 0.880021\n",
      "2646-th loss is : 0.455081\n",
      "2647-th loss is : 0.33306\n",
      "2648-th loss is : 0.37936\n",
      "2649-th loss is : 0.432722\n",
      "2650-th loss is : 0.828843\n",
      "2651-th loss is : 0.903577\n",
      "2652-th loss is : 0.175183\n",
      "2653-th loss is : 0.169607\n",
      "2654-th loss is : 0.32104\n",
      "2655-th loss is : 0.204009\n",
      "2656-th loss is : 0.117935\n",
      "2657-th loss is : 0.276332\n",
      "2658-th loss is : 0.457788\n",
      "2659-th loss is : 0.183506\n",
      "2660-th loss is : 0.84859\n",
      "2661-th loss is : 0.294975\n",
      "2662-th loss is : 0.129119\n",
      "2663-th loss is : 0.717623\n",
      "2664-th loss is : 0.476976\n",
      "2665-th loss is : 0.877792\n",
      "2666-th loss is : 0.840434\n",
      "2667-th loss is : 0.786645\n",
      "2668-th loss is : 0.285998\n",
      "2669-th loss is : 0.134006\n",
      "2670-th loss is : 0.511109\n",
      "2671-th loss is : 0.108751\n",
      "2672-th loss is : 0.292137\n",
      "2673-th loss is : 0.447006\n",
      "2674-th loss is : 0.84034\n",
      "2675-th loss is : 0.119924\n",
      "2676-th loss is : 0.124451\n",
      "2677-th loss is : 0.099148\n",
      "2678-th loss is : 0.413917\n",
      "2679-th loss is : 0.34937\n",
      "2680-th loss is : 0.277637\n",
      "2681-th loss is : 0.834221\n",
      "2682-th loss is : 0.151955\n",
      "2683-th loss is : 0.150082\n",
      "2684-th loss is : 0.145201\n",
      "2685-th loss is : 0.450153\n",
      "2686-th loss is : 0.89591\n",
      "2687-th loss is : 0.552232\n",
      "2688-th loss is : 0.805289\n",
      "2689-th loss is : 0.812571\n",
      "2690-th loss is : 0.255643\n",
      "2691-th loss is : 0.281925\n",
      "2692-th loss is : 0.236275\n",
      "2693-th loss is : 0.114583\n",
      "2694-th loss is : 0.124483\n",
      "2695-th loss is : 0.160504\n",
      "2696-th loss is : 0.094106\n",
      "2697-th loss is : 0.642061\n",
      "2698-th loss is : 0.221129\n",
      "2699-th loss is : 0.578449\n",
      "2700-th loss is : 0.130567\n",
      "2701-th loss is : 0.0989593\n",
      "2702-th loss is : 0.400019\n",
      "2703-th loss is : 0.21378\n",
      "2704-th loss is : 0.436051\n",
      "2705-th loss is : 0.905703\n",
      "2706-th loss is : 0.180784\n",
      "2707-th loss is : 0.0913135\n",
      "2708-th loss is : 0.744076\n",
      "2709-th loss is : 0.299495\n",
      "2710-th loss is : 0.247236\n",
      "2711-th loss is : 0.568319\n",
      "2712-th loss is : 0.857956\n",
      "2713-th loss is : 0.312447\n",
      "2714-th loss is : 0.240614\n",
      "2715-th loss is : 0.443002\n",
      "2716-th loss is : 0.174123\n",
      "2717-th loss is : 0.774609\n",
      "2718-th loss is : 0.311965\n",
      "2719-th loss is : 0.521186\n",
      "2720-th loss is : 0.891904\n",
      "2721-th loss is : 0.507242\n",
      "2722-th loss is : 0.292685\n",
      "2723-th loss is : 0.0936265\n",
      "2724-th loss is : 0.393002\n",
      "2725-th loss is : 0.311329\n",
      "2726-th loss is : 0.0891312\n",
      "2727-th loss is : 0.304638\n",
      "2728-th loss is : 0.312426\n",
      "2729-th loss is : 0.830642\n",
      "2730-th loss is : 0.521227\n",
      "2731-th loss is : 0.735104\n",
      "2732-th loss is : 0.67604\n",
      "2733-th loss is : 0.163991\n",
      "2734-th loss is : 0.300099\n",
      "2735-th loss is : 0.576405\n",
      "2736-th loss is : 0.619717\n",
      "2737-th loss is : 0.522253\n",
      "2738-th loss is : 0.096682\n",
      "2739-th loss is : 0.431023\n",
      "2740-th loss is : 0.430412\n",
      "2741-th loss is : 0.146337\n",
      "2742-th loss is : 0.32547\n",
      "2743-th loss is : 0.246294\n",
      "2744-th loss is : 0.776005\n",
      "2745-th loss is : 0.886142\n",
      "2746-th loss is : 0.43318\n",
      "2747-th loss is : 0.106915\n",
      "2748-th loss is : 0.486112\n",
      "2749-th loss is : 0.314365\n",
      "2750-th loss is : 0.135498\n",
      "2751-th loss is : 0.887382\n",
      "2752-th loss is : 0.117357\n",
      "2753-th loss is : 0.592074\n",
      "2754-th loss is : 0.371234\n",
      "2755-th loss is : 0.664868\n",
      "2756-th loss is : 0.0930529\n",
      "2757-th loss is : 0.792227\n",
      "2758-th loss is : 0.627957\n",
      "2759-th loss is : 0.196321\n",
      "2760-th loss is : 0.331166\n",
      "2761-th loss is : 0.35922\n",
      "2762-th loss is : 0.465678\n",
      "2763-th loss is : 0.564206\n",
      "2764-th loss is : 0.379467\n",
      "2765-th loss is : 0.287197\n",
      "2766-th loss is : 0.639112\n",
      "2767-th loss is : 0.823191\n",
      "2768-th loss is : 0.884667\n",
      "2769-th loss is : 0.131673\n",
      "2770-th loss is : 0.692957\n",
      "2771-th loss is : 0.175786\n",
      "2772-th loss is : 0.409973\n",
      "2773-th loss is : 0.121947\n",
      "2774-th loss is : 0.541518\n",
      "2775-th loss is : 0.16408\n",
      "2776-th loss is : 0.606801\n",
      "2777-th loss is : 0.881868\n",
      "2778-th loss is : 0.558792\n",
      "2779-th loss is : 0.780867\n",
      "2780-th loss is : 0.171053\n",
      "2781-th loss is : 0.61534\n",
      "2782-th loss is : 0.451318\n",
      "2783-th loss is : 0.41305\n",
      "2784-th loss is : 0.336467\n",
      "2785-th loss is : 0.619851\n",
      "2786-th loss is : 0.198322\n",
      "2787-th loss is : 0.656428\n",
      "2788-th loss is : 0.431333\n",
      "2789-th loss is : 0.433802\n",
      "2790-th loss is : 0.75487\n",
      "2791-th loss is : 0.513057\n",
      "2792-th loss is : 0.86499\n",
      "2793-th loss is : 0.180709\n",
      "2794-th loss is : 0.356072\n",
      "2795-th loss is : 0.855125\n",
      "2796-th loss is : 0.580549\n",
      "2797-th loss is : 0.654775\n",
      "2798-th loss is : 0.217514\n",
      "2799-th loss is : 0.74782\n",
      "2800-th loss is : 0.219291\n",
      "2801-th loss is : 0.335858\n",
      "2802-th loss is : 0.10951\n",
      "2803-th loss is : 0.302894\n",
      "2804-th loss is : 0.134873\n",
      "2805-th loss is : 0.12086\n",
      "2806-th loss is : 0.441796\n",
      "2807-th loss is : 0.339281\n",
      "2808-th loss is : 0.344068\n",
      "2809-th loss is : 0.516879\n",
      "2810-th loss is : 0.151444\n",
      "2811-th loss is : 0.17799\n",
      "2812-th loss is : 0.539423\n",
      "2813-th loss is : 0.463489\n",
      "2814-th loss is : 0.407399\n",
      "2815-th loss is : 0.260556\n",
      "2816-th loss is : 0.657216\n",
      "2817-th loss is : 0.657743\n",
      "2818-th loss is : 0.101099\n",
      "2819-th loss is : 0.650078\n",
      "2820-th loss is : 0.425351\n",
      "2821-th loss is : 0.167717\n",
      "2822-th loss is : 0.236005\n",
      "2823-th loss is : 0.339377\n",
      "2824-th loss is : 0.600097\n",
      "2825-th loss is : 0.250387\n",
      "2826-th loss is : 0.447413\n",
      "2827-th loss is : 0.176495\n",
      "2828-th loss is : 0.435366\n",
      "2829-th loss is : 0.110701\n",
      "2830-th loss is : 0.461282\n",
      "2831-th loss is : 0.264976\n",
      "2832-th loss is : 0.472026\n",
      "2833-th loss is : 0.109397\n",
      "2834-th loss is : 0.59017\n",
      "2835-th loss is : 0.162849\n",
      "2836-th loss is : 0.378868\n",
      "2837-th loss is : 0.685137\n",
      "2838-th loss is : 0.123464\n",
      "2839-th loss is : 0.185513\n",
      "2840-th loss is : 0.178187\n",
      "2841-th loss is : 0.125582\n",
      "2842-th loss is : 0.420308\n",
      "2843-th loss is : 0.0975402\n",
      "2844-th loss is : 0.650114\n",
      "2845-th loss is : 0.645278\n",
      "2846-th loss is : 0.188194\n",
      "2847-th loss is : 0.315744\n",
      "2848-th loss is : 0.271668\n",
      "2849-th loss is : 0.391232\n",
      "2850-th loss is : 0.0843385\n",
      "2851-th loss is : 0.380808\n",
      "2852-th loss is : 0.741124\n",
      "2853-th loss is : 0.535927\n",
      "2854-th loss is : 0.126998\n",
      "2855-th loss is : 0.340938\n",
      "2856-th loss is : 0.0999052\n",
      "2857-th loss is : 0.114714\n",
      "2858-th loss is : 0.338879\n",
      "2859-th loss is : 0.0884565\n",
      "2860-th loss is : 0.322978\n",
      "2861-th loss is : 0.309231\n",
      "2862-th loss is : 0.216449\n",
      "2863-th loss is : 0.239004\n",
      "2864-th loss is : 0.104151\n",
      "2865-th loss is : 0.380229\n",
      "2866-th loss is : 0.404364\n",
      "2867-th loss is : 0.375985\n",
      "2868-th loss is : 0.328876\n",
      "2869-th loss is : 0.806365\n",
      "2870-th loss is : 0.6163\n",
      "2871-th loss is : 0.198593\n",
      "2872-th loss is : 0.400872\n",
      "2873-th loss is : 0.761004\n",
      "2874-th loss is : 0.090592\n",
      "2875-th loss is : 0.419907\n",
      "2876-th loss is : 0.196943\n",
      "2877-th loss is : 0.694572\n",
      "2878-th loss is : 0.392099\n",
      "2879-th loss is : 0.772058\n",
      "2880-th loss is : 0.269979\n",
      "2881-th loss is : 0.107529\n",
      "2882-th loss is : 0.229176\n",
      "2883-th loss is : 0.722441\n",
      "2884-th loss is : 0.423852\n",
      "2885-th loss is : 0.535659\n",
      "2886-th loss is : 0.497326\n",
      "2887-th loss is : 0.124718\n",
      "2888-th loss is : 0.529769\n",
      "2889-th loss is : 0.257561\n",
      "2890-th loss is : 0.528968\n",
      "2891-th loss is : 0.58127\n",
      "2892-th loss is : 0.168873\n",
      "2893-th loss is : 0.534241\n",
      "2894-th loss is : 0.262132\n",
      "2895-th loss is : 0.271478\n",
      "2896-th loss is : 0.211888\n",
      "2897-th loss is : 0.823426\n",
      "2898-th loss is : 0.457349\n",
      "2899-th loss is : 0.0794429\n",
      "2900-th loss is : 0.286189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2901-th loss is : 0.378614\n",
      "2902-th loss is : 0.811244\n",
      "2903-th loss is : 0.372775\n",
      "2904-th loss is : 0.325846\n",
      "2905-th loss is : 0.419113\n",
      "2906-th loss is : 0.110711\n",
      "2907-th loss is : 0.401713\n",
      "2908-th loss is : 0.264219\n",
      "2909-th loss is : 0.583242\n",
      "2910-th loss is : 0.154376\n",
      "2911-th loss is : 0.721219\n",
      "2912-th loss is : 0.190212\n",
      "2913-th loss is : 0.157387\n",
      "2914-th loss is : 0.770892\n",
      "2915-th loss is : 0.710311\n",
      "2916-th loss is : 0.412379\n",
      "2917-th loss is : 0.157324\n",
      "2918-th loss is : 0.394782\n",
      "2919-th loss is : 0.449893\n",
      "2920-th loss is : 0.102977\n",
      "2921-th loss is : 0.389174\n",
      "2922-th loss is : 0.382598\n",
      "2923-th loss is : 0.550896\n",
      "2924-th loss is : 0.550067\n",
      "2925-th loss is : 0.742657\n",
      "2926-th loss is : 0.241969\n",
      "2927-th loss is : 0.78334\n",
      "2928-th loss is : 0.45589\n",
      "2929-th loss is : 0.303845\n",
      "2930-th loss is : 0.34237\n",
      "2931-th loss is : 0.795802\n",
      "2932-th loss is : 0.80006\n",
      "2933-th loss is : 0.116435\n",
      "2934-th loss is : 0.627986\n",
      "2935-th loss is : 0.257045\n",
      "2936-th loss is : 0.522344\n",
      "2937-th loss is : 0.561221\n",
      "2938-th loss is : 0.422547\n",
      "2939-th loss is : 0.822298\n",
      "2940-th loss is : 0.66605\n",
      "2941-th loss is : 0.160345\n",
      "2942-th loss is : 0.120332\n",
      "2943-th loss is : 0.343124\n",
      "2944-th loss is : 0.487828\n",
      "2945-th loss is : 0.0855429\n",
      "2946-th loss is : 0.773302\n",
      "2947-th loss is : 0.580381\n",
      "2948-th loss is : 0.0806544\n",
      "2949-th loss is : 0.673029\n",
      "2950-th loss is : 0.228017\n",
      "2951-th loss is : 0.759187\n",
      "2952-th loss is : 0.416709\n",
      "2953-th loss is : 0.482747\n",
      "2954-th loss is : 0.105795\n",
      "2955-th loss is : 0.517406\n",
      "2956-th loss is : 0.236205\n",
      "2957-th loss is : 0.0801074\n",
      "2958-th loss is : 0.246476\n",
      "2959-th loss is : 0.329576\n",
      "2960-th loss is : 0.679162\n",
      "2961-th loss is : 0.341616\n",
      "2962-th loss is : 0.179299\n",
      "2963-th loss is : 0.254751\n",
      "2964-th loss is : 0.565718\n",
      "2965-th loss is : 0.365759\n",
      "2966-th loss is : 0.337979\n",
      "2967-th loss is : 0.509705\n",
      "2968-th loss is : 0.253444\n",
      "2969-th loss is : 0.751393\n",
      "2970-th loss is : 0.0695458\n",
      "2971-th loss is : 0.435262\n",
      "2972-th loss is : 0.141999\n",
      "2973-th loss is : 0.459826\n",
      "2974-th loss is : 0.184319\n",
      "2975-th loss is : 0.688894\n",
      "2976-th loss is : 0.64769\n",
      "2977-th loss is : 0.38976\n",
      "2978-th loss is : 0.50958\n",
      "2979-th loss is : 0.308007\n",
      "2980-th loss is : 0.356441\n",
      "2981-th loss is : 0.532831\n",
      "2982-th loss is : 0.476573\n",
      "2983-th loss is : 0.27842\n",
      "2984-th loss is : 0.088894\n",
      "2985-th loss is : 0.370004\n",
      "2986-th loss is : 0.58232\n",
      "2987-th loss is : 0.0930755\n",
      "2988-th loss is : 0.314228\n",
      "2989-th loss is : 0.333704\n",
      "2990-th loss is : 0.0763977\n",
      "2991-th loss is : 0.649014\n",
      "2992-th loss is : 0.124405\n",
      "2993-th loss is : 0.4138\n",
      "2994-th loss is : 0.427666\n",
      "2995-th loss is : 0.632066\n",
      "2996-th loss is : 0.279201\n",
      "2997-th loss is : 0.396526\n",
      "2998-th loss is : 0.0675729\n",
      "2999-th loss is : 0.0831763\n",
      "3000-th loss is : 0.6305\n",
      "3001-th loss is : 0.635763\n",
      "3002-th loss is : 0.171153\n",
      "3003-th loss is : 0.718379\n",
      "3004-th loss is : 0.472412\n",
      "3005-th loss is : 0.186669\n",
      "3006-th loss is : 0.386101\n",
      "3007-th loss is : 0.487894\n",
      "3008-th loss is : 0.252791\n",
      "3009-th loss is : 0.316923\n",
      "3010-th loss is : 0.644329\n",
      "3011-th loss is : 0.28183\n",
      "3012-th loss is : 0.279944\n",
      "3013-th loss is : 0.199495\n",
      "3014-th loss is : 0.264708\n",
      "3015-th loss is : 0.0845758\n",
      "3016-th loss is : 0.276374\n",
      "3017-th loss is : 0.557087\n",
      "3018-th loss is : 0.151895\n",
      "3019-th loss is : 0.196508\n",
      "3020-th loss is : 0.196915\n",
      "3021-th loss is : 0.353193\n",
      "3022-th loss is : 0.163398\n",
      "3023-th loss is : 0.142933\n",
      "3024-th loss is : 0.132726\n",
      "3025-th loss is : 0.205336\n",
      "3026-th loss is : 0.22957\n",
      "3027-th loss is : 0.307334\n",
      "3028-th loss is : 0.40257\n",
      "3029-th loss is : 0.456475\n",
      "3030-th loss is : 0.370722\n",
      "3031-th loss is : 0.0911211\n",
      "3032-th loss is : 0.762557\n",
      "3033-th loss is : 0.728417\n",
      "3034-th loss is : 0.0650939\n",
      "3035-th loss is : 0.635384\n",
      "3036-th loss is : 0.758543\n",
      "3037-th loss is : 0.0726896\n",
      "3038-th loss is : 0.486274\n",
      "3039-th loss is : 0.348531\n",
      "3040-th loss is : 0.279613\n",
      "3041-th loss is : 0.762421\n",
      "3042-th loss is : 0.630566\n",
      "3043-th loss is : 0.096146\n",
      "3044-th loss is : 0.505608\n",
      "3045-th loss is : 0.0742835\n",
      "3046-th loss is : 0.492716\n",
      "3047-th loss is : 0.186609\n",
      "3048-th loss is : 0.0868165\n",
      "3049-th loss is : 0.373271\n",
      "3050-th loss is : 0.401555\n",
      "3051-th loss is : 0.098319\n",
      "3052-th loss is : 0.171192\n",
      "3053-th loss is : 0.307049\n",
      "3054-th loss is : 0.0761229\n",
      "3055-th loss is : 0.600267\n",
      "3056-th loss is : 0.253051\n",
      "3057-th loss is : 0.478758\n",
      "3058-th loss is : 0.144155\n",
      "3059-th loss is : 0.458251\n",
      "3060-th loss is : 0.521432\n",
      "3061-th loss is : 0.220823\n",
      "3062-th loss is : 0.0904177\n",
      "3063-th loss is : 0.581305\n",
      "3064-th loss is : 0.385969\n",
      "3065-th loss is : 0.191304\n",
      "3066-th loss is : 0.379889\n",
      "3067-th loss is : 0.120399\n",
      "3068-th loss is : 0.266455\n",
      "3069-th loss is : 0.222643\n",
      "3070-th loss is : 0.194515\n",
      "3071-th loss is : 0.0735017\n",
      "3072-th loss is : 0.712439\n",
      "3073-th loss is : 0.582578\n",
      "3074-th loss is : 0.712522\n",
      "3075-th loss is : 0.711961\n",
      "3076-th loss is : 0.139137\n",
      "3077-th loss is : 0.40328\n",
      "3078-th loss is : 0.559877\n",
      "3079-th loss is : 0.258682\n",
      "3080-th loss is : 0.226308\n",
      "3081-th loss is : 0.255304\n",
      "3082-th loss is : 0.119327\n",
      "3083-th loss is : 0.391915\n",
      "3084-th loss is : 0.543885\n",
      "3085-th loss is : 0.341381\n",
      "3086-th loss is : 0.206662\n",
      "3087-th loss is : 0.341346\n",
      "3088-th loss is : 0.150594\n",
      "3089-th loss is : 0.337211\n",
      "3090-th loss is : 0.691299\n",
      "3091-th loss is : 0.13476\n",
      "3092-th loss is : 0.0716712\n",
      "3093-th loss is : 0.194936\n",
      "3094-th loss is : 0.512071\n",
      "3095-th loss is : 0.252582\n",
      "3096-th loss is : 0.401095\n",
      "3097-th loss is : 0.378006\n",
      "3098-th loss is : 0.269689\n",
      "3099-th loss is : 0.434358\n",
      "3100-th loss is : 0.185081\n",
      "3101-th loss is : 0.0700189\n",
      "3102-th loss is : 0.124868\n",
      "3103-th loss is : 0.255636\n",
      "3104-th loss is : 0.671884\n",
      "3105-th loss is : 0.696388\n",
      "3106-th loss is : 0.0700197\n",
      "3107-th loss is : 0.570775\n",
      "3108-th loss is : 0.115043\n",
      "3109-th loss is : 0.7277\n",
      "3110-th loss is : 0.219878\n",
      "3111-th loss is : 0.273119\n",
      "3112-th loss is : 0.408833\n",
      "3113-th loss is : 0.154522\n",
      "3114-th loss is : 0.407\n",
      "3115-th loss is : 0.633838\n",
      "3116-th loss is : 0.568765\n",
      "3117-th loss is : 0.255943\n",
      "3118-th loss is : 0.102446\n",
      "3119-th loss is : 0.0935527\n",
      "3120-th loss is : 0.370753\n",
      "3121-th loss is : 0.15492\n",
      "3122-th loss is : 0.768812\n",
      "3123-th loss is : 0.320022\n",
      "3124-th loss is : 0.401189\n",
      "3125-th loss is : 0.0750235\n",
      "3126-th loss is : 0.0924185\n",
      "3127-th loss is : 0.147099\n",
      "3128-th loss is : 0.706887\n",
      "3129-th loss is : 0.0601754\n",
      "3130-th loss is : 0.0657337\n",
      "3131-th loss is : 0.672038\n",
      "3132-th loss is : 0.679098\n",
      "3133-th loss is : 0.406135\n",
      "3134-th loss is : 0.08175\n",
      "3135-th loss is : 0.239455\n",
      "3136-th loss is : 0.661858\n",
      "3137-th loss is : 0.534409\n",
      "3138-th loss is : 0.596123\n",
      "3139-th loss is : 0.460058\n",
      "3140-th loss is : 0.175132\n",
      "3141-th loss is : 0.377183\n",
      "3142-th loss is : 0.19809\n",
      "3143-th loss is : 0.10895\n",
      "3144-th loss is : 0.592846\n",
      "3145-th loss is : 0.0626986\n",
      "3146-th loss is : 0.151091\n",
      "3147-th loss is : 0.669065\n",
      "3148-th loss is : 0.345465\n",
      "3149-th loss is : 0.123192\n",
      "3150-th loss is : 0.0998101\n",
      "3151-th loss is : 0.313073\n",
      "3152-th loss is : 0.19335\n",
      "3153-th loss is : 0.157299\n",
      "3154-th loss is : 0.20019\n",
      "3155-th loss is : 0.124434\n",
      "3156-th loss is : 0.233812\n",
      "3157-th loss is : 0.302672\n",
      "3158-th loss is : 0.19428\n",
      "3159-th loss is : 0.307676\n",
      "3160-th loss is : 0.193149\n",
      "3161-th loss is : 0.530878\n",
      "3162-th loss is : 0.682554\n",
      "3163-th loss is : 0.420432\n",
      "3164-th loss is : 0.486895\n",
      "3165-th loss is : 0.620668\n",
      "3166-th loss is : 0.180729\n",
      "3167-th loss is : 0.722127\n",
      "3168-th loss is : 0.534363\n",
      "3169-th loss is : 0.46522\n",
      "3170-th loss is : 0.118302\n",
      "3171-th loss is : 0.418768\n",
      "3172-th loss is : 0.572321\n",
      "3173-th loss is : 0.22095\n",
      "3174-th loss is : 0.164861\n",
      "3175-th loss is : 0.526213\n",
      "3176-th loss is : 0.322331\n",
      "3177-th loss is : 0.176437\n",
      "3178-th loss is : 0.247843\n",
      "3179-th loss is : 0.64231\n",
      "3180-th loss is : 0.7331\n",
      "3181-th loss is : 0.458157\n",
      "3182-th loss is : 0.738809\n",
      "3183-th loss is : 0.077187\n",
      "3184-th loss is : 0.155305\n",
      "3185-th loss is : 0.533022\n",
      "3186-th loss is : 0.100829\n",
      "3187-th loss is : 0.365795\n",
      "3188-th loss is : 0.250109\n",
      "3189-th loss is : 0.12519\n",
      "3190-th loss is : 0.188361\n",
      "3191-th loss is : 0.682009\n",
      "3192-th loss is : 0.410572\n",
      "3193-th loss is : 0.132633\n",
      "3194-th loss is : 0.270823\n",
      "3195-th loss is : 0.0955808\n",
      "3196-th loss is : 0.057596\n",
      "3197-th loss is : 0.46172\n",
      "3198-th loss is : 0.224522\n",
      "3199-th loss is : 0.189601\n",
      "3200-th loss is : 0.196605\n",
      "3201-th loss is : 0.511229\n",
      "3202-th loss is : 0.132794\n",
      "3203-th loss is : 0.220079\n",
      "3204-th loss is : 0.392908\n",
      "3205-th loss is : 0.601882\n",
      "3206-th loss is : 0.0934911\n",
      "3207-th loss is : 0.189191\n",
      "3208-th loss is : 0.303985\n",
      "3209-th loss is : 0.593278\n",
      "3210-th loss is : 0.363211\n",
      "3211-th loss is : 0.19869\n",
      "3212-th loss is : 0.0869967\n",
      "3213-th loss is : 0.063589\n",
      "3214-th loss is : 0.198967\n",
      "3215-th loss is : 0.0604625\n",
      "3216-th loss is : 0.174328\n",
      "3217-th loss is : 0.654761\n",
      "3218-th loss is : 0.0592597\n",
      "3219-th loss is : 0.584437\n",
      "3220-th loss is : 0.0971836\n",
      "3221-th loss is : 0.204662\n",
      "3222-th loss is : 0.342065\n",
      "3223-th loss is : 0.195318\n",
      "3224-th loss is : 0.534869\n",
      "3225-th loss is : 0.718391\n",
      "3226-th loss is : 0.416326\n",
      "3227-th loss is : 0.170882\n",
      "3228-th loss is : 0.470983\n",
      "3229-th loss is : 0.141171\n",
      "3230-th loss is : 0.604639\n",
      "3231-th loss is : 0.195108\n",
      "3232-th loss is : 0.311061\n",
      "3233-th loss is : 0.0641069\n",
      "3234-th loss is : 0.110028\n",
      "3235-th loss is : 0.0720953\n",
      "3236-th loss is : 0.557305\n",
      "3237-th loss is : 0.15302\n",
      "3238-th loss is : 0.265593\n",
      "3239-th loss is : 0.243054\n",
      "3240-th loss is : 0.398723\n",
      "3241-th loss is : 0.21631\n",
      "3242-th loss is : 0.0806838\n",
      "3243-th loss is : 0.158135\n",
      "3244-th loss is : 0.399402\n",
      "3245-th loss is : 0.0629704\n",
      "3246-th loss is : 0.506381\n",
      "3247-th loss is : 0.349568\n",
      "3248-th loss is : 0.38228\n",
      "3249-th loss is : 0.253804\n",
      "3250-th loss is : 0.488178\n",
      "3251-th loss is : 0.675643\n",
      "3252-th loss is : 0.14424\n",
      "3253-th loss is : 0.197727\n",
      "3254-th loss is : 0.179948\n",
      "3255-th loss is : 0.139257\n",
      "3256-th loss is : 0.335482\n",
      "3257-th loss is : 0.375135\n",
      "3258-th loss is : 0.339496\n",
      "3259-th loss is : 0.317099\n",
      "3260-th loss is : 0.532926\n",
      "3261-th loss is : 0.552987\n",
      "3262-th loss is : 0.129539\n",
      "3263-th loss is : 0.0802442\n",
      "3264-th loss is : 0.642705\n",
      "3265-th loss is : 0.217766\n",
      "3266-th loss is : 0.658852\n",
      "3267-th loss is : 0.609924\n",
      "3268-th loss is : 0.417322\n",
      "3269-th loss is : 0.110442\n",
      "3270-th loss is : 0.622718\n",
      "3271-th loss is : 0.312635\n",
      "3272-th loss is : 0.559096\n",
      "3273-th loss is : 0.68002\n",
      "3274-th loss is : 0.282329\n",
      "3275-th loss is : 0.127162\n",
      "3276-th loss is : 0.607826\n",
      "3277-th loss is : 0.515897\n",
      "3278-th loss is : 0.116214\n",
      "3279-th loss is : 0.450266\n",
      "3280-th loss is : 0.454653\n",
      "3281-th loss is : 0.141807\n",
      "3282-th loss is : 0.305381\n",
      "3283-th loss is : 0.2636\n",
      "3284-th loss is : 0.276083\n",
      "3285-th loss is : 0.448132\n",
      "3286-th loss is : 0.618577\n",
      "3287-th loss is : 0.0736402\n",
      "3288-th loss is : 0.0950513\n",
      "3289-th loss is : 0.150669\n",
      "3290-th loss is : 0.313167\n",
      "3291-th loss is : 0.288238\n",
      "3292-th loss is : 0.185295\n",
      "3293-th loss is : 0.0512599\n",
      "3294-th loss is : 0.383033\n",
      "3295-th loss is : 0.281423\n",
      "3296-th loss is : 0.638699\n",
      "3297-th loss is : 0.415121\n",
      "3298-th loss is : 0.0896392\n",
      "3299-th loss is : 0.328572\n",
      "3300-th loss is : 0.397745\n",
      "3301-th loss is : 0.102247\n",
      "3302-th loss is : 0.0578621\n",
      "3303-th loss is : 0.402034\n",
      "3304-th loss is : 0.395255\n",
      "3305-th loss is : 0.382193\n",
      "3306-th loss is : 0.524549\n",
      "3307-th loss is : 0.136499\n",
      "3308-th loss is : 0.427892\n",
      "3309-th loss is : 0.0567213\n",
      "3310-th loss is : 0.567122\n",
      "3311-th loss is : 0.467969\n",
      "3312-th loss is : 0.0583565\n",
      "3313-th loss is : 0.560855\n",
      "3314-th loss is : 0.167615\n",
      "3315-th loss is : 0.0565314\n",
      "3316-th loss is : 0.611778\n",
      "3317-th loss is : 0.239649\n",
      "3318-th loss is : 0.197575\n",
      "3319-th loss is : 0.172409\n",
      "3320-th loss is : 0.406638\n",
      "3321-th loss is : 0.325884\n",
      "3322-th loss is : 0.378774\n",
      "3323-th loss is : 0.465502\n",
      "3324-th loss is : 0.439565\n",
      "3325-th loss is : 0.107577\n",
      "3326-th loss is : 0.234457\n",
      "3327-th loss is : 0.28887\n",
      "3328-th loss is : 0.446917\n",
      "3329-th loss is : 0.110843\n",
      "3330-th loss is : 0.0595538\n",
      "3331-th loss is : 0.546291\n",
      "3332-th loss is : 0.167911\n",
      "3333-th loss is : 0.192995\n",
      "3334-th loss is : 0.294291\n",
      "3335-th loss is : 0.0502144\n",
      "3336-th loss is : 0.376066\n",
      "3337-th loss is : 0.0898075\n",
      "3338-th loss is : 0.683239\n",
      "3339-th loss is : 0.219563\n",
      "3340-th loss is : 0.561698\n",
      "3341-th loss is : 0.333604\n",
      "3342-th loss is : 0.48691\n",
      "3343-th loss is : 0.208566\n",
      "3344-th loss is : 0.332479\n",
      "3345-th loss is : 0.420412\n",
      "3346-th loss is : 0.544438\n",
      "3347-th loss is : 0.270506\n",
      "3348-th loss is : 0.254386\n",
      "3349-th loss is : 0.252837\n",
      "3350-th loss is : 0.625955\n",
      "3351-th loss is : 0.60692\n",
      "3352-th loss is : 0.0489664\n",
      "3353-th loss is : 0.490608\n",
      "3354-th loss is : 0.0555172\n",
      "3355-th loss is : 0.59803\n",
      "3356-th loss is : 0.441722\n",
      "3357-th loss is : 0.248189\n",
      "3358-th loss is : 0.14693\n",
      "3359-th loss is : 0.383835\n",
      "3360-th loss is : 0.631982\n",
      "3361-th loss is : 0.235709\n",
      "3362-th loss is : 0.679965\n",
      "3363-th loss is : 0.133787\n",
      "3364-th loss is : 0.271702\n",
      "3365-th loss is : 0.0531111\n",
      "3366-th loss is : 0.128675\n",
      "3367-th loss is : 0.160317\n",
      "3368-th loss is : 0.560214\n",
      "3369-th loss is : 0.290719\n",
      "3370-th loss is : 0.125269\n",
      "3371-th loss is : 0.311515\n",
      "3372-th loss is : 0.235806\n",
      "3373-th loss is : 0.673372\n",
      "3374-th loss is : 0.152039\n",
      "3375-th loss is : 0.223711\n",
      "3376-th loss is : 0.0971933\n",
      "3377-th loss is : 0.0542618\n",
      "3378-th loss is : 0.689618\n",
      "3379-th loss is : 0.408685\n",
      "3380-th loss is : 0.161894\n",
      "3381-th loss is : 0.0890358\n",
      "3382-th loss is : 0.104091\n",
      "3383-th loss is : 0.387278\n",
      "3384-th loss is : 0.17808\n",
      "3385-th loss is : 0.260308\n",
      "3386-th loss is : 0.360192\n",
      "3387-th loss is : 0.0480724\n",
      "3388-th loss is : 0.372608\n",
      "3389-th loss is : 0.130349\n",
      "3390-th loss is : 0.280972\n",
      "3391-th loss is : 0.0869987\n",
      "3392-th loss is : 0.0937229\n",
      "3393-th loss is : 0.177925\n",
      "3394-th loss is : 0.183945\n",
      "3395-th loss is : 0.433077\n",
      "3396-th loss is : 0.689037\n",
      "3397-th loss is : 0.545524\n",
      "3398-th loss is : 0.433147\n",
      "3399-th loss is : 0.586004\n",
      "3400-th loss is : 0.251287\n",
      "3401-th loss is : 0.192191\n",
      "3402-th loss is : 0.242118\n",
      "3403-th loss is : 0.273052\n",
      "3404-th loss is : 0.509574\n",
      "3405-th loss is : 0.657624\n",
      "3406-th loss is : 0.361852\n",
      "3407-th loss is : 0.271617\n",
      "3408-th loss is : 0.446376\n",
      "3409-th loss is : 0.53163\n",
      "3410-th loss is : 0.554514\n",
      "3411-th loss is : 0.503831\n",
      "3412-th loss is : 0.292047\n",
      "3413-th loss is : 0.329507\n",
      "3414-th loss is : 0.558993\n",
      "3415-th loss is : 0.522222\n",
      "3416-th loss is : 0.202177\n",
      "3417-th loss is : 0.334981\n",
      "3418-th loss is : 0.306722\n",
      "3419-th loss is : 0.273409\n",
      "3420-th loss is : 0.156548\n",
      "3421-th loss is : 0.552083\n",
      "3422-th loss is : 0.391065\n",
      "3423-th loss is : 0.0788675\n",
      "3424-th loss is : 0.383731\n",
      "3425-th loss is : 0.0814206\n",
      "3426-th loss is : 0.335573\n",
      "3427-th loss is : 0.194053\n",
      "3428-th loss is : 0.113702\n",
      "3429-th loss is : 0.427393\n",
      "3430-th loss is : 0.271253\n",
      "3431-th loss is : 0.616405\n",
      "3432-th loss is : 0.125135\n",
      "3433-th loss is : 0.122367\n",
      "3434-th loss is : 0.0924511\n",
      "3435-th loss is : 0.457628\n",
      "3436-th loss is : 0.506808\n",
      "3437-th loss is : 0.355959\n",
      "3438-th loss is : 0.317684\n",
      "3439-th loss is : 0.210707\n",
      "3440-th loss is : 0.110326\n",
      "3441-th loss is : 0.253842\n",
      "3442-th loss is : 0.535612\n",
      "3443-th loss is : 0.675751\n",
      "3444-th loss is : 0.0742333\n",
      "3445-th loss is : 0.47825\n",
      "3446-th loss is : 0.355699\n",
      "3447-th loss is : 0.114155\n",
      "3448-th loss is : 0.0649482\n",
      "3449-th loss is : 0.368639\n",
      "3450-th loss is : 0.432796\n",
      "3451-th loss is : 0.420813\n",
      "3452-th loss is : 0.204296\n",
      "3453-th loss is : 0.396755\n",
      "3454-th loss is : 0.137087\n",
      "3455-th loss is : 0.259314\n",
      "3456-th loss is : 0.55584\n",
      "3457-th loss is : 0.203049\n",
      "3458-th loss is : 0.132018\n",
      "3459-th loss is : 0.483813\n",
      "3460-th loss is : 0.165627\n",
      "3461-th loss is : 0.0876852\n",
      "3462-th loss is : 0.503379\n",
      "3463-th loss is : 0.0879977\n",
      "3464-th loss is : 0.084504\n",
      "3465-th loss is : 0.307966\n",
      "3466-th loss is : 0.130404\n",
      "3467-th loss is : 0.0971826\n",
      "3468-th loss is : 0.143788\n",
      "3469-th loss is : 0.349787\n",
      "3470-th loss is : 0.244391\n",
      "3471-th loss is : 0.22311\n",
      "3472-th loss is : 0.0479449\n",
      "3473-th loss is : 0.253632\n",
      "3474-th loss is : 0.0665125\n",
      "3475-th loss is : 0.110539\n",
      "3476-th loss is : 0.457966\n",
      "3477-th loss is : 0.453788\n",
      "3478-th loss is : 0.144648\n",
      "3479-th loss is : 0.506397\n",
      "3480-th loss is : 0.200595\n",
      "3481-th loss is : 0.0915976\n",
      "3482-th loss is : 0.0932735\n",
      "3483-th loss is : 0.593087\n",
      "3484-th loss is : 0.59932\n",
      "3485-th loss is : 0.064338\n",
      "3486-th loss is : 0.619372\n",
      "3487-th loss is : 0.434688\n",
      "3488-th loss is : 0.572199\n",
      "3489-th loss is : 0.646922\n",
      "3490-th loss is : 0.175951\n",
      "3491-th loss is : 0.273439\n",
      "3492-th loss is : 0.26898\n",
      "3493-th loss is : 0.36811\n",
      "3494-th loss is : 0.100811\n",
      "3495-th loss is : 0.225378\n",
      "3496-th loss is : 0.170972\n",
      "3497-th loss is : 0.277404\n",
      "3498-th loss is : 0.310286\n",
      "3499-th loss is : 0.238826\n",
      "3500-th loss is : 0.541296\n",
      "3501-th loss is : 0.0802422\n",
      "3502-th loss is : 0.313715\n",
      "3503-th loss is : 0.14094\n",
      "3504-th loss is : 0.302213\n",
      "3505-th loss is : 0.211819\n",
      "3506-th loss is : 0.0752939\n",
      "3507-th loss is : 0.418399\n",
      "3508-th loss is : 0.0600252\n",
      "3509-th loss is : 0.375558\n",
      "3510-th loss is : 0.283476\n",
      "3511-th loss is : 0.496997\n",
      "3512-th loss is : 0.084174\n",
      "3513-th loss is : 0.339361\n",
      "3514-th loss is : 0.316155\n",
      "3515-th loss is : 0.349867\n",
      "3516-th loss is : 0.493749\n",
      "3517-th loss is : 0.61841\n",
      "3518-th loss is : 0.0463521\n",
      "3519-th loss is : 0.0882791\n",
      "3520-th loss is : 0.0647167\n",
      "3521-th loss is : 0.245861\n",
      "3522-th loss is : 0.398213\n",
      "3523-th loss is : 0.107784\n",
      "3524-th loss is : 0.53719\n",
      "3525-th loss is : 0.241296\n",
      "3526-th loss is : 0.410299\n",
      "3527-th loss is : 0.201798\n",
      "3528-th loss is : 0.317896\n",
      "3529-th loss is : 0.447006\n",
      "3530-th loss is : 0.0683962\n",
      "3531-th loss is : 0.0603159\n",
      "3532-th loss is : 0.0786142\n",
      "3533-th loss is : 0.615021\n",
      "3534-th loss is : 0.198135\n",
      "3535-th loss is : 0.358553\n",
      "3536-th loss is : 0.197121\n",
      "3537-th loss is : 0.428873\n",
      "3538-th loss is : 0.540819\n",
      "3539-th loss is : 0.248006\n",
      "3540-th loss is : 0.19281\n",
      "3541-th loss is : 0.0489979\n",
      "3542-th loss is : 0.636045\n",
      "3543-th loss is : 0.373073\n",
      "3544-th loss is : 0.537231\n",
      "3545-th loss is : 0.557234\n",
      "3546-th loss is : 0.166236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547-th loss is : 0.173339\n",
      "3548-th loss is : 0.639838\n",
      "3549-th loss is : 0.286195\n",
      "3550-th loss is : 0.0610051\n",
      "3551-th loss is : 0.450307\n",
      "3552-th loss is : 0.203566\n",
      "3553-th loss is : 0.606693\n",
      "3554-th loss is : 0.155544\n",
      "3555-th loss is : 0.0424833\n",
      "3556-th loss is : 0.617183\n",
      "3557-th loss is : 0.619311\n",
      "3558-th loss is : 0.196234\n",
      "3559-th loss is : 0.389925\n",
      "3560-th loss is : 0.110968\n",
      "3561-th loss is : 0.0473095\n",
      "3562-th loss is : 0.514586\n",
      "3563-th loss is : 0.212632\n",
      "3564-th loss is : 0.514864\n",
      "3565-th loss is : 0.643109\n",
      "3566-th loss is : 0.583406\n",
      "3567-th loss is : 0.271082\n",
      "3568-th loss is : 0.168085\n",
      "3569-th loss is : 0.0596527\n",
      "3570-th loss is : 0.362186\n",
      "3571-th loss is : 0.569586\n",
      "3572-th loss is : 0.107902\n",
      "3573-th loss is : 0.0854389\n",
      "3574-th loss is : 0.137639\n",
      "3575-th loss is : 0.238485\n",
      "3576-th loss is : 0.102968\n",
      "3577-th loss is : 0.255731\n",
      "3578-th loss is : 0.401406\n",
      "3579-th loss is : 0.411571\n",
      "3580-th loss is : 0.10212\n",
      "3581-th loss is : 0.342458\n",
      "3582-th loss is : 0.133983\n",
      "3583-th loss is : 0.632387\n",
      "3584-th loss is : 0.0987207\n",
      "3585-th loss is : 0.049364\n",
      "3586-th loss is : 0.0800453\n",
      "3587-th loss is : 0.26487\n",
      "3588-th loss is : 0.41375\n",
      "3589-th loss is : 0.222872\n",
      "3590-th loss is : 0.10759\n",
      "3591-th loss is : 0.4403\n",
      "3592-th loss is : 0.200506\n",
      "3593-th loss is : 0.18167\n",
      "3594-th loss is : 0.305885\n",
      "3595-th loss is : 0.173345\n",
      "3596-th loss is : 0.326023\n",
      "3597-th loss is : 0.0763036\n",
      "3598-th loss is : 0.384243\n",
      "3599-th loss is : 0.35673\n",
      "3600-th loss is : 0.206505\n",
      "3601-th loss is : 0.270322\n",
      "3602-th loss is : 0.130921\n",
      "3603-th loss is : 0.0821038\n",
      "3604-th loss is : 0.13934\n",
      "3605-th loss is : 0.266734\n",
      "3606-th loss is : 0.130228\n",
      "3607-th loss is : 0.478058\n",
      "3608-th loss is : 0.355407\n",
      "3609-th loss is : 0.469685\n",
      "3610-th loss is : 0.478275\n",
      "3611-th loss is : 0.285529\n",
      "3612-th loss is : 0.310685\n",
      "3613-th loss is : 0.0548378\n",
      "3614-th loss is : 0.0391906\n",
      "3615-th loss is : 0.141428\n",
      "3616-th loss is : 0.400469\n",
      "3617-th loss is : 0.064768\n",
      "3618-th loss is : 0.113514\n",
      "3619-th loss is : 0.176607\n",
      "3620-th loss is : 0.395992\n",
      "3621-th loss is : 0.349103\n",
      "3622-th loss is : 0.138816\n",
      "3623-th loss is : 0.391092\n",
      "3624-th loss is : 0.593492\n",
      "3625-th loss is : 0.327953\n",
      "3626-th loss is : 0.38349\n",
      "3627-th loss is : 0.188631\n",
      "3628-th loss is : 0.138175\n",
      "3629-th loss is : 0.180922\n",
      "3630-th loss is : 0.431727\n",
      "3631-th loss is : 0.483751\n",
      "3632-th loss is : 0.181625\n",
      "3633-th loss is : 0.473264\n",
      "3634-th loss is : 0.0605887\n",
      "3635-th loss is : 0.192632\n",
      "3636-th loss is : 0.447777\n",
      "3637-th loss is : 0.359122\n",
      "3638-th loss is : 0.540247\n",
      "3639-th loss is : 0.0571006\n",
      "3640-th loss is : 0.441935\n",
      "3641-th loss is : 0.037841\n",
      "3642-th loss is : 0.431056\n",
      "3643-th loss is : 0.283371\n",
      "3644-th loss is : 0.13196\n",
      "3645-th loss is : 0.621102\n",
      "3646-th loss is : 0.0394291\n",
      "3647-th loss is : 0.614128\n",
      "3648-th loss is : 0.0732598\n",
      "3649-th loss is : 0.332216\n",
      "3650-th loss is : 0.386391\n",
      "3651-th loss is : 0.560246\n",
      "3652-th loss is : 0.443076\n",
      "3653-th loss is : 0.0988465\n",
      "3654-th loss is : 0.0469931\n",
      "3655-th loss is : 0.493281\n",
      "3656-th loss is : 0.548102\n",
      "3657-th loss is : 0.17737\n",
      "3658-th loss is : 0.115588\n",
      "3659-th loss is : 0.462691\n",
      "3660-th loss is : 0.463875\n",
      "3661-th loss is : 0.317619\n",
      "3662-th loss is : 0.547935\n",
      "3663-th loss is : 0.286028\n",
      "3664-th loss is : 0.0827766\n",
      "3665-th loss is : 0.376901\n",
      "3666-th loss is : 0.108926\n",
      "3667-th loss is : 0.110305\n",
      "3668-th loss is : 0.189575\n",
      "3669-th loss is : 0.0622139\n",
      "3670-th loss is : 0.236769\n",
      "3671-th loss is : 0.164473\n",
      "3672-th loss is : 0.301016\n",
      "3673-th loss is : 0.195741\n",
      "3674-th loss is : 0.318129\n",
      "3675-th loss is : 0.0968918\n",
      "3676-th loss is : 0.340853\n",
      "3677-th loss is : 0.569354\n",
      "3678-th loss is : 0.408308\n",
      "3679-th loss is : 0.279279\n",
      "3680-th loss is : 0.0533235\n",
      "3681-th loss is : 0.122949\n",
      "3682-th loss is : 0.147665\n",
      "3683-th loss is : 0.313978\n",
      "3684-th loss is : 0.193723\n",
      "3685-th loss is : 0.0688416\n",
      "3686-th loss is : 0.387014\n",
      "3687-th loss is : 0.465588\n",
      "3688-th loss is : 0.281385\n",
      "3689-th loss is : 0.460833\n",
      "3690-th loss is : 0.152038\n",
      "3691-th loss is : 0.603155\n",
      "3692-th loss is : 0.519445\n",
      "3693-th loss is : 0.194656\n",
      "3694-th loss is : 0.483731\n",
      "3695-th loss is : 0.263673\n",
      "3696-th loss is : 0.529306\n",
      "3697-th loss is : 0.116587\n",
      "3698-th loss is : 0.280139\n",
      "3699-th loss is : 0.464181\n",
      "3700-th loss is : 0.121453\n",
      "3701-th loss is : 0.298153\n",
      "3702-th loss is : 0.425204\n",
      "3703-th loss is : 0.463856\n",
      "3704-th loss is : 0.249813\n",
      "3705-th loss is : 0.0644127\n",
      "3706-th loss is : 0.430158\n",
      "3707-th loss is : 0.415605\n",
      "3708-th loss is : 0.29472\n",
      "3709-th loss is : 0.308151\n",
      "3710-th loss is : 0.429311\n",
      "3711-th loss is : 0.0349359\n",
      "3712-th loss is : 0.223062\n",
      "3713-th loss is : 0.423288\n",
      "3714-th loss is : 0.214211\n",
      "3715-th loss is : 0.49293\n",
      "3716-th loss is : 0.0746799\n",
      "3717-th loss is : 0.554974\n",
      "3718-th loss is : 0.201485\n",
      "3719-th loss is : 0.571678\n",
      "3720-th loss is : 0.197706\n",
      "3721-th loss is : 0.267175\n",
      "3722-th loss is : 0.181515\n",
      "3723-th loss is : 0.21451\n",
      "3724-th loss is : 0.599665\n",
      "3725-th loss is : 0.562444\n",
      "3726-th loss is : 0.19791\n",
      "3727-th loss is : 0.365333\n",
      "3728-th loss is : 0.0413204\n",
      "3729-th loss is : 0.0981149\n",
      "3730-th loss is : 0.263271\n",
      "3731-th loss is : 0.0856426\n",
      "3732-th loss is : 0.516011\n",
      "3733-th loss is : 0.065655\n",
      "3734-th loss is : 0.37822\n",
      "3735-th loss is : 0.0970858\n",
      "3736-th loss is : 0.504548\n",
      "3737-th loss is : 0.484569\n",
      "3738-th loss is : 0.0534862\n",
      "3739-th loss is : 0.175255\n",
      "3740-th loss is : 0.147953\n",
      "3741-th loss is : 0.437335\n",
      "3742-th loss is : 0.0357235\n",
      "3743-th loss is : 0.374732\n",
      "3744-th loss is : 0.186827\n",
      "3745-th loss is : 0.404574\n",
      "3746-th loss is : 0.138097\n",
      "3747-th loss is : 0.0457936\n",
      "3748-th loss is : 0.317106\n",
      "3749-th loss is : 0.283101\n",
      "3750-th loss is : 0.149465\n",
      "3751-th loss is : 0.191232\n",
      "3752-th loss is : 0.0461538\n",
      "3753-th loss is : 0.167978\n",
      "3754-th loss is : 0.347506\n",
      "3755-th loss is : 0.0516961\n",
      "3756-th loss is : 0.245059\n",
      "3757-th loss is : 0.0426295\n",
      "3758-th loss is : 0.128466\n",
      "3759-th loss is : 0.339788\n",
      "3760-th loss is : 0.277034\n",
      "3761-th loss is : 0.112457\n",
      "3762-th loss is : 0.0376521\n",
      "3763-th loss is : 0.150959\n",
      "3764-th loss is : 0.130932\n",
      "3765-th loss is : 0.150504\n",
      "3766-th loss is : 0.240249\n",
      "3767-th loss is : 0.250947\n",
      "3768-th loss is : 0.065555\n",
      "3769-th loss is : 0.0843885\n",
      "3770-th loss is : 0.0719932\n",
      "3771-th loss is : 0.51181\n",
      "3772-th loss is : 0.344065\n",
      "3773-th loss is : 0.0370843\n",
      "3774-th loss is : 0.532248\n",
      "3775-th loss is : 0.111173\n",
      "3776-th loss is : 0.110945\n",
      "3777-th loss is : 0.475595\n",
      "3778-th loss is : 0.520218\n",
      "3779-th loss is : 0.411855\n",
      "3780-th loss is : 0.058259\n",
      "3781-th loss is : 0.390062\n",
      "3782-th loss is : 0.257065\n",
      "3783-th loss is : 0.444073\n",
      "3784-th loss is : 0.541786\n",
      "3785-th loss is : 0.151114\n",
      "3786-th loss is : 0.0646134\n",
      "3787-th loss is : 0.097656\n",
      "3788-th loss is : 0.55027\n",
      "3789-th loss is : 0.283483\n",
      "3790-th loss is : 0.396783\n",
      "3791-th loss is : 0.0694172\n",
      "3792-th loss is : 0.170952\n",
      "3793-th loss is : 0.561859\n",
      "3794-th loss is : 0.0965566\n",
      "3795-th loss is : 0.397782\n",
      "3796-th loss is : 0.541243\n",
      "3797-th loss is : 0.0664794\n",
      "3798-th loss is : 0.303087\n",
      "3799-th loss is : 0.379956\n",
      "3800-th loss is : 0.0470469\n",
      "3801-th loss is : 0.318816\n",
      "3802-th loss is : 0.0803153\n",
      "3803-th loss is : 0.0667363\n",
      "3804-th loss is : 0.30074\n",
      "3805-th loss is : 0.0629747\n",
      "3806-th loss is : 0.0860881\n",
      "3807-th loss is : 0.525831\n",
      "3808-th loss is : 0.0431635\n",
      "3809-th loss is : 0.507618\n",
      "3810-th loss is : 0.317812\n",
      "3811-th loss is : 0.371884\n",
      "3812-th loss is : 0.150144\n",
      "3813-th loss is : 0.183959\n",
      "3814-th loss is : 0.115438\n",
      "3815-th loss is : 0.44345\n",
      "3816-th loss is : 0.116449\n",
      "3817-th loss is : 0.0440597\n",
      "3818-th loss is : 0.175516\n",
      "3819-th loss is : 0.263011\n",
      "3820-th loss is : 0.256294\n",
      "3821-th loss is : 0.328219\n",
      "3822-th loss is : 0.51625\n",
      "3823-th loss is : 0.300384\n",
      "3824-th loss is : 0.285692\n",
      "3825-th loss is : 0.434093\n",
      "3826-th loss is : 0.308855\n",
      "3827-th loss is : 0.437308\n",
      "3828-th loss is : 0.25155\n",
      "3829-th loss is : 0.183351\n",
      "3830-th loss is : 0.0383714\n",
      "3831-th loss is : 0.225938\n",
      "3832-th loss is : 0.222402\n",
      "3833-th loss is : 0.575877\n",
      "3834-th loss is : 0.108637\n",
      "3835-th loss is : 0.31417\n",
      "3836-th loss is : 0.129308\n",
      "3837-th loss is : 0.108848\n",
      "3838-th loss is : 0.352152\n",
      "3839-th loss is : 0.0752171\n",
      "3840-th loss is : 0.550549\n",
      "3841-th loss is : 0.413947\n",
      "3842-th loss is : 0.331958\n",
      "3843-th loss is : 0.403893\n",
      "3844-th loss is : 0.437296\n",
      "3845-th loss is : 0.214444\n",
      "3846-th loss is : 0.176787\n",
      "3847-th loss is : 0.289403\n",
      "3848-th loss is : 0.245956\n",
      "3849-th loss is : 0.435915\n",
      "3850-th loss is : 0.433303\n",
      "3851-th loss is : 0.550357\n",
      "3852-th loss is : 0.186019\n",
      "3853-th loss is : 0.191859\n",
      "3854-th loss is : 0.494626\n",
      "3855-th loss is : 0.379035\n",
      "3856-th loss is : 0.390346\n",
      "3857-th loss is : 0.0318619\n",
      "3858-th loss is : 0.153527\n",
      "3859-th loss is : 0.116007\n",
      "3860-th loss is : 0.0861623\n",
      "3861-th loss is : 0.168742\n",
      "3862-th loss is : 0.395651\n",
      "3863-th loss is : 0.531068\n",
      "3864-th loss is : 0.151861\n",
      "3865-th loss is : 0.266962\n",
      "3866-th loss is : 0.47544\n",
      "3867-th loss is : 0.179554\n",
      "3868-th loss is : 0.279514\n",
      "3869-th loss is : 0.10718\n",
      "3870-th loss is : 0.338432\n",
      "3871-th loss is : 0.0942007\n",
      "3872-th loss is : 0.221381\n",
      "3873-th loss is : 0.210805\n",
      "3874-th loss is : 0.158247\n",
      "3875-th loss is : 0.567349\n",
      "3876-th loss is : 0.235678\n",
      "3877-th loss is : 0.104473\n",
      "3878-th loss is : 0.241422\n",
      "3879-th loss is : 0.433917\n",
      "3880-th loss is : 0.111979\n",
      "3881-th loss is : 0.40617\n",
      "3882-th loss is : 0.46137\n",
      "3883-th loss is : 0.367855\n",
      "3884-th loss is : 0.205513\n",
      "3885-th loss is : 0.559663\n",
      "3886-th loss is : 0.266467\n",
      "3887-th loss is : 0.11442\n",
      "3888-th loss is : 0.440495\n",
      "3889-th loss is : 0.352977\n",
      "3890-th loss is : 0.141806\n",
      "3891-th loss is : 0.169651\n",
      "3892-th loss is : 0.0886386\n",
      "3893-th loss is : 0.277325\n",
      "3894-th loss is : 0.098651\n",
      "3895-th loss is : 0.341261\n",
      "3896-th loss is : 0.0342106\n",
      "3897-th loss is : 0.0838407\n",
      "3898-th loss is : 0.432949\n",
      "3899-th loss is : 0.0490013\n",
      "3900-th loss is : 0.406164\n",
      "3901-th loss is : 0.195725\n",
      "3902-th loss is : 0.158159\n",
      "3903-th loss is : 0.0363984\n",
      "3904-th loss is : 0.260628\n",
      "3905-th loss is : 0.402171\n",
      "3906-th loss is : 0.0608409\n",
      "3907-th loss is : 0.367835\n",
      "3908-th loss is : 0.164827\n",
      "3909-th loss is : 0.243332\n",
      "3910-th loss is : 0.32909\n",
      "3911-th loss is : 0.22872\n",
      "3912-th loss is : 0.353829\n",
      "3913-th loss is : 0.44053\n",
      "3914-th loss is : 0.461515\n",
      "3915-th loss is : 0.377099\n",
      "3916-th loss is : 0.0812235\n",
      "3917-th loss is : 0.103072\n",
      "3918-th loss is : 0.466594\n",
      "3919-th loss is : 0.219445\n",
      "3920-th loss is : 0.399605\n",
      "3921-th loss is : 0.288291\n",
      "3922-th loss is : 0.207538\n",
      "3923-th loss is : 0.0782162\n",
      "3924-th loss is : 0.0490317\n",
      "3925-th loss is : 0.319464\n",
      "3926-th loss is : 0.555751\n",
      "3927-th loss is : 0.434656\n",
      "3928-th loss is : 0.27909\n",
      "3929-th loss is : 0.405179\n",
      "3930-th loss is : 0.323088\n",
      "3931-th loss is : 0.0707649\n",
      "3932-th loss is : 0.0342392\n",
      "3933-th loss is : 0.541457\n",
      "3934-th loss is : 0.065167\n",
      "3935-th loss is : 0.417183\n",
      "3936-th loss is : 0.50005\n",
      "3937-th loss is : 0.465716\n",
      "3938-th loss is : 0.169103\n",
      "3939-th loss is : 0.0898308\n",
      "3940-th loss is : 0.319933\n",
      "3941-th loss is : 0.0859801\n",
      "3942-th loss is : 0.188374\n",
      "3943-th loss is : 0.3748\n",
      "3944-th loss is : 0.0879303\n",
      "3945-th loss is : 0.0321044\n",
      "3946-th loss is : 0.264294\n",
      "3947-th loss is : 0.505164\n",
      "3948-th loss is : 0.0593878\n",
      "3949-th loss is : 0.347425\n",
      "3950-th loss is : 0.0913153\n",
      "3951-th loss is : 0.214098\n",
      "3952-th loss is : 0.138027\n",
      "3953-th loss is : 0.11506\n",
      "3954-th loss is : 0.532459\n",
      "3955-th loss is : 0.309092\n",
      "3956-th loss is : 0.131658\n",
      "3957-th loss is : 0.351465\n",
      "3958-th loss is : 0.299878\n",
      "3959-th loss is : 0.067846\n",
      "3960-th loss is : 0.206546\n",
      "3961-th loss is : 0.120935\n",
      "3962-th loss is : 0.103355\n",
      "3963-th loss is : 0.229517\n",
      "3964-th loss is : 0.22334\n",
      "3965-th loss is : 0.312795\n",
      "3966-th loss is : 0.207763\n",
      "3967-th loss is : 0.258181\n",
      "3968-th loss is : 0.471527\n",
      "3969-th loss is : 0.0964713\n",
      "3970-th loss is : 0.504726\n",
      "3971-th loss is : 0.0734725\n",
      "3972-th loss is : 0.183183\n",
      "3973-th loss is : 0.283627\n",
      "3974-th loss is : 0.207171\n",
      "3975-th loss is : 0.097132\n",
      "3976-th loss is : 0.247018\n",
      "3977-th loss is : 0.383321\n",
      "3978-th loss is : 0.24153\n",
      "3979-th loss is : 0.338382\n",
      "3980-th loss is : 0.0347127\n",
      "3981-th loss is : 0.0321759\n",
      "3982-th loss is : 0.507892\n",
      "3983-th loss is : 0.258329\n",
      "3984-th loss is : 0.0812229\n",
      "3985-th loss is : 0.135034\n",
      "3986-th loss is : 0.294931\n",
      "3987-th loss is : 0.199348\n",
      "3988-th loss is : 0.0805492\n",
      "3989-th loss is : 0.144457\n",
      "3990-th loss is : 0.446165\n",
      "3991-th loss is : 0.0970509\n",
      "3992-th loss is : 0.0347966\n",
      "3993-th loss is : 0.256183\n",
      "3994-th loss is : 0.249216\n",
      "3995-th loss is : 0.0624283\n",
      "3996-th loss is : 0.373128\n",
      "3997-th loss is : 0.372127\n",
      "3998-th loss is : 0.0984491\n",
      "3999-th loss is : 0.2608\n",
      "4000-th loss is : 0.48763\n",
      "4001-th loss is : 0.0499026\n",
      "4002-th loss is : 0.0865924\n",
      "4003-th loss is : 0.235616\n",
      "4004-th loss is : 0.28733\n",
      "4005-th loss is : 0.106716\n",
      "4006-th loss is : 0.391636\n",
      "4007-th loss is : 0.459529\n",
      "4008-th loss is : 0.0518452\n",
      "4009-th loss is : 0.354225\n",
      "4010-th loss is : 0.435872\n",
      "4011-th loss is : 0.0651928\n",
      "4012-th loss is : 0.424078\n",
      "4013-th loss is : 0.301736\n",
      "4014-th loss is : 0.429224\n",
      "4015-th loss is : 0.0915116\n",
      "4016-th loss is : 0.217838\n",
      "4017-th loss is : 0.13772\n",
      "4018-th loss is : 0.439529\n",
      "4019-th loss is : 0.455837\n",
      "4020-th loss is : 0.424063\n",
      "4021-th loss is : 0.134111\n",
      "4022-th loss is : 0.0700247\n",
      "4023-th loss is : 0.0802265\n",
      "4024-th loss is : 0.0469124\n",
      "4025-th loss is : 0.0481379\n",
      "4026-th loss is : 0.130103\n",
      "4027-th loss is : 0.0302147\n",
      "4028-th loss is : 0.51414\n",
      "4029-th loss is : 0.521977\n",
      "4030-th loss is : 0.333246\n",
      "4031-th loss is : 0.0665823\n",
      "4032-th loss is : 0.375121\n",
      "4033-th loss is : 0.302898\n",
      "4034-th loss is : 0.318425\n",
      "4035-th loss is : 0.461189\n",
      "4036-th loss is : 0.0984033\n",
      "4037-th loss is : 0.111787\n",
      "4038-th loss is : 0.101896\n",
      "4039-th loss is : 0.143573\n",
      "4040-th loss is : 0.137047\n",
      "4041-th loss is : 0.318702\n",
      "4042-th loss is : 0.13385\n",
      "4043-th loss is : 0.256369\n",
      "4044-th loss is : 0.320531\n",
      "4045-th loss is : 0.172496\n",
      "4046-th loss is : 0.276564\n",
      "4047-th loss is : 0.343808\n",
      "4048-th loss is : 0.166706\n",
      "4049-th loss is : 0.0331799\n",
      "4050-th loss is : 0.200872\n",
      "4051-th loss is : 0.180129\n",
      "4052-th loss is : 0.413971\n",
      "4053-th loss is : 0.279696\n",
      "4054-th loss is : 0.172692\n",
      "4055-th loss is : 0.480682\n",
      "4056-th loss is : 0.405887\n",
      "4057-th loss is : 0.275167\n",
      "4058-th loss is : 0.277419\n",
      "4059-th loss is : 0.244946\n",
      "4060-th loss is : 0.491513\n",
      "4061-th loss is : 0.0638388\n",
      "4062-th loss is : 0.173142\n",
      "4063-th loss is : 0.22831\n",
      "4064-th loss is : 0.357597\n",
      "4065-th loss is : 0.36364\n",
      "4066-th loss is : 0.145603\n",
      "4067-th loss is : 0.402255\n",
      "4068-th loss is : 0.511962\n",
      "4069-th loss is : 0.159513\n",
      "4070-th loss is : 0.102388\n",
      "4071-th loss is : 0.0794861\n",
      "4072-th loss is : 0.291919\n",
      "4073-th loss is : 0.18024\n",
      "4074-th loss is : 0.145495\n",
      "4075-th loss is : 0.434322\n",
      "4076-th loss is : 0.101989\n",
      "4077-th loss is : 0.172489\n",
      "4078-th loss is : 0.226878\n",
      "4079-th loss is : 0.514303\n",
      "4080-th loss is : 0.239583\n",
      "4081-th loss is : 0.133089\n",
      "4082-th loss is : 0.156554\n",
      "4083-th loss is : 0.0340093\n",
      "4084-th loss is : 0.425011\n",
      "4085-th loss is : 0.381164\n",
      "4086-th loss is : 0.383508\n",
      "4087-th loss is : 0.0943252\n",
      "4088-th loss is : 0.0485498\n",
      "4089-th loss is : 0.238596\n",
      "4090-th loss is : 0.0621693\n",
      "4091-th loss is : 0.217213\n",
      "4092-th loss is : 0.0309828\n",
      "4093-th loss is : 0.433315\n",
      "4094-th loss is : 0.0974615\n",
      "4095-th loss is : 0.106118\n",
      "4096-th loss is : 0.059789\n",
      "4097-th loss is : 0.220563\n",
      "4098-th loss is : 0.32345\n",
      "4099-th loss is : 0.0514449\n",
      "4100-th loss is : 0.355522\n",
      "4101-th loss is : 0.195761\n",
      "4102-th loss is : 0.473038\n",
      "4103-th loss is : 0.232481\n",
      "4104-th loss is : 0.0971425\n",
      "4105-th loss is : 0.0752416\n",
      "4106-th loss is : 0.028157\n",
      "4107-th loss is : 0.341137\n",
      "4108-th loss is : 0.371074\n",
      "4109-th loss is : 0.0905823\n",
      "4110-th loss is : 0.18967\n",
      "4111-th loss is : 0.348208\n",
      "4112-th loss is : 0.0514423\n",
      "4113-th loss is : 0.465133\n",
      "4114-th loss is : 0.0587436\n",
      "4115-th loss is : 0.168861\n",
      "4116-th loss is : 0.0280472\n",
      "4117-th loss is : 0.487278\n",
      "4118-th loss is : 0.230248\n",
      "4119-th loss is : 0.144703\n",
      "4120-th loss is : 0.377196\n",
      "4121-th loss is : 0.282067\n",
      "4122-th loss is : 0.0812985\n",
      "4123-th loss is : 0.116531\n",
      "4124-th loss is : 0.150049\n",
      "4125-th loss is : 0.15125\n",
      "4126-th loss is : 0.0861781\n",
      "4127-th loss is : 0.256372\n",
      "4128-th loss is : 0.110843\n",
      "4129-th loss is : 0.0682699\n",
      "4130-th loss is : 0.179976\n",
      "4131-th loss is : 0.363691\n",
      "4132-th loss is : 0.0946134\n",
      "4133-th loss is : 0.448152\n",
      "4134-th loss is : 0.490773\n",
      "4135-th loss is : 0.196567\n",
      "4136-th loss is : 0.46605\n",
      "4137-th loss is : 0.424608\n",
      "4138-th loss is : 0.168063\n",
      "4139-th loss is : 0.0937581\n",
      "4140-th loss is : 0.501414\n",
      "4141-th loss is : 0.0942462\n",
      "4142-th loss is : 0.180219\n",
      "4143-th loss is : 0.458749\n",
      "4144-th loss is : 0.168907\n",
      "4145-th loss is : 0.027735\n",
      "4146-th loss is : 0.072268\n",
      "4147-th loss is : 0.150811\n",
      "4148-th loss is : 0.17022\n",
      "4149-th loss is : 0.236853\n",
      "4150-th loss is : 0.317094\n",
      "4151-th loss is : 0.0914852\n",
      "4152-th loss is : 0.116522\n",
      "4153-th loss is : 0.155808\n",
      "4154-th loss is : 0.244316\n",
      "4155-th loss is : 0.0967621\n",
      "4156-th loss is : 0.226266\n",
      "4157-th loss is : 0.0549832\n",
      "4158-th loss is : 0.254246\n",
      "4159-th loss is : 0.042856\n",
      "4160-th loss is : 0.252668\n",
      "4161-th loss is : 0.436759\n",
      "4162-th loss is : 0.452406\n",
      "4163-th loss is : 0.0693105\n",
      "4164-th loss is : 0.174862\n",
      "4165-th loss is : 0.123052\n",
      "4166-th loss is : 0.181268\n",
      "4167-th loss is : 0.193419\n",
      "4168-th loss is : 0.178628\n",
      "4169-th loss is : 0.0810365\n",
      "4170-th loss is : 0.358034\n",
      "4171-th loss is : 0.141772\n",
      "4172-th loss is : 0.189209\n",
      "4173-th loss is : 0.222707\n",
      "4174-th loss is : 0.198148\n",
      "4175-th loss is : 0.122487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4176-th loss is : 0.317873\n",
      "4177-th loss is : 0.0987888\n",
      "4178-th loss is : 0.0420147\n",
      "4179-th loss is : 0.317983\n",
      "4180-th loss is : 0.0610476\n",
      "4181-th loss is : 0.399261\n",
      "4182-th loss is : 0.0226417\n",
      "4183-th loss is : 0.0514413\n",
      "4184-th loss is : 0.0805631\n",
      "4185-th loss is : 0.0438234\n",
      "4186-th loss is : 0.0947148\n",
      "4187-th loss is : 0.201061\n",
      "4188-th loss is : 0.481999\n",
      "4189-th loss is : 0.147444\n",
      "4190-th loss is : 0.400966\n",
      "4191-th loss is : 0.319399\n",
      "4192-th loss is : 0.0609363\n",
      "4193-th loss is : 0.022091\n",
      "4194-th loss is : 0.422322\n",
      "4195-th loss is : 0.22383\n",
      "4196-th loss is : 0.116307\n",
      "4197-th loss is : 0.0721759\n",
      "4198-th loss is : 0.46265\n",
      "4199-th loss is : 0.0314781\n",
      "4200-th loss is : 0.304244\n",
      "4201-th loss is : 0.474389\n",
      "4202-th loss is : 0.0218225\n",
      "4203-th loss is : 0.0654591\n",
      "4204-th loss is : 0.148444\n",
      "4205-th loss is : 0.370409\n",
      "4206-th loss is : 0.151153\n",
      "4207-th loss is : 0.242515\n",
      "4208-th loss is : 0.0254099\n",
      "4209-th loss is : 0.314377\n",
      "4210-th loss is : 0.138438\n",
      "4211-th loss is : 0.305154\n",
      "4212-th loss is : 0.0364593\n",
      "4213-th loss is : 0.133346\n",
      "4214-th loss is : 0.352247\n",
      "4215-th loss is : 0.250497\n",
      "4216-th loss is : 0.414239\n",
      "4217-th loss is : 0.193901\n",
      "4218-th loss is : 0.0495074\n",
      "4219-th loss is : 0.429971\n",
      "4220-th loss is : 0.268182\n",
      "4221-th loss is : 0.201265\n",
      "4222-th loss is : 0.036897\n",
      "4223-th loss is : 0.372442\n",
      "4224-th loss is : 0.073396\n",
      "4225-th loss is : 0.0510386\n",
      "4226-th loss is : 0.145215\n",
      "4227-th loss is : 0.0953593\n",
      "4228-th loss is : 0.18371\n",
      "4229-th loss is : 0.355734\n",
      "4230-th loss is : 0.0429641\n",
      "4231-th loss is : 0.0546552\n",
      "4232-th loss is : 0.0387546\n",
      "4233-th loss is : 0.168914\n",
      "4234-th loss is : 0.215138\n",
      "4235-th loss is : 0.435611\n",
      "4236-th loss is : 0.457503\n",
      "4237-th loss is : 0.0274704\n",
      "4238-th loss is : 0.183911\n",
      "4239-th loss is : 0.20674\n",
      "4240-th loss is : 0.158072\n",
      "4241-th loss is : 0.444674\n",
      "4242-th loss is : 0.318357\n",
      "4243-th loss is : 0.134894\n",
      "4244-th loss is : 0.118901\n",
      "4245-th loss is : 0.0873342\n",
      "4246-th loss is : 0.0365364\n",
      "4247-th loss is : 0.0291945\n",
      "4248-th loss is : 0.141271\n",
      "4249-th loss is : 0.146017\n",
      "4250-th loss is : 0.109442\n",
      "4251-th loss is : 0.0678273\n",
      "4252-th loss is : 0.0232233\n",
      "4253-th loss is : 0.028564\n",
      "4254-th loss is : 0.0758289\n",
      "4255-th loss is : 0.128101\n",
      "4256-th loss is : 0.323399\n",
      "4257-th loss is : 0.144833\n",
      "4258-th loss is : 0.238252\n",
      "4259-th loss is : 0.105297\n",
      "4260-th loss is : 0.145493\n",
      "4261-th loss is : 0.158684\n",
      "4262-th loss is : 0.135159\n",
      "4263-th loss is : 0.135147\n",
      "4264-th loss is : 0.119927\n",
      "4265-th loss is : 0.364863\n",
      "4266-th loss is : 0.0233408\n",
      "4267-th loss is : 0.0204956\n",
      "4268-th loss is : 0.129913\n",
      "4269-th loss is : 0.172895\n",
      "4270-th loss is : 0.331517\n",
      "4271-th loss is : 0.0691142\n",
      "4272-th loss is : 0.170126\n",
      "4273-th loss is : 0.409141\n",
      "4274-th loss is : 0.111131\n",
      "4275-th loss is : 0.0727265\n",
      "4276-th loss is : 0.0191614\n",
      "4277-th loss is : 0.256755\n",
      "4278-th loss is : 0.304273\n",
      "4279-th loss is : 0.305299\n",
      "4280-th loss is : 0.0373342\n",
      "4281-th loss is : 0.200423\n",
      "4282-th loss is : 0.220244\n",
      "4283-th loss is : 0.0576963\n",
      "4284-th loss is : 0.430088\n",
      "4285-th loss is : 0.028061\n",
      "4286-th loss is : 0.0720103\n",
      "4287-th loss is : 0.327296\n",
      "4288-th loss is : 0.103098\n",
      "4289-th loss is : 0.0463683\n",
      "4290-th loss is : 0.026318\n",
      "4291-th loss is : 0.0301796\n",
      "4292-th loss is : 0.198094\n",
      "4293-th loss is : 0.378753\n",
      "4294-th loss is : 0.0315392\n",
      "4295-th loss is : 0.160052\n",
      "4296-th loss is : 0.1185\n",
      "4297-th loss is : 0.362899\n",
      "4298-th loss is : 0.0182832\n",
      "4299-th loss is : 0.198722\n",
      "4300-th loss is : 0.393487\n",
      "4301-th loss is : 0.126299\n",
      "4302-th loss is : 0.0568893\n",
      "4303-th loss is : 0.0616787\n",
      "4304-th loss is : 0.380558\n",
      "4305-th loss is : 0.159793\n",
      "4306-th loss is : 0.307128\n",
      "4307-th loss is : 0.463528\n",
      "4308-th loss is : 0.311468\n",
      "4309-th loss is : 0.0370088\n",
      "4310-th loss is : 0.0171272\n",
      "4311-th loss is : 0.195611\n",
      "4312-th loss is : 0.303001\n",
      "4313-th loss is : 0.0444738\n",
      "4314-th loss is : 0.0631609\n",
      "4315-th loss is : 0.0324808\n",
      "4316-th loss is : 0.0517706\n",
      "4317-th loss is : 0.127989\n",
      "4318-th loss is : 0.103624\n",
      "4319-th loss is : 0.0464418\n",
      "4320-th loss is : 0.253438\n",
      "4321-th loss is : 0.133361\n",
      "4322-th loss is : 0.136546\n",
      "4323-th loss is : 0.0291654\n",
      "4324-th loss is : 0.362762\n",
      "4325-th loss is : 0.180265\n",
      "4326-th loss is : 0.348464\n",
      "4327-th loss is : 0.18625\n",
      "4328-th loss is : 0.179492\n",
      "4329-th loss is : 0.117415\n",
      "4330-th loss is : 0.0518693\n",
      "4331-th loss is : 0.0801501\n",
      "4332-th loss is : 0.35891\n",
      "4333-th loss is : 0.051982\n",
      "4334-th loss is : 0.381352\n",
      "4335-th loss is : 0.0233864\n",
      "4336-th loss is : 0.184219\n",
      "4337-th loss is : 0.322769\n",
      "4338-th loss is : 0.0488238\n",
      "4339-th loss is : 0.0781413\n",
      "4340-th loss is : 0.0385087\n",
      "4341-th loss is : 0.0513636\n",
      "4342-th loss is : 0.0380539\n",
      "4343-th loss is : 0.0935507\n",
      "4344-th loss is : 0.284135\n",
      "4345-th loss is : 0.0328945\n",
      "4346-th loss is : 0.248473\n",
      "4347-th loss is : 0.135436\n",
      "4348-th loss is : 0.313719\n",
      "4349-th loss is : 0.281722\n",
      "4350-th loss is : 0.0352333\n",
      "4351-th loss is : 0.260344\n",
      "4352-th loss is : 0.197143\n",
      "4353-th loss is : 0.293925\n",
      "4354-th loss is : 0.0318044\n",
      "4355-th loss is : 0.201292\n",
      "4356-th loss is : 0.024055\n",
      "4357-th loss is : 0.0652802\n",
      "4358-th loss is : 0.186294\n",
      "4359-th loss is : 0.131243\n",
      "4360-th loss is : 0.165473\n",
      "4361-th loss is : 0.17549\n",
      "4362-th loss is : 0.402817\n",
      "4363-th loss is : 0.227085\n",
      "4364-th loss is : 0.132999\n",
      "4365-th loss is : 0.288263\n",
      "4366-th loss is : 0.147686\n",
      "4367-th loss is : 0.0324107\n",
      "4368-th loss is : 0.262689\n",
      "4369-th loss is : 0.230561\n",
      "4370-th loss is : 0.162089\n",
      "4371-th loss is : 0.272793\n",
      "4372-th loss is : 0.203093\n",
      "4373-th loss is : 0.130083\n",
      "4374-th loss is : 0.186548\n",
      "4375-th loss is : 0.294541\n",
      "4376-th loss is : 0.142397\n",
      "4377-th loss is : 0.324778\n",
      "4378-th loss is : 0.223451\n",
      "4379-th loss is : 0.114858\n",
      "4380-th loss is : 0.255325\n",
      "4381-th loss is : 0.429523\n",
      "4382-th loss is : 0.0809602\n",
      "4383-th loss is : 0.26145\n",
      "4384-th loss is : 0.359517\n",
      "4385-th loss is : 0.0817784\n",
      "4386-th loss is : 0.187604\n",
      "4387-th loss is : 0.197391\n",
      "4388-th loss is : 0.0166624\n",
      "4389-th loss is : 0.0444807\n",
      "4390-th loss is : 0.169817\n",
      "4391-th loss is : 0.356918\n",
      "4392-th loss is : 0.0258068\n",
      "4393-th loss is : 0.33482\n",
      "4394-th loss is : 0.0233834\n",
      "4395-th loss is : 0.111053\n",
      "4396-th loss is : 0.114332\n",
      "4397-th loss is : 0.223563\n",
      "4398-th loss is : 0.125238\n",
      "4399-th loss is : 0.389163\n",
      "4400-th loss is : 0.145958\n",
      "4401-th loss is : 0.189748\n",
      "4402-th loss is : 0.0282486\n",
      "4403-th loss is : 0.427162\n",
      "4404-th loss is : 0.45567\n",
      "4405-th loss is : 0.454205\n",
      "4406-th loss is : 0.039364\n",
      "4407-th loss is : 0.0262686\n",
      "4408-th loss is : 0.237096\n",
      "4409-th loss is : 0.0187921\n",
      "4410-th loss is : 0.262931\n",
      "4411-th loss is : 0.374055\n",
      "4412-th loss is : 0.036943\n",
      "4413-th loss is : 0.434895\n",
      "4414-th loss is : 0.244636\n",
      "4415-th loss is : 0.339442\n",
      "4416-th loss is : 0.0274957\n",
      "4417-th loss is : 0.457736\n",
      "4418-th loss is : 0.14738\n",
      "4419-th loss is : 0.155594\n",
      "4420-th loss is : 0.337652\n",
      "4421-th loss is : 0.36648\n",
      "4422-th loss is : 0.0486472\n",
      "4423-th loss is : 0.44415\n",
      "4424-th loss is : 0.248336\n",
      "4425-th loss is : 0.277799\n",
      "4426-th loss is : 0.143649\n",
      "4427-th loss is : 0.0635057\n",
      "4428-th loss is : 0.368258\n",
      "4429-th loss is : 0.0331094\n",
      "4430-th loss is : 0.332413\n",
      "4431-th loss is : 0.0234871\n",
      "4432-th loss is : 0.405025\n",
      "4433-th loss is : 0.305156\n",
      "4434-th loss is : 0.14823\n",
      "4435-th loss is : 0.0268664\n",
      "4436-th loss is : 0.0745306\n",
      "4437-th loss is : 0.376897\n",
      "4438-th loss is : 0.294391\n",
      "4439-th loss is : 0.383432\n",
      "4440-th loss is : 0.23352\n",
      "4441-th loss is : 0.0493447\n",
      "4442-th loss is : 0.375082\n",
      "4443-th loss is : 0.0245854\n",
      "4444-th loss is : 0.315879\n",
      "4445-th loss is : 0.150759\n",
      "4446-th loss is : 0.0423098\n",
      "4447-th loss is : 0.151159\n",
      "4448-th loss is : 0.0276768\n",
      "4449-th loss is : 0.0318266\n",
      "4450-th loss is : 0.438724\n",
      "4451-th loss is : 0.0221871\n",
      "4452-th loss is : 0.0228475\n",
      "4453-th loss is : 0.257828\n",
      "4454-th loss is : 0.131858\n",
      "4455-th loss is : 0.291125\n",
      "4456-th loss is : 0.0744133\n",
      "4457-th loss is : 0.0943848\n",
      "4458-th loss is : 0.105374\n",
      "4459-th loss is : 0.0238202\n",
      "4460-th loss is : 0.288139\n",
      "4461-th loss is : 0.354404\n",
      "4462-th loss is : 0.0913143\n",
      "4463-th loss is : 0.0291328\n",
      "4464-th loss is : 0.203987\n",
      "4465-th loss is : 0.356894\n",
      "4466-th loss is : 0.369313\n",
      "4467-th loss is : 0.227643\n",
      "4468-th loss is : 0.197297\n",
      "4469-th loss is : 0.220596\n",
      "4470-th loss is : 0.189954\n",
      "4471-th loss is : 0.295969\n",
      "4472-th loss is : 0.381165\n",
      "4473-th loss is : 0.126377\n",
      "4474-th loss is : 0.270916\n",
      "4475-th loss is : 0.208377\n",
      "4476-th loss is : 0.0162592\n",
      "4477-th loss is : 0.336667\n",
      "4478-th loss is : 0.0293123\n",
      "4479-th loss is : 0.0621696\n",
      "4480-th loss is : 0.104705\n",
      "4481-th loss is : 0.38565\n",
      "4482-th loss is : 0.100658\n",
      "4483-th loss is : 0.0594325\n",
      "4484-th loss is : 0.357916\n",
      "4485-th loss is : 0.266657\n",
      "4486-th loss is : 0.40123\n",
      "4487-th loss is : 0.43228\n",
      "4488-th loss is : 0.138213\n",
      "4489-th loss is : 0.022002\n",
      "4490-th loss is : 0.234637\n",
      "4491-th loss is : 0.277754\n",
      "4492-th loss is : 0.0769447\n",
      "4493-th loss is : 0.314642\n",
      "4494-th loss is : 0.283186\n",
      "4495-th loss is : 0.415286\n",
      "4496-th loss is : 0.428628\n",
      "4497-th loss is : 0.428721\n",
      "4498-th loss is : 0.0156243\n",
      "4499-th loss is : 0.440127\n",
      "4500-th loss is : 0.367595\n",
      "4501-th loss is : 0.431344\n",
      "4502-th loss is : 0.0725886\n",
      "4503-th loss is : 0.210218\n",
      "4504-th loss is : 0.274414\n",
      "4505-th loss is : 0.0137749\n",
      "4506-th loss is : 0.071051\n",
      "4507-th loss is : 0.0524204\n",
      "4508-th loss is : 0.267563\n",
      "4509-th loss is : 0.208186\n",
      "4510-th loss is : 0.313237\n",
      "4511-th loss is : 0.188272\n",
      "4512-th loss is : 0.0317982\n",
      "4513-th loss is : 0.042721\n",
      "4514-th loss is : 0.0672389\n",
      "4515-th loss is : 0.31259\n",
      "4516-th loss is : 0.143381\n",
      "4517-th loss is : 0.223913\n",
      "4518-th loss is : 0.0618412\n",
      "4519-th loss is : 0.0648879\n",
      "4520-th loss is : 0.0937186\n",
      "4521-th loss is : 0.10841\n",
      "4522-th loss is : 0.340783\n",
      "4523-th loss is : 0.0989256\n",
      "4524-th loss is : 0.151742\n",
      "4525-th loss is : 0.0167976\n",
      "4526-th loss is : 0.374543\n",
      "4527-th loss is : 0.350307\n",
      "4528-th loss is : 0.208512\n",
      "4529-th loss is : 0.0963941\n",
      "4530-th loss is : 0.019938\n",
      "4531-th loss is : 0.13855\n",
      "4532-th loss is : 0.127146\n",
      "4533-th loss is : 0.317394\n",
      "4534-th loss is : 0.128257\n",
      "4535-th loss is : 0.130925\n",
      "4536-th loss is : 0.0969444\n",
      "4537-th loss is : 0.257359\n",
      "4538-th loss is : 0.278654\n",
      "4539-th loss is : 0.156485\n",
      "4540-th loss is : 0.0727921\n",
      "4541-th loss is : 0.368265\n",
      "4542-th loss is : 0.0697858\n",
      "4543-th loss is : 0.411613\n",
      "4544-th loss is : 0.0469138\n",
      "4545-th loss is : 0.0431913\n",
      "4546-th loss is : 0.134181\n",
      "4547-th loss is : 0.0489844\n",
      "4548-th loss is : 0.0832216\n",
      "4549-th loss is : 0.0522957\n",
      "4550-th loss is : 0.243998\n",
      "4551-th loss is : 0.131886\n",
      "4552-th loss is : 0.0182727\n",
      "4553-th loss is : 0.275668\n",
      "4554-th loss is : 0.0245536\n",
      "4555-th loss is : 0.432945\n",
      "4556-th loss is : 0.162568\n",
      "4557-th loss is : 0.0132167\n",
      "4558-th loss is : 0.180557\n",
      "4559-th loss is : 0.0210568\n",
      "4560-th loss is : 0.182969\n",
      "4561-th loss is : 0.11434\n",
      "4562-th loss is : 0.161606\n",
      "4563-th loss is : 0.355119\n",
      "4564-th loss is : 0.143315\n",
      "4565-th loss is : 0.0320304\n",
      "4566-th loss is : 0.301311\n",
      "4567-th loss is : 0.194783\n",
      "4568-th loss is : 0.256339\n",
      "4569-th loss is : 0.293296\n",
      "4570-th loss is : 0.247533\n",
      "4571-th loss is : 0.0345937\n",
      "4572-th loss is : 0.0181154\n",
      "4573-th loss is : 0.264964\n",
      "4574-th loss is : 0.0650215\n",
      "4575-th loss is : 0.0279403\n",
      "4576-th loss is : 0.308697\n",
      "4577-th loss is : 0.20766\n",
      "4578-th loss is : 0.0960542\n",
      "4579-th loss is : 0.421381\n",
      "4580-th loss is : 0.429606\n",
      "4581-th loss is : 0.112661\n",
      "4582-th loss is : 0.0474048\n",
      "4583-th loss is : 0.368941\n",
      "4584-th loss is : 0.0444616\n",
      "4585-th loss is : 0.0870086\n",
      "4586-th loss is : 0.184087\n",
      "4587-th loss is : 0.23654\n",
      "4588-th loss is : 0.100578\n",
      "4589-th loss is : 0.0509063\n",
      "4590-th loss is : 0.157313\n",
      "4591-th loss is : 0.153741\n",
      "4592-th loss is : 0.0332168\n",
      "4593-th loss is : 0.199806\n",
      "4594-th loss is : 0.0750621\n",
      "4595-th loss is : 0.214499\n",
      "4596-th loss is : 0.136653\n",
      "4597-th loss is : 0.144158\n",
      "4598-th loss is : 0.216776\n",
      "4599-th loss is : 0.0430921\n",
      "4600-th loss is : 0.0640194\n",
      "4601-th loss is : 0.344499\n",
      "4602-th loss is : 0.0131103\n",
      "4603-th loss is : 0.223422\n",
      "4604-th loss is : 0.100019\n",
      "4605-th loss is : 0.157285\n",
      "4606-th loss is : 0.286252\n",
      "4607-th loss is : 0.0960227\n",
      "4608-th loss is : 0.127503\n",
      "4609-th loss is : 0.0340765\n",
      "4610-th loss is : 0.212261\n",
      "4611-th loss is : 0.298466\n",
      "4612-th loss is : 0.243873\n",
      "4613-th loss is : 0.377377\n",
      "4614-th loss is : 0.251261\n",
      "4615-th loss is : 0.0923496\n",
      "4616-th loss is : 0.0930978\n",
      "4617-th loss is : 0.318671\n",
      "4618-th loss is : 0.0318975\n",
      "4619-th loss is : 0.111501\n",
      "4620-th loss is : 0.097066\n",
      "4621-th loss is : 0.0434307\n",
      "4622-th loss is : 0.0476432\n",
      "4623-th loss is : 0.0733098\n",
      "4624-th loss is : 0.348472\n",
      "4625-th loss is : 0.0366681\n",
      "4626-th loss is : 0.0993365\n",
      "4627-th loss is : 0.304223\n",
      "4628-th loss is : 0.184846\n",
      "4629-th loss is : 0.0213251\n",
      "4630-th loss is : 0.29319\n",
      "4631-th loss is : 0.127953\n",
      "4632-th loss is : 0.340758\n",
      "4633-th loss is : 0.210962\n",
      "4634-th loss is : 0.0184889\n",
      "4635-th loss is : 0.19946\n",
      "4636-th loss is : 0.276106\n",
      "4637-th loss is : 0.0226854\n",
      "4638-th loss is : 0.0863437\n",
      "4639-th loss is : 0.326485\n",
      "4640-th loss is : 0.158926\n",
      "4641-th loss is : 0.229367\n",
      "4642-th loss is : 0.0989504\n",
      "4643-th loss is : 0.173482\n",
      "4644-th loss is : 0.124873\n",
      "4645-th loss is : 0.0682313\n",
      "4646-th loss is : 0.0984835\n",
      "4647-th loss is : 0.12896\n",
      "4648-th loss is : 0.171294\n",
      "4649-th loss is : 0.0390652\n",
      "4650-th loss is : 0.0988598\n",
      "4651-th loss is : 0.0300903\n",
      "4652-th loss is : 0.233487\n",
      "4653-th loss is : 0.123605\n",
      "4654-th loss is : 0.049121\n",
      "4655-th loss is : 0.0233252\n",
      "4656-th loss is : 0.197831\n",
      "4657-th loss is : 0.0128482\n",
      "4658-th loss is : 0.252852\n",
      "4659-th loss is : 0.027491\n",
      "4660-th loss is : 0.0156357\n",
      "4661-th loss is : 0.0569086\n",
      "4662-th loss is : 0.0306161\n",
      "4663-th loss is : 0.231726\n",
      "4664-th loss is : 0.352248\n",
      "4665-th loss is : 0.292872\n",
      "4666-th loss is : 0.404879\n",
      "4667-th loss is : 0.0423459\n",
      "4668-th loss is : 0.28761\n",
      "4669-th loss is : 0.0215116\n",
      "4670-th loss is : 0.0895258\n",
      "4671-th loss is : 0.325099\n",
      "4672-th loss is : 0.050504\n",
      "4673-th loss is : 0.128031\n",
      "4674-th loss is : 0.208823\n",
      "4675-th loss is : 0.26259\n",
      "4676-th loss is : 0.0230664\n",
      "4677-th loss is : 0.293468\n",
      "4678-th loss is : 0.23095\n",
      "4679-th loss is : 0.0444321\n",
      "4680-th loss is : 0.18954\n",
      "4681-th loss is : 0.338905\n",
      "4682-th loss is : 0.0324952\n",
      "4683-th loss is : 0.376826\n",
      "4684-th loss is : 0.258992\n",
      "4685-th loss is : 0.373755\n",
      "4686-th loss is : 0.2219\n",
      "4687-th loss is : 0.374948\n",
      "4688-th loss is : 0.0594081\n",
      "4689-th loss is : 0.0468071\n",
      "4690-th loss is : 0.376312\n",
      "4691-th loss is : 0.0540476\n",
      "4692-th loss is : 0.284922\n",
      "4693-th loss is : 0.249307\n",
      "4694-th loss is : 0.126978\n",
      "4695-th loss is : 0.0641393\n",
      "4696-th loss is : 0.0573058\n",
      "4697-th loss is : 0.0882911\n",
      "4698-th loss is : 0.0134014\n",
      "4699-th loss is : 0.181048\n",
      "4700-th loss is : 0.0710396\n",
      "4701-th loss is : 0.341019\n",
      "4702-th loss is : 0.342027\n",
      "4703-th loss is : 0.398209\n",
      "4704-th loss is : 0.00990638\n",
      "4705-th loss is : 0.0235991\n",
      "4706-th loss is : 0.111624\n",
      "4707-th loss is : 0.24523\n",
      "4708-th loss is : 0.329665\n",
      "4709-th loss is : 0.0172609\n",
      "4710-th loss is : 0.33739\n",
      "4711-th loss is : 0.115676\n",
      "4712-th loss is : 0.240994\n",
      "4713-th loss is : 0.388232\n",
      "4714-th loss is : 0.106194\n",
      "4715-th loss is : 0.0179392\n",
      "4716-th loss is : 0.0579153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4717-th loss is : 0.0965253\n",
      "4718-th loss is : 0.201519\n",
      "4719-th loss is : 0.285131\n",
      "4720-th loss is : 0.407554\n",
      "4721-th loss is : 0.226002\n",
      "4722-th loss is : 0.101895\n",
      "4723-th loss is : 0.125142\n",
      "4724-th loss is : 0.0113236\n",
      "4725-th loss is : 0.0699367\n",
      "4726-th loss is : 0.125259\n",
      "4727-th loss is : 0.262814\n",
      "4728-th loss is : 0.247542\n",
      "4729-th loss is : 0.159001\n",
      "4730-th loss is : 0.101677\n",
      "4731-th loss is : 0.0361273\n",
      "4732-th loss is : 0.155188\n",
      "4733-th loss is : 0.342413\n",
      "4734-th loss is : 0.391436\n",
      "4735-th loss is : 0.0686454\n",
      "4736-th loss is : 0.105778\n",
      "4737-th loss is : 0.0128552\n",
      "4738-th loss is : 0.115263\n",
      "4739-th loss is : 0.030512\n",
      "4740-th loss is : 0.33997\n",
      "4741-th loss is : 0.0819479\n",
      "4742-th loss is : 0.186471\n",
      "4743-th loss is : 0.0141082\n",
      "4744-th loss is : 0.16437\n",
      "4745-th loss is : 0.253703\n",
      "4746-th loss is : 0.0458254\n",
      "4747-th loss is : 0.208328\n",
      "4748-th loss is : 0.0367343\n",
      "4749-th loss is : 0.0952998\n",
      "4750-th loss is : 0.046568\n",
      "4751-th loss is : 0.165174\n",
      "4752-th loss is : 0.0414923\n",
      "4753-th loss is : 0.0642432\n",
      "4754-th loss is : 0.169759\n",
      "4755-th loss is : 0.0225369\n",
      "4756-th loss is : 0.0265892\n",
      "4757-th loss is : 0.194965\n",
      "4758-th loss is : 0.133366\n",
      "4759-th loss is : 0.307954\n",
      "4760-th loss is : 0.242638\n",
      "4761-th loss is : 0.330975\n",
      "4762-th loss is : 0.316069\n",
      "4763-th loss is : 0.0469948\n",
      "4764-th loss is : 0.112653\n",
      "4765-th loss is : 0.0741261\n",
      "4766-th loss is : 0.0454206\n",
      "4767-th loss is : 0.351414\n",
      "4768-th loss is : 0.28221\n",
      "4769-th loss is : 0.30099\n",
      "4770-th loss is : 0.213137\n",
      "4771-th loss is : 0.144281\n",
      "4772-th loss is : 0.13422\n",
      "4773-th loss is : 0.0533095\n",
      "4774-th loss is : 0.0184578\n",
      "4775-th loss is : 0.14025\n",
      "4776-th loss is : 0.0143298\n",
      "4777-th loss is : 0.184572\n",
      "4778-th loss is : 0.335122\n",
      "4779-th loss is : 0.0964862\n",
      "4780-th loss is : 0.0797538\n",
      "4781-th loss is : 0.173025\n",
      "4782-th loss is : 0.254962\n",
      "4783-th loss is : 0.345733\n",
      "4784-th loss is : 0.240336\n",
      "4785-th loss is : 0.143313\n",
      "4786-th loss is : 0.148699\n",
      "4787-th loss is : 0.216444\n",
      "4788-th loss is : 0.0399962\n",
      "4789-th loss is : 0.0106458\n",
      "4790-th loss is : 0.341117\n",
      "4791-th loss is : 0.043028\n",
      "4792-th loss is : 0.161846\n",
      "4793-th loss is : 0.192089\n",
      "4794-th loss is : 0.155777\n",
      "4795-th loss is : 0.0330521\n",
      "4796-th loss is : 0.0239539\n",
      "4797-th loss is : 0.161195\n",
      "4798-th loss is : 0.31017\n",
      "4799-th loss is : 0.0131218\n",
      "4800-th loss is : 0.0675256\n",
      "4801-th loss is : 0.129208\n",
      "4802-th loss is : 0.167947\n",
      "4803-th loss is : 0.12957\n",
      "4804-th loss is : 0.0256117\n",
      "4805-th loss is : 0.0495384\n",
      "4806-th loss is : 0.275825\n",
      "4807-th loss is : 0.106902\n",
      "4808-th loss is : 0.227308\n",
      "4809-th loss is : 0.0874147\n",
      "4810-th loss is : 0.0416241\n",
      "4811-th loss is : 0.300399\n",
      "4812-th loss is : 0.196542\n",
      "4813-th loss is : 0.204366\n",
      "4814-th loss is : 0.0398027\n",
      "4815-th loss is : 0.0360867\n",
      "4816-th loss is : 0.0985973\n",
      "4817-th loss is : 0.299144\n",
      "4818-th loss is : 0.372878\n",
      "4819-th loss is : 0.236733\n",
      "4820-th loss is : 0.0902517\n",
      "4821-th loss is : 0.287649\n",
      "4822-th loss is : 0.0360149\n",
      "4823-th loss is : 0.292031\n",
      "4824-th loss is : 0.111299\n",
      "4825-th loss is : 0.0228551\n",
      "4826-th loss is : 0.170592\n",
      "4827-th loss is : 0.0177824\n",
      "4828-th loss is : 0.276099\n",
      "4829-th loss is : 0.0671904\n",
      "4830-th loss is : 0.0366089\n",
      "4831-th loss is : 0.0698393\n",
      "4832-th loss is : 0.0374789\n",
      "4833-th loss is : 0.0713117\n",
      "4834-th loss is : 0.280206\n",
      "4835-th loss is : 0.316996\n",
      "4836-th loss is : 0.0227028\n",
      "4837-th loss is : 0.297403\n",
      "4838-th loss is : 0.172776\n",
      "4839-th loss is : 0.119996\n",
      "4840-th loss is : 0.31192\n",
      "4841-th loss is : 0.111387\n",
      "4842-th loss is : 0.251542\n",
      "4843-th loss is : 0.197329\n",
      "4844-th loss is : 0.224544\n",
      "4845-th loss is : 0.0223983\n",
      "4846-th loss is : 0.0299423\n",
      "4847-th loss is : 0.300031\n",
      "4848-th loss is : 0.0186132\n",
      "4849-th loss is : 0.0508051\n",
      "4850-th loss is : 0.0464056\n",
      "4851-th loss is : 0.330422\n",
      "4852-th loss is : 0.0697193\n",
      "4853-th loss is : 0.366082\n",
      "4854-th loss is : 0.258616\n",
      "4855-th loss is : 0.0444149\n",
      "4856-th loss is : 0.0898823\n",
      "4857-th loss is : 0.174645\n",
      "4858-th loss is : 0.00913494\n",
      "4859-th loss is : 0.341138\n",
      "4860-th loss is : 0.038501\n",
      "4861-th loss is : 0.057098\n",
      "4862-th loss is : 0.322502\n",
      "4863-th loss is : 0.0615285\n",
      "4864-th loss is : 0.109048\n",
      "4865-th loss is : 0.291076\n",
      "4866-th loss is : 0.1352\n",
      "4867-th loss is : 0.301991\n",
      "4868-th loss is : 0.0403292\n",
      "4869-th loss is : 0.0364107\n",
      "4870-th loss is : 0.128669\n",
      "4871-th loss is : 0.00756357\n",
      "4872-th loss is : 0.0697036\n",
      "4873-th loss is : 0.113406\n",
      "4874-th loss is : 0.271389\n",
      "4875-th loss is : 0.120904\n",
      "4876-th loss is : 0.0259422\n",
      "4877-th loss is : 0.0812954\n",
      "4878-th loss is : 0.315496\n",
      "4879-th loss is : 0.173356\n",
      "4880-th loss is : 0.222374\n",
      "4881-th loss is : 0.277933\n",
      "4882-th loss is : 0.0716549\n",
      "4883-th loss is : 0.22087\n",
      "4884-th loss is : 0.237339\n",
      "4885-th loss is : 0.16914\n",
      "4886-th loss is : 0.263678\n",
      "4887-th loss is : 0.0501453\n",
      "4888-th loss is : 0.0480013\n",
      "4889-th loss is : 0.130821\n",
      "4890-th loss is : 0.137381\n",
      "4891-th loss is : 0.320986\n",
      "4892-th loss is : 0.187563\n",
      "4893-th loss is : 0.072835\n",
      "4894-th loss is : 0.0823042\n",
      "4895-th loss is : 0.0263424\n",
      "4896-th loss is : 0.175643\n",
      "4897-th loss is : 0.126314\n",
      "4898-th loss is : 0.296284\n",
      "4899-th loss is : 0.042616\n",
      "4900-th loss is : 0.0262553\n",
      "4901-th loss is : 0.0142331\n",
      "4902-th loss is : 0.0434829\n",
      "4903-th loss is : 0.374996\n",
      "4904-th loss is : 0.0361989\n",
      "4905-th loss is : 0.247612\n",
      "4906-th loss is : 0.0633992\n",
      "4907-th loss is : 0.10027\n",
      "4908-th loss is : 0.00703658\n",
      "4909-th loss is : 0.0610246\n",
      "4910-th loss is : 0.37551\n",
      "4911-th loss is : 0.0278177\n",
      "4912-th loss is : 0.207195\n",
      "4913-th loss is : 0.302477\n",
      "4914-th loss is : 0.0255756\n",
      "4915-th loss is : 0.120749\n",
      "4916-th loss is : 0.0139333\n",
      "4917-th loss is : 0.280561\n",
      "4918-th loss is : 0.13344\n",
      "4919-th loss is : 0.200279\n",
      "4920-th loss is : 0.190315\n",
      "4921-th loss is : 0.203483\n",
      "4922-th loss is : 0.0263428\n",
      "4923-th loss is : 0.136886\n",
      "4924-th loss is : 0.0500349\n",
      "4925-th loss is : 0.130178\n",
      "4926-th loss is : 0.184452\n",
      "4927-th loss is : 0.0716851\n",
      "4928-th loss is : 0.0410914\n",
      "4929-th loss is : 0.369554\n",
      "4930-th loss is : 0.363678\n",
      "4931-th loss is : 0.0379897\n",
      "4932-th loss is : 0.0209356\n",
      "4933-th loss is : 0.0741374\n",
      "4934-th loss is : 0.00935991\n",
      "4935-th loss is : 0.0705989\n",
      "4936-th loss is : 0.12932\n",
      "4937-th loss is : 0.0279978\n",
      "4938-th loss is : 0.00924734\n",
      "4939-th loss is : 0.281057\n",
      "4940-th loss is : 0.0949516\n",
      "4941-th loss is : 0.0643196\n",
      "4942-th loss is : 0.253266\n",
      "4943-th loss is : 0.125205\n",
      "4944-th loss is : 0.29863\n",
      "4945-th loss is : 0.320506\n",
      "4946-th loss is : 0.338727\n",
      "4947-th loss is : 0.212985\n",
      "4948-th loss is : 0.0353531\n",
      "4949-th loss is : 0.0633009\n",
      "4950-th loss is : 0.368966\n",
      "4951-th loss is : 0.117761\n",
      "4952-th loss is : 0.307122\n",
      "4953-th loss is : 0.0574304\n",
      "4954-th loss is : 0.155706\n",
      "4955-th loss is : 0.0194849\n",
      "4956-th loss is : 0.00903356\n",
      "4957-th loss is : 0.0979244\n",
      "4958-th loss is : 0.26288\n",
      "4959-th loss is : 0.332432\n",
      "4960-th loss is : 0.370548\n",
      "4961-th loss is : 0.160772\n",
      "4962-th loss is : 0.363636\n",
      "4963-th loss is : 0.130841\n",
      "4964-th loss is : 0.0126228\n",
      "4965-th loss is : 0.08754\n",
      "4966-th loss is : 0.0108384\n",
      "4967-th loss is : 0.164051\n",
      "4968-th loss is : 0.0961982\n",
      "4969-th loss is : 0.268717\n",
      "4970-th loss is : 0.277905\n",
      "4971-th loss is : 0.179743\n",
      "4972-th loss is : 0.265335\n",
      "4973-th loss is : 0.202412\n",
      "4974-th loss is : 0.297017\n",
      "4975-th loss is : 0.128722\n",
      "4976-th loss is : 0.0990124\n",
      "4977-th loss is : 0.324587\n",
      "4978-th loss is : 0.154835\n",
      "4979-th loss is : 0.203815\n",
      "4980-th loss is : 0.136312\n",
      "4981-th loss is : 0.286257\n",
      "4982-th loss is : 0.275218\n",
      "4983-th loss is : 0.158105\n",
      "4984-th loss is : 0.00799091\n",
      "4985-th loss is : 0.0127746\n",
      "4986-th loss is : 0.114133\n",
      "4987-th loss is : 0.0337471\n",
      "4988-th loss is : 0.00899\n",
      "4989-th loss is : 0.318336\n",
      "4990-th loss is : 0.340084\n",
      "4991-th loss is : 0.294437\n",
      "4992-th loss is : 0.245478\n",
      "4993-th loss is : 0.0223298\n",
      "4994-th loss is : 0.141648\n",
      "4995-th loss is : 0.04483\n",
      "4996-th loss is : 0.367382\n",
      "4997-th loss is : 0.0444574\n",
      "4998-th loss is : 0.257964\n",
      "4999-th loss is : 0.159864\n",
      "5000-th loss is : 0.0647243\n",
      "5001-th loss is : 0.0934433\n",
      "5002-th loss is : 0.00906172\n",
      "5003-th loss is : 0.20744\n",
      "5004-th loss is : 0.308926\n",
      "5005-th loss is : 0.191391\n",
      "5006-th loss is : 0.0615081\n",
      "5007-th loss is : 0.0267117\n",
      "5008-th loss is : 0.268772\n",
      "5009-th loss is : 0.0591532\n",
      "5010-th loss is : 0.196042\n",
      "5011-th loss is : 0.102547\n",
      "5012-th loss is : 0.275032\n",
      "5013-th loss is : 0.316253\n",
      "5014-th loss is : 0.138159\n",
      "5015-th loss is : 0.113236\n",
      "5016-th loss is : 0.0836282\n",
      "5017-th loss is : 0.119504\n",
      "5018-th loss is : 0.192189\n",
      "5019-th loss is : 0.0153326\n",
      "5020-th loss is : 0.00903546\n",
      "5021-th loss is : 0.0292869\n",
      "5022-th loss is : 0.112325\n",
      "5023-th loss is : 0.01832\n",
      "5024-th loss is : 0.322323\n",
      "5025-th loss is : 0.118753\n",
      "5026-th loss is : 0.0269185\n",
      "5027-th loss is : 0.155777\n",
      "5028-th loss is : 0.203162\n",
      "5029-th loss is : 0.143545\n",
      "5030-th loss is : 0.343961\n",
      "5031-th loss is : 0.0520307\n",
      "5032-th loss is : 0.0367962\n",
      "5033-th loss is : 0.118689\n",
      "5034-th loss is : 0.204252\n",
      "5035-th loss is : 0.10758\n",
      "5036-th loss is : 0.0282329\n",
      "5037-th loss is : 0.0163928\n",
      "5038-th loss is : 0.194137\n",
      "5039-th loss is : 0.330379\n",
      "5040-th loss is : 0.158694\n",
      "5041-th loss is : 0.0826599\n",
      "5042-th loss is : 0.0665281\n",
      "5043-th loss is : 0.100837\n",
      "5044-th loss is : 0.0302308\n",
      "5045-th loss is : 0.0382581\n",
      "5046-th loss is : 0.0544989\n",
      "5047-th loss is : 0.0315261\n",
      "5048-th loss is : 0.061079\n",
      "5049-th loss is : 0.0613412\n",
      "5050-th loss is : 0.229214\n",
      "5051-th loss is : 0.0650061\n",
      "5052-th loss is : 0.0663099\n",
      "5053-th loss is : 0.302308\n",
      "5054-th loss is : 0.192093\n",
      "5055-th loss is : 0.0149686\n",
      "5056-th loss is : 0.0849116\n",
      "5057-th loss is : 0.0822066\n",
      "5058-th loss is : 0.0652959\n",
      "5059-th loss is : 0.143913\n",
      "5060-th loss is : 0.295295\n",
      "5061-th loss is : 0.18385\n",
      "5062-th loss is : 0.154519\n",
      "5063-th loss is : 0.199532\n",
      "5064-th loss is : 0.187677\n",
      "5065-th loss is : 0.0436722\n",
      "5066-th loss is : 0.128606\n",
      "5067-th loss is : 0.224639\n",
      "5068-th loss is : 0.0955921\n",
      "5069-th loss is : 0.056825\n",
      "5070-th loss is : 0.025453\n",
      "5071-th loss is : 0.34479\n",
      "5072-th loss is : 0.0123597\n",
      "5073-th loss is : 0.0611788\n",
      "5074-th loss is : 0.110898\n",
      "5075-th loss is : 0.331345\n",
      "5076-th loss is : 0.108602\n",
      "5077-th loss is : 0.110712\n",
      "5078-th loss is : 0.0208507\n",
      "5079-th loss is : 0.0962532\n",
      "5080-th loss is : 0.0905086\n",
      "5081-th loss is : 0.14321\n",
      "5082-th loss is : 0.0324912\n",
      "5083-th loss is : 0.263486\n",
      "5084-th loss is : 0.13362\n",
      "5085-th loss is : 0.126549\n",
      "5086-th loss is : 0.0805819\n",
      "5087-th loss is : 0.276115\n",
      "5088-th loss is : 0.244308\n",
      "5089-th loss is : 0.319843\n",
      "5090-th loss is : 0.12168\n",
      "5091-th loss is : 0.334303\n",
      "5092-th loss is : 0.319532\n",
      "5093-th loss is : 0.301299\n",
      "5094-th loss is : 0.279906\n",
      "5095-th loss is : 0.1234\n",
      "5096-th loss is : 0.19849\n",
      "5097-th loss is : 0.321831\n",
      "5098-th loss is : 0.00914214\n",
      "5099-th loss is : 0.0912422\n",
      "5100-th loss is : 0.223972\n",
      "5101-th loss is : 0.186299\n",
      "5102-th loss is : 0.046704\n",
      "5103-th loss is : 0.230188\n",
      "5104-th loss is : 0.0280772\n",
      "5105-th loss is : 0.314483\n",
      "5106-th loss is : 0.274704\n",
      "5107-th loss is : 0.0145996\n",
      "5108-th loss is : 0.0217845\n",
      "5109-th loss is : 0.28728\n",
      "5110-th loss is : 0.23319\n",
      "5111-th loss is : 0.0435203\n",
      "5112-th loss is : 0.298952\n",
      "5113-th loss is : 0.316513\n",
      "5114-th loss is : 0.0193611\n",
      "5115-th loss is : 0.0558581\n",
      "5116-th loss is : 0.0240349\n",
      "5117-th loss is : 0.0408333\n",
      "5118-th loss is : 0.0157884\n",
      "5119-th loss is : 0.0125737\n",
      "5120-th loss is : 0.280105\n",
      "5121-th loss is : 0.0210085\n",
      "5122-th loss is : 0.154884\n",
      "5123-th loss is : 0.23752\n",
      "5124-th loss is : 0.0863267\n",
      "5125-th loss is : 0.0303462\n",
      "5126-th loss is : 0.0968804\n",
      "5127-th loss is : 0.282402\n",
      "5128-th loss is : 0.0315759\n",
      "5129-th loss is : 0.117059\n",
      "5130-th loss is : 0.0577081\n",
      "5131-th loss is : 0.148582\n",
      "5132-th loss is : 0.197271\n",
      "5133-th loss is : 0.127389\n",
      "5134-th loss is : 0.0259202\n",
      "5135-th loss is : 0.0302347\n",
      "5136-th loss is : 0.0149661\n",
      "5137-th loss is : 0.0156053\n",
      "5138-th loss is : 0.11532\n",
      "5139-th loss is : 0.0769854\n",
      "5140-th loss is : 0.0180556\n",
      "5141-th loss is : 0.0089789\n",
      "5142-th loss is : 0.315773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143-th loss is : 0.214953\n",
      "5144-th loss is : 0.0143212\n",
      "5145-th loss is : 0.118852\n",
      "5146-th loss is : 0.183193\n",
      "5147-th loss is : 0.172046\n",
      "5148-th loss is : 0.131462\n",
      "5149-th loss is : 0.0390031\n",
      "5150-th loss is : 0.0139632\n",
      "5151-th loss is : 0.0247782\n",
      "5152-th loss is : 0.155916\n",
      "5153-th loss is : 0.0552607\n",
      "5154-th loss is : 0.100429\n",
      "5155-th loss is : 0.125135\n",
      "5156-th loss is : 0.131892\n",
      "5157-th loss is : 0.264573\n",
      "5158-th loss is : 0.124325\n",
      "5159-th loss is : 0.00452845\n",
      "5160-th loss is : 0.133117\n",
      "5161-th loss is : 0.0451072\n",
      "5162-th loss is : 0.173955\n",
      "5163-th loss is : 0.332098\n",
      "5164-th loss is : 0.088652\n",
      "5165-th loss is : 0.0863791\n",
      "5166-th loss is : 0.219288\n",
      "5167-th loss is : 0.108614\n",
      "5168-th loss is : 0.32341\n",
      "5169-th loss is : 0.253347\n",
      "5170-th loss is : 0.0204003\n",
      "5171-th loss is : 0.0519619\n",
      "5172-th loss is : 0.0586572\n",
      "5173-th loss is : 0.0737391\n",
      "5174-th loss is : 0.0801187\n",
      "5175-th loss is : 0.056239\n",
      "5176-th loss is : 0.0788106\n",
      "5177-th loss is : 0.0532993\n",
      "5178-th loss is : 0.066979\n",
      "5179-th loss is : 0.076065\n",
      "5180-th loss is : 0.0576226\n",
      "5181-th loss is : 0.00554626\n",
      "5182-th loss is : 0.0929976\n",
      "5183-th loss is : 0.143647\n",
      "5184-th loss is : 0.206572\n",
      "5185-th loss is : 0.0145527\n",
      "5186-th loss is : 0.0471452\n",
      "5187-th loss is : 0.266916\n",
      "5188-th loss is : 0.112297\n",
      "5189-th loss is : 0.00471026\n",
      "5190-th loss is : 0.0377263\n",
      "5191-th loss is : 0.341237\n",
      "5192-th loss is : 0.0125554\n",
      "5193-th loss is : 0.0933097\n",
      "5194-th loss is : 0.136921\n",
      "5195-th loss is : 0.0811321\n",
      "5196-th loss is : 0.303641\n",
      "5197-th loss is : 0.147349\n",
      "5198-th loss is : 0.0250606\n",
      "5199-th loss is : 0.0277779\n",
      "5200-th loss is : 0.166952\n",
      "5201-th loss is : 0.201314\n",
      "5202-th loss is : 0.0315977\n",
      "5203-th loss is : 0.228224\n",
      "5204-th loss is : 0.233594\n",
      "5205-th loss is : 0.078819\n",
      "5206-th loss is : 0.215735\n",
      "5207-th loss is : 0.109514\n",
      "5208-th loss is : 0.0237843\n",
      "5209-th loss is : 0.217757\n",
      "5210-th loss is : 0.139081\n",
      "5211-th loss is : 0.0968361\n",
      "5212-th loss is : 0.0286376\n",
      "5213-th loss is : 0.206705\n",
      "5214-th loss is : 0.174558\n",
      "5215-th loss is : 0.118462\n",
      "5216-th loss is : 0.0708641\n",
      "5217-th loss is : 0.039094\n",
      "5218-th loss is : 0.23411\n",
      "5219-th loss is : 0.331559\n",
      "5220-th loss is : 0.298715\n",
      "5221-th loss is : 0.0547874\n",
      "5222-th loss is : 0.0260899\n",
      "5223-th loss is : 0.0426142\n",
      "5224-th loss is : 0.251972\n",
      "5225-th loss is : 0.0861406\n",
      "5226-th loss is : 0.267201\n",
      "5227-th loss is : 0.279924\n",
      "5228-th loss is : 0.0058086\n",
      "5229-th loss is : 0.102531\n",
      "5230-th loss is : 0.117565\n",
      "5231-th loss is : 0.256467\n",
      "5232-th loss is : 0.0696296\n",
      "5233-th loss is : 0.259304\n",
      "5234-th loss is : 0.273424\n",
      "5235-th loss is : 0.251026\n",
      "5236-th loss is : 0.0413636\n",
      "5237-th loss is : 0.224382\n",
      "5238-th loss is : 0.0668205\n",
      "5239-th loss is : 0.127117\n",
      "5240-th loss is : 0.155675\n",
      "5241-th loss is : 0.0699606\n",
      "5242-th loss is : 0.100686\n",
      "5243-th loss is : 0.200356\n",
      "5244-th loss is : 0.0286343\n",
      "5245-th loss is : 0.00772976\n",
      "5246-th loss is : 0.149063\n",
      "5247-th loss is : 0.11412\n",
      "5248-th loss is : 0.123724\n",
      "5249-th loss is : 0.176084\n",
      "5250-th loss is : 0.0224098\n",
      "5251-th loss is : 0.130191\n",
      "5252-th loss is : 0.0777179\n",
      "5253-th loss is : 0.0314872\n",
      "5254-th loss is : 0.194267\n",
      "5255-th loss is : 0.00893857\n",
      "5256-th loss is : 0.130777\n",
      "5257-th loss is : 0.00715467\n",
      "5258-th loss is : 0.0102475\n",
      "5259-th loss is : 0.0718658\n",
      "5260-th loss is : 0.0845931\n",
      "5261-th loss is : 0.0164377\n",
      "5262-th loss is : 0.164331\n",
      "5263-th loss is : 0.0105489\n",
      "5264-th loss is : 0.170287\n",
      "5265-th loss is : 0.0879654\n",
      "5266-th loss is : 0.223467\n",
      "5267-th loss is : 0.0897166\n",
      "5268-th loss is : 0.0225408\n",
      "5269-th loss is : 0.128668\n",
      "5270-th loss is : 0.0634826\n",
      "5271-th loss is : 0.0708183\n",
      "5272-th loss is : 0.229871\n",
      "5273-th loss is : 0.00387628\n",
      "5274-th loss is : 0.0266935\n",
      "5275-th loss is : 0.089698\n",
      "5276-th loss is : 0.0388861\n",
      "5277-th loss is : 0.0556212\n",
      "5278-th loss is : 0.159681\n",
      "5279-th loss is : 0.0332623\n",
      "5280-th loss is : 0.00668765\n",
      "5281-th loss is : 0.300328\n",
      "5282-th loss is : 0.159506\n",
      "5283-th loss is : 0.0613772\n",
      "5284-th loss is : 0.224293\n",
      "5285-th loss is : 0.28268\n",
      "5286-th loss is : 0.293514\n",
      "5287-th loss is : 0.284342\n",
      "5288-th loss is : 0.0507267\n",
      "5289-th loss is : 0.222388\n",
      "5290-th loss is : 0.00755679\n",
      "5291-th loss is : 0.30269\n",
      "5292-th loss is : 0.00779242\n",
      "5293-th loss is : 0.039721\n",
      "5294-th loss is : 0.0303462\n",
      "5295-th loss is : 0.0692972\n",
      "5296-th loss is : 0.322596\n",
      "5297-th loss is : 0.144595\n",
      "5298-th loss is : 0.265342\n",
      "5299-th loss is : 0.0175361\n",
      "5300-th loss is : 0.276776\n",
      "5301-th loss is : 0.146892\n",
      "5302-th loss is : 0.065157\n",
      "5303-th loss is : 0.256331\n",
      "5304-th loss is : 0.178156\n",
      "5305-th loss is : 0.00446664\n",
      "5306-th loss is : 0.229681\n",
      "5307-th loss is : 0.110726\n",
      "5308-th loss is : 0.0522663\n",
      "5309-th loss is : 0.15079\n",
      "5310-th loss is : 0.268871\n",
      "5311-th loss is : 0.126853\n",
      "5312-th loss is : 0.135671\n",
      "5313-th loss is : 0.0510929\n",
      "5314-th loss is : 0.0112787\n",
      "5315-th loss is : 0.204243\n",
      "5316-th loss is : 0.00883009\n",
      "5317-th loss is : 0.218985\n",
      "5318-th loss is : 0.25264\n",
      "5319-th loss is : 0.0806426\n",
      "5320-th loss is : 0.0550997\n",
      "5321-th loss is : 0.156258\n",
      "5322-th loss is : 0.222055\n",
      "5323-th loss is : 0.0806365\n",
      "5324-th loss is : 0.020079\n",
      "5325-th loss is : 0.245863\n",
      "5326-th loss is : 0.231835\n",
      "5327-th loss is : 0.233199\n",
      "5328-th loss is : 0.215605\n",
      "5329-th loss is : 0.036429\n",
      "5330-th loss is : 0.147101\n",
      "5331-th loss is : 0.110252\n",
      "5332-th loss is : 0.167005\n",
      "5333-th loss is : 0.229924\n",
      "5334-th loss is : 0.090525\n",
      "5335-th loss is : 0.0700464\n",
      "5336-th loss is : 0.03477\n",
      "5337-th loss is : 0.166345\n",
      "5338-th loss is : 0.237416\n",
      "5339-th loss is : 0.0627133\n",
      "5340-th loss is : 0.0575114\n",
      "5341-th loss is : 0.117506\n",
      "5342-th loss is : 0.0105605\n",
      "5343-th loss is : 0.00639977\n",
      "5344-th loss is : 0.173879\n",
      "5345-th loss is : 0.176024\n",
      "5346-th loss is : 0.214404\n",
      "5347-th loss is : 0.269373\n",
      "5348-th loss is : 0.0700162\n",
      "5349-th loss is : 0.170096\n",
      "5350-th loss is : 0.130043\n",
      "5351-th loss is : 0.00700823\n",
      "5352-th loss is : 0.057278\n",
      "5353-th loss is : 0.192019\n",
      "5354-th loss is : 0.191756\n",
      "5355-th loss is : 0.0267406\n",
      "5356-th loss is : 0.0843159\n",
      "5357-th loss is : 0.322042\n",
      "5358-th loss is : 0.134135\n",
      "5359-th loss is : 0.0740215\n",
      "5360-th loss is : 0.106844\n",
      "5361-th loss is : 0.0672115\n",
      "5362-th loss is : 0.0588447\n",
      "5363-th loss is : 0.160159\n",
      "5364-th loss is : 0.0392703\n",
      "5365-th loss is : 0.137199\n",
      "5366-th loss is : 0.00352249\n",
      "5367-th loss is : 0.097841\n",
      "5368-th loss is : 0.0172492\n",
      "5369-th loss is : 0.0450898\n",
      "5370-th loss is : 0.0130673\n",
      "5371-th loss is : 0.0671196\n",
      "5372-th loss is : 0.228346\n",
      "5373-th loss is : 0.0432833\n",
      "5374-th loss is : 0.133277\n",
      "5375-th loss is : 0.00769891\n",
      "5376-th loss is : 0.250477\n",
      "5377-th loss is : 0.126607\n",
      "5378-th loss is : 0.309056\n",
      "5379-th loss is : 0.00400851\n",
      "5380-th loss is : 0.310317\n",
      "5381-th loss is : 0.05057\n",
      "5382-th loss is : 0.0998032\n",
      "5383-th loss is : 0.0322546\n",
      "5384-th loss is : 0.100959\n",
      "5385-th loss is : 0.0760935\n",
      "5386-th loss is : 0.0435434\n",
      "5387-th loss is : 0.0237264\n",
      "5388-th loss is : 0.145295\n",
      "5389-th loss is : 0.0367258\n",
      "5390-th loss is : 0.118992\n",
      "5391-th loss is : 0.0711082\n",
      "5392-th loss is : 0.0496437\n",
      "5393-th loss is : 0.210925\n",
      "5394-th loss is : 0.0772966\n",
      "5395-th loss is : 0.180279\n",
      "5396-th loss is : 0.0475883\n",
      "5397-th loss is : 0.213709\n",
      "5398-th loss is : 0.109653\n",
      "5399-th loss is : 0.152702\n",
      "5400-th loss is : 0.0198162\n",
      "5401-th loss is : 0.015905\n",
      "5402-th loss is : 0.0113894\n",
      "5403-th loss is : 0.00261886\n",
      "5404-th loss is : 0.02577\n",
      "5405-th loss is : 0.0693014\n",
      "5406-th loss is : 0.313143\n",
      "5407-th loss is : 0.253676\n",
      "5408-th loss is : 0.306386\n",
      "5409-th loss is : 0.0518989\n",
      "5410-th loss is : 0.115832\n",
      "5411-th loss is : 0.290105\n",
      "5412-th loss is : 0.0111075\n",
      "5413-th loss is : 0.115758\n",
      "5414-th loss is : 0.242064\n",
      "5415-th loss is : 0.0363879\n",
      "5416-th loss is : 0.0128278\n",
      "5417-th loss is : 0.0982839\n",
      "5418-th loss is : 0.138574\n",
      "5419-th loss is : 0.0499239\n",
      "5420-th loss is : 0.0141204\n",
      "5421-th loss is : 0.0094473\n",
      "5422-th loss is : 0.176468\n",
      "5423-th loss is : 0.160637\n",
      "5424-th loss is : 0.0856694\n",
      "5425-th loss is : 0.0165367\n",
      "5426-th loss is : 0.0980063\n",
      "5427-th loss is : 0.216673\n",
      "5428-th loss is : 0.2923\n",
      "5429-th loss is : 0.113823\n",
      "5430-th loss is : 0.0926024\n",
      "5431-th loss is : 0.204811\n",
      "5432-th loss is : 0.122411\n",
      "5433-th loss is : 0.0074494\n",
      "5434-th loss is : 0.00755521\n",
      "5435-th loss is : 0.215368\n",
      "5436-th loss is : 0.0136589\n",
      "5437-th loss is : 0.0109369\n",
      "5438-th loss is : 0.0361253\n",
      "5439-th loss is : 0.103805\n",
      "5440-th loss is : 0.00924641\n",
      "5441-th loss is : 0.0675482\n",
      "5442-th loss is : 0.130447\n",
      "5443-th loss is : 0.226717\n",
      "5444-th loss is : 0.0191482\n",
      "5445-th loss is : 0.263809\n",
      "5446-th loss is : 0.0786949\n",
      "5447-th loss is : 0.10173\n",
      "5448-th loss is : 0.125984\n",
      "5449-th loss is : 0.0146765\n",
      "5450-th loss is : 0.00661829\n",
      "5451-th loss is : 0.0388166\n",
      "5452-th loss is : 0.00448677\n",
      "5453-th loss is : 0.0699122\n",
      "5454-th loss is : 0.176608\n",
      "5455-th loss is : 0.0497704\n",
      "5456-th loss is : 0.102485\n",
      "5457-th loss is : 0.309789\n",
      "5458-th loss is : 0.00815941\n",
      "5459-th loss is : 0.041753\n",
      "5460-th loss is : 0.00859876\n",
      "5461-th loss is : 0.0215457\n",
      "5462-th loss is : 0.0955695\n",
      "5463-th loss is : 0.132087\n",
      "5464-th loss is : 0.282567\n",
      "5465-th loss is : 0.0534289\n",
      "5466-th loss is : 0.130497\n",
      "5467-th loss is : 0.00583844\n",
      "5468-th loss is : 0.306142\n",
      "5469-th loss is : 0.0464684\n",
      "5470-th loss is : 0.0449746\n",
      "5471-th loss is : 0.139166\n",
      "5472-th loss is : 0.0719527\n",
      "5473-th loss is : 0.0629128\n",
      "5474-th loss is : 0.0141535\n",
      "5475-th loss is : 0.0778931\n",
      "5476-th loss is : 0.0245438\n",
      "5477-th loss is : 0.0267954\n",
      "5478-th loss is : 0.0111819\n",
      "5479-th loss is : 0.0727735\n",
      "5480-th loss is : 0.255163\n",
      "5481-th loss is : 0.080535\n",
      "5482-th loss is : 0.0684275\n",
      "5483-th loss is : 0.126667\n",
      "5484-th loss is : 0.228673\n",
      "5485-th loss is : 0.0866345\n",
      "5486-th loss is : 0.0168554\n",
      "5487-th loss is : 0.128333\n",
      "5488-th loss is : 0.108964\n",
      "5489-th loss is : 0.052836\n",
      "5490-th loss is : 0.00509686\n",
      "5491-th loss is : 0.196961\n",
      "5492-th loss is : 0.221976\n",
      "5493-th loss is : 0.0326459\n",
      "5494-th loss is : 0.211398\n",
      "5495-th loss is : 0.0933323\n",
      "5496-th loss is : 0.300266\n",
      "5497-th loss is : 0.0211862\n",
      "5498-th loss is : 0.0372261\n",
      "5499-th loss is : 0.231281\n",
      "5500-th loss is : 0.286669\n",
      "5501-th loss is : 0.243487\n",
      "5502-th loss is : 0.0484254\n",
      "5503-th loss is : 0.0330581\n",
      "5504-th loss is : 0.278708\n",
      "5505-th loss is : 0.0312827\n",
      "5506-th loss is : 0.0171355\n",
      "5507-th loss is : 0.0632478\n",
      "5508-th loss is : 0.00793328\n",
      "5509-th loss is : 0.0627611\n",
      "5510-th loss is : 0.222068\n",
      "5511-th loss is : 0.00571613\n",
      "5512-th loss is : 0.150299\n",
      "5513-th loss is : 0.201166\n",
      "5514-th loss is : 0.042237\n",
      "5515-th loss is : 0.00604624\n",
      "5516-th loss is : 0.0338424\n",
      "5517-th loss is : 0.0101182\n",
      "5518-th loss is : 0.301245\n",
      "5519-th loss is : 0.0792898\n",
      "5520-th loss is : 0.0752306\n",
      "5521-th loss is : 0.021587\n",
      "5522-th loss is : 0.253475\n",
      "5523-th loss is : 0.230555\n",
      "5524-th loss is : 0.117566\n",
      "5525-th loss is : 0.0558523\n",
      "5526-th loss is : 0.102947\n",
      "5527-th loss is : 0.0354536\n",
      "5528-th loss is : 0.083947\n",
      "5529-th loss is : 0.0767438\n",
      "5530-th loss is : 0.172182\n",
      "5531-th loss is : 0.181742\n",
      "5532-th loss is : 0.103166\n",
      "5533-th loss is : 0.00825131\n",
      "5534-th loss is : 0.0551207\n",
      "5535-th loss is : 0.0283961\n",
      "5536-th loss is : 0.022303\n",
      "5537-th loss is : 0.00544523\n",
      "5538-th loss is : 0.0219667\n",
      "5539-th loss is : 0.10835\n",
      "5540-th loss is : 0.0270904\n",
      "5541-th loss is : 0.172473\n",
      "5542-th loss is : 0.193898\n",
      "5543-th loss is : 0.00735978\n",
      "5544-th loss is : 0.0852998\n",
      "5545-th loss is : 0.248941\n",
      "5546-th loss is : 0.0929855\n",
      "5547-th loss is : 0.00578914\n",
      "5548-th loss is : 0.191862\n",
      "5549-th loss is : 0.149635\n",
      "5550-th loss is : 0.025483\n",
      "5551-th loss is : 0.125146\n",
      "5552-th loss is : 0.0750052\n",
      "5553-th loss is : 0.212432\n",
      "5554-th loss is : 0.144132\n",
      "5555-th loss is : 0.191\n",
      "5556-th loss is : 0.0889809\n",
      "5557-th loss is : 0.119789\n",
      "5558-th loss is : 0.245576\n",
      "5559-th loss is : 0.295605\n",
      "5560-th loss is : 0.159352\n",
      "5561-th loss is : 0.0536869\n",
      "5562-th loss is : 0.121222\n",
      "5563-th loss is : 0.0545858\n",
      "5564-th loss is : 0.0560403\n",
      "5565-th loss is : 0.179727\n",
      "5566-th loss is : 0.169279\n",
      "5567-th loss is : 0.0129166\n",
      "5568-th loss is : 0.189599\n",
      "5569-th loss is : 0.14015\n",
      "5570-th loss is : 0.0901795\n",
      "5571-th loss is : 0.0808197\n",
      "5572-th loss is : 0.145681\n",
      "5573-th loss is : 0.0194733\n",
      "5574-th loss is : 0.189169\n",
      "5575-th loss is : 0.121902\n",
      "5576-th loss is : 0.10259\n",
      "5577-th loss is : 0.00193746\n",
      "5578-th loss is : 0.285296\n",
      "5579-th loss is : 0.129925\n",
      "5580-th loss is : 0.16482\n",
      "5581-th loss is : 0.00390934\n",
      "5582-th loss is : 0.0171492\n",
      "5583-th loss is : 0.0880031\n",
      "5584-th loss is : 0.01591\n",
      "5585-th loss is : 0.137323\n",
      "5586-th loss is : 0.205521\n",
      "5587-th loss is : 0.0680365\n",
      "5588-th loss is : 0.226922\n",
      "5589-th loss is : 0.0349095\n",
      "5590-th loss is : 0.0310879\n",
      "5591-th loss is : 0.00159371\n",
      "5592-th loss is : 0.230117\n",
      "5593-th loss is : 0.106933\n",
      "5594-th loss is : 0.0505311\n",
      "5595-th loss is : 0.210128\n",
      "5596-th loss is : 0.152954\n",
      "5597-th loss is : 0.25801\n",
      "5598-th loss is : 0.110266\n",
      "5599-th loss is : 0.0229678\n",
      "5600-th loss is : 0.166278\n",
      "5601-th loss is : 0.190185\n",
      "5602-th loss is : 0.288398\n",
      "5603-th loss is : 0.0390133\n",
      "5604-th loss is : 0.129637\n",
      "5605-th loss is : 0.234456\n",
      "5606-th loss is : 0.238726\n",
      "5607-th loss is : 0.255349\n",
      "5608-th loss is : 0.104997\n",
      "5609-th loss is : 0.00552921\n",
      "5610-th loss is : 0.0392821\n",
      "5611-th loss is : 0.0587896\n",
      "5612-th loss is : 0.00857321\n",
      "5613-th loss is : 0.00990886\n",
      "5614-th loss is : 0.00268538\n",
      "5615-th loss is : 0.0879412\n",
      "5616-th loss is : 0.00152634\n",
      "5617-th loss is : 0.0260519\n",
      "5618-th loss is : 0.240984\n",
      "5619-th loss is : 0.102063\n",
      "5620-th loss is : 0.257262\n",
      "5621-th loss is : 0.290051\n",
      "5622-th loss is : 0.0742841\n",
      "5623-th loss is : 0.28962\n",
      "5624-th loss is : 0.104308\n",
      "5625-th loss is : 0.210484\n",
      "5626-th loss is : 0.106497\n",
      "5627-th loss is : 0.0208027\n",
      "5628-th loss is : 0.16205\n",
      "5629-th loss is : 0.0441123\n",
      "5630-th loss is : 0.0241698\n",
      "5631-th loss is : 0.0107147\n",
      "5632-th loss is : 0.00337974\n",
      "5633-th loss is : 0.0252755\n",
      "5634-th loss is : 0.140117\n",
      "5635-th loss is : 0.0337065\n",
      "5636-th loss is : 0.279804\n",
      "5637-th loss is : 0.128693\n",
      "5638-th loss is : 0.0232344\n",
      "5639-th loss is : 0.00214307\n",
      "5640-th loss is : 0.1172\n",
      "5641-th loss is : 0.0259341\n",
      "5642-th loss is : 0.154921\n",
      "5643-th loss is : 0.288914\n",
      "5644-th loss is : 0.00968695\n",
      "5645-th loss is : 0.0892046\n",
      "5646-th loss is : 0.206456\n",
      "5647-th loss is : 0.0399962\n",
      "5648-th loss is : 0.0822959\n",
      "5649-th loss is : 0.00131811\n",
      "5650-th loss is : 0.103949\n",
      "5651-th loss is : 0.0749887\n",
      "5652-th loss is : 0.181457\n",
      "5653-th loss is : 0.0443052\n",
      "5654-th loss is : 0.0979145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5655-th loss is : 0.0715577\n",
      "5656-th loss is : 0.276402\n",
      "5657-th loss is : 0.0670699\n",
      "5658-th loss is : 0.0357661\n",
      "5659-th loss is : 0.209224\n",
      "5660-th loss is : 0.144688\n",
      "5661-th loss is : 0.249107\n",
      "5662-th loss is : 0.184066\n",
      "5663-th loss is : 0.0978238\n",
      "5664-th loss is : 0.0711522\n",
      "5665-th loss is : 0.0437171\n",
      "5666-th loss is : 0.0235016\n",
      "5667-th loss is : 0.0286963\n",
      "5668-th loss is : 0.0117056\n",
      "5669-th loss is : 0.253512\n",
      "5670-th loss is : 0.0742945\n",
      "5671-th loss is : 0.0852634\n",
      "5672-th loss is : 0.0195395\n",
      "5673-th loss is : 0.0164406\n",
      "5674-th loss is : 0.0797247\n",
      "5675-th loss is : 0.290078\n",
      "5676-th loss is : 0.0332006\n",
      "5677-th loss is : 0.103475\n",
      "5678-th loss is : 0.115771\n",
      "5679-th loss is : 0.0116399\n",
      "5680-th loss is : 0.12056\n",
      "5681-th loss is : 0.0630623\n",
      "5682-th loss is : 0.0923633\n",
      "5683-th loss is : 0.0825955\n",
      "5684-th loss is : 0.177423\n",
      "5685-th loss is : 0.133675\n",
      "5686-th loss is : 0.236558\n",
      "5687-th loss is : 0.0622284\n",
      "5688-th loss is : 0.261646\n",
      "5689-th loss is : 0.219623\n",
      "5690-th loss is : 0.100556\n",
      "5691-th loss is : 0.0473671\n",
      "5692-th loss is : 0.288028\n",
      "5693-th loss is : 0.086443\n",
      "5694-th loss is : 0.223725\n",
      "5695-th loss is : 0.200379\n",
      "5696-th loss is : 0.0455134\n",
      "5697-th loss is : 0.0990526\n",
      "5698-th loss is : 0.108464\n",
      "5699-th loss is : 0.0146094\n",
      "5700-th loss is : 0.00373341\n",
      "5701-th loss is : 0.00200625\n",
      "5702-th loss is : 0.209728\n",
      "5703-th loss is : 0.273872\n",
      "5704-th loss is : 0.0472537\n",
      "5705-th loss is : 0.18314\n",
      "5706-th loss is : 0.0153804\n",
      "5707-th loss is : 0.0273729\n",
      "5708-th loss is : 0.169047\n",
      "5709-th loss is : 0.00698889\n",
      "5710-th loss is : 0.00911869\n",
      "5711-th loss is : 0.106925\n",
      "5712-th loss is : 0.146455\n",
      "5713-th loss is : 0.181192\n",
      "5714-th loss is : 0.0699586\n",
      "5715-th loss is : 0.277153\n",
      "5716-th loss is : 0.00219114\n",
      "5717-th loss is : 0.139969\n",
      "5718-th loss is : 0.272901\n",
      "5719-th loss is : 0.0169219\n",
      "5720-th loss is : 0.273995\n",
      "5721-th loss is : 0.130157\n",
      "5722-th loss is : 0.0601188\n",
      "5723-th loss is : 0.230275\n",
      "5724-th loss is : 0.175503\n",
      "5725-th loss is : 0.132041\n",
      "5726-th loss is : 0.0313029\n",
      "5727-th loss is : 0.171693\n",
      "5728-th loss is : 0.282931\n",
      "5729-th loss is : 0.12425\n",
      "5730-th loss is : 0.278852\n",
      "5731-th loss is : 0.196396\n",
      "5732-th loss is : 0.16287\n",
      "5733-th loss is : 0.127322\n",
      "5734-th loss is : 0.0341677\n",
      "5735-th loss is : 0.00156109\n",
      "5736-th loss is : 0.0537187\n",
      "5737-th loss is : 0.0276399\n",
      "5738-th loss is : 0.0507495\n",
      "5739-th loss is : 0.163951\n",
      "5740-th loss is : 0.107217\n",
      "5741-th loss is : 0.131\n",
      "5742-th loss is : 0.202025\n",
      "5743-th loss is : 0.012592\n",
      "5744-th loss is : 0.0778232\n",
      "5745-th loss is : 0.159809\n",
      "5746-th loss is : 0.166681\n",
      "5747-th loss is : 0.22459\n",
      "5748-th loss is : 0.231287\n",
      "5749-th loss is : 0.0697318\n",
      "5750-th loss is : 0.00746386\n",
      "5751-th loss is : 0.108366\n",
      "5752-th loss is : 0.0587231\n",
      "5753-th loss is : 0.132363\n",
      "5754-th loss is : 0.0835894\n",
      "5755-th loss is : 0.0253748\n",
      "5756-th loss is : 0.0791997\n",
      "5757-th loss is : 0.190164\n",
      "5758-th loss is : 0.00498097\n",
      "5759-th loss is : 0.139199\n",
      "5760-th loss is : 0.0121471\n",
      "5761-th loss is : 0.152902\n",
      "5762-th loss is : 0.00429957\n",
      "5763-th loss is : 0.0077152\n",
      "5764-th loss is : 0.00897369\n",
      "5765-th loss is : 0.21918\n",
      "5766-th loss is : 0.0335442\n",
      "5767-th loss is : 0.195387\n",
      "5768-th loss is : 0.197791\n",
      "5769-th loss is : 0.118467\n",
      "5770-th loss is : 0.0300954\n",
      "5771-th loss is : 0.176487\n",
      "5772-th loss is : 0.0496453\n",
      "5773-th loss is : 0.0957702\n",
      "5774-th loss is : 0.232814\n",
      "5775-th loss is : 0.016737\n",
      "5776-th loss is : 0.112884\n",
      "5777-th loss is : 0.00546794\n",
      "5778-th loss is : 0.0739084\n",
      "5779-th loss is : 0.0685275\n",
      "5780-th loss is : 0.177875\n",
      "5781-th loss is : 0.00370529\n",
      "5782-th loss is : 0.00232827\n",
      "5783-th loss is : 0.0181306\n",
      "5784-th loss is : 0.0748977\n",
      "5785-th loss is : 0.247231\n",
      "5786-th loss is : 0.276672\n",
      "5787-th loss is : 0.0116449\n",
      "5788-th loss is : 0.185402\n",
      "5789-th loss is : 0.137312\n",
      "5790-th loss is : 0.205269\n",
      "5791-th loss is : 0.0391542\n",
      "5792-th loss is : 0.079414\n",
      "5793-th loss is : 0.0111465\n",
      "5794-th loss is : 0.268521\n",
      "5795-th loss is : 0.0792213\n",
      "5796-th loss is : 0.0603446\n",
      "5797-th loss is : 0.0455083\n",
      "5798-th loss is : 0.22432\n",
      "5799-th loss is : 0.0196247\n",
      "5800-th loss is : 0.116884\n",
      "5801-th loss is : 0.0157151\n",
      "5802-th loss is : 0.181202\n",
      "5803-th loss is : 0.0432922\n",
      "5804-th loss is : 0.0139705\n",
      "5805-th loss is : 0.0184567\n",
      "5806-th loss is : 0.209368\n",
      "5807-th loss is : 0.00612178\n",
      "5808-th loss is : 0.0554784\n",
      "5809-th loss is : 0.164576\n",
      "5810-th loss is : 0.000878524\n",
      "5811-th loss is : 0.261569\n",
      "5812-th loss is : 0.0776324\n",
      "5813-th loss is : 0.012225\n",
      "5814-th loss is : 0.0550146\n",
      "5815-th loss is : 0.256475\n",
      "5816-th loss is : 0.27075\n",
      "5817-th loss is : 0.0847342\n",
      "5818-th loss is : 0.197513\n",
      "5819-th loss is : 0.138969\n",
      "5820-th loss is : 0.00947654\n",
      "5821-th loss is : 0.0209961\n",
      "5822-th loss is : 0.0261148\n",
      "5823-th loss is : 0.0437864\n",
      "5824-th loss is : 0.00400808\n",
      "5825-th loss is : 0.0177552\n",
      "5826-th loss is : 0.266616\n",
      "5827-th loss is : 0.113175\n",
      "5828-th loss is : 0.184953\n",
      "5829-th loss is : 0.0350214\n",
      "5830-th loss is : 0.167755\n",
      "5831-th loss is : 0.0166173\n",
      "5832-th loss is : 0.00599339\n",
      "5833-th loss is : 0.209934\n",
      "5834-th loss is : 0.187937\n",
      "5835-th loss is : 0.0413804\n",
      "5836-th loss is : 0.16051\n",
      "5837-th loss is : 0.235979\n",
      "5838-th loss is : 0.0020761\n",
      "5839-th loss is : 0.00805876\n",
      "5840-th loss is : 0.02589\n",
      "5841-th loss is : 0.0520429\n",
      "5842-th loss is : 0.0188432\n",
      "5843-th loss is : 0.22908\n",
      "5844-th loss is : 0.112025\n",
      "5845-th loss is : 0.0395839\n",
      "5846-th loss is : 0.00139463\n",
      "5847-th loss is : 0.00713225\n",
      "5848-th loss is : 0.0439438\n",
      "5849-th loss is : 0.0283631\n",
      "5850-th loss is : 0.197074\n",
      "5851-th loss is : 0.108908\n",
      "5852-th loss is : 0.0692728\n",
      "5853-th loss is : 0.206366\n",
      "5854-th loss is : 0.0380329\n",
      "5855-th loss is : 0.245609\n",
      "5856-th loss is : 0.212243\n",
      "5857-th loss is : 0.202438\n",
      "5858-th loss is : 0.00388936\n",
      "5859-th loss is : 0.1097\n",
      "5860-th loss is : 0.0554883\n",
      "5861-th loss is : 0.0541979\n",
      "5862-th loss is : 0.00247679\n",
      "5863-th loss is : 0.238817\n",
      "5864-th loss is : 0.038697\n",
      "5865-th loss is : 0.110382\n",
      "5866-th loss is : 0.0920879\n",
      "5867-th loss is : 0.123359\n",
      "5868-th loss is : 0.220637\n",
      "5869-th loss is : 0.0139915\n",
      "5870-th loss is : 0.139414\n",
      "5871-th loss is : 0.26819\n",
      "5872-th loss is : 0.014593\n",
      "5873-th loss is : 0.178885\n",
      "5874-th loss is : 0.111431\n",
      "5875-th loss is : 0.0503458\n",
      "5876-th loss is : 0.228849\n",
      "5877-th loss is : 0.0167149\n",
      "5878-th loss is : 0.256348\n",
      "5879-th loss is : 0.210207\n",
      "5880-th loss is : 0.0179814\n",
      "5881-th loss is : 0.10123\n",
      "5882-th loss is : 0.0772116\n",
      "5883-th loss is : 0.00558744\n",
      "5884-th loss is : 0.0819189\n",
      "5885-th loss is : 0.00471097\n",
      "5886-th loss is : 0.0013092\n",
      "5887-th loss is : 0.170729\n",
      "5888-th loss is : 0.0158188\n",
      "5889-th loss is : 0.0320897\n",
      "5890-th loss is : 0.0394344\n",
      "5891-th loss is : 0.23363\n",
      "5892-th loss is : 0.120074\n",
      "5893-th loss is : 0.0644716\n",
      "5894-th loss is : 0.0519164\n",
      "5895-th loss is : 0.16327\n",
      "5896-th loss is : 0.0645641\n",
      "5897-th loss is : 0.193992\n",
      "5898-th loss is : 0.119518\n",
      "5899-th loss is : 0.0218557\n",
      "5900-th loss is : 0.0346878\n",
      "5901-th loss is : 0.0104914\n",
      "5902-th loss is : 0.000859107\n",
      "5903-th loss is : 0.103416\n",
      "5904-th loss is : 0.0253347\n",
      "5905-th loss is : 0.0239583\n",
      "5906-th loss is : 0.199545\n",
      "5907-th loss is : 0.0142608\n",
      "5908-th loss is : 0.0167531\n",
      "5909-th loss is : 0.193421\n",
      "5910-th loss is : 0.153328\n",
      "5911-th loss is : 0.264496\n",
      "5912-th loss is : 0.00757442\n",
      "5913-th loss is : 0.0221321\n",
      "5914-th loss is : 0.0656786\n",
      "5915-th loss is : 0.175438\n",
      "5916-th loss is : 0.0105157\n",
      "5917-th loss is : 0.00730053\n",
      "5918-th loss is : 0.208816\n",
      "5919-th loss is : 0.0234677\n",
      "5920-th loss is : 0.0854051\n",
      "5921-th loss is : 0.258372\n",
      "5922-th loss is : 0.0726613\n",
      "5923-th loss is : 0.00660817\n",
      "5924-th loss is : 0.0866553\n",
      "5925-th loss is : 0.218186\n",
      "5926-th loss is : 0.00715896\n",
      "5927-th loss is : 0.023757\n",
      "5928-th loss is : 0.0884148\n",
      "5929-th loss is : 0.102258\n",
      "5930-th loss is : 0.0905322\n",
      "5931-th loss is : 0.000791461\n",
      "5932-th loss is : 0.00515509\n",
      "5933-th loss is : 0.252324\n",
      "5934-th loss is : 0.171668\n",
      "5935-th loss is : 0.00387062\n",
      "5936-th loss is : 0.104937\n",
      "5937-th loss is : 0.255376\n",
      "5938-th loss is : 0.133168\n",
      "5939-th loss is : 0.0253341\n",
      "5940-th loss is : 0.179319\n",
      "5941-th loss is : 0.146273\n",
      "5942-th loss is : 0.0431723\n",
      "5943-th loss is : 0.21411\n",
      "5944-th loss is : 0.090756\n",
      "5945-th loss is : 0.00875249\n",
      "5946-th loss is : 0.229685\n",
      "5947-th loss is : 0.0157086\n",
      "5948-th loss is : 0.255734\n",
      "5949-th loss is : 0.260976\n",
      "5950-th loss is : 0.0539296\n",
      "5951-th loss is : 0.248698\n",
      "5952-th loss is : 0.0267573\n",
      "5953-th loss is : 0.230003\n",
      "5954-th loss is : 0.10379\n",
      "5955-th loss is : 0.00294998\n",
      "5956-th loss is : 0.117986\n",
      "5957-th loss is : 0.168728\n",
      "5958-th loss is : 0.123344\n",
      "5959-th loss is : 0.186543\n",
      "5960-th loss is : 0.17567\n",
      "5961-th loss is : 0.00437419\n",
      "5962-th loss is : 0.0748282\n",
      "5963-th loss is : 0.0839339\n",
      "5964-th loss is : 0.185482\n",
      "5965-th loss is : 0.223083\n",
      "5966-th loss is : 0.088967\n",
      "5967-th loss is : 0.0364908\n",
      "5968-th loss is : 0.047444\n",
      "5969-th loss is : 0.176024\n",
      "5970-th loss is : 0.00300995\n",
      "5971-th loss is : 0.00100491\n",
      "5972-th loss is : 0.0169927\n",
      "5973-th loss is : 0.0540425\n",
      "5974-th loss is : 0.0186282\n",
      "5975-th loss is : 0.0353587\n",
      "5976-th loss is : 0.252698\n",
      "5977-th loss is : 0.134423\n",
      "5978-th loss is : 0.087979\n",
      "5979-th loss is : 0.00134907\n",
      "5980-th loss is : 0.0193517\n",
      "5981-th loss is : 0.139217\n",
      "5982-th loss is : 0.226971\n",
      "5983-th loss is : 0.00442909\n",
      "5984-th loss is : 0.145806\n",
      "5985-th loss is : 0.0985348\n",
      "5986-th loss is : 0.00336037\n",
      "5987-th loss is : 0.135281\n",
      "5988-th loss is : 0.178759\n",
      "5989-th loss is : 0.0466535\n",
      "5990-th loss is : 0.000328516\n",
      "5991-th loss is : 0.0925136\n",
      "5992-th loss is : 0.182472\n",
      "5993-th loss is : 0.128216\n",
      "5994-th loss is : 0.210098\n",
      "5995-th loss is : 0.165078\n",
      "5996-th loss is : 0.126946\n",
      "5997-th loss is : 0.189412\n",
      "5998-th loss is : 0.189636\n",
      "5999-th loss is : 0.021177\n",
      "6000-th loss is : 0.00565209\n",
      "6001-th loss is : 0.0369592\n",
      "6002-th loss is : 0.0452701\n",
      "6003-th loss is : 0.0118247\n",
      "6004-th loss is : 0.0145453\n",
      "6005-th loss is : 0.00643754\n",
      "6006-th loss is : 0.0598922\n",
      "6007-th loss is : 0.243492\n",
      "6008-th loss is : 0.159563\n",
      "6009-th loss is : 0.000473466\n",
      "6010-th loss is : 0.0164865\n",
      "6011-th loss is : 0.20291\n",
      "6012-th loss is : 0.0505657\n",
      "6013-th loss is : 0.124288\n",
      "6014-th loss is : 0.00949624\n",
      "6015-th loss is : 0.00590131\n",
      "6016-th loss is : 0.028833\n",
      "6017-th loss is : 0.0721186\n",
      "6018-th loss is : 0.0208348\n",
      "6019-th loss is : 0.250068\n",
      "6020-th loss is : 0.202261\n",
      "6021-th loss is : 0.0107931\n",
      "6022-th loss is : 0.254258\n",
      "6023-th loss is : 0.0242677\n",
      "6024-th loss is : 0.19204\n",
      "6025-th loss is : 0.0890761\n",
      "6026-th loss is : 0.0230623\n",
      "6027-th loss is : 0.105532\n",
      "6028-th loss is : 0.158838\n",
      "6029-th loss is : 0.228424\n",
      "6030-th loss is : 0.0563012\n",
      "6031-th loss is : 0.000449299\n",
      "6032-th loss is : 0.00069416\n",
      "6033-th loss is : 0.229422\n",
      "6034-th loss is : 0.0256837\n",
      "6035-th loss is : 0.177593\n",
      "6036-th loss is : 0.0145301\n",
      "6037-th loss is : 0.0831409\n",
      "6038-th loss is : 0.0967992\n",
      "6039-th loss is : 0.154279\n",
      "6040-th loss is : 0.113204\n",
      "6041-th loss is : 0.217734\n",
      "6042-th loss is : 0.093526\n",
      "6043-th loss is : 0.0118\n",
      "6044-th loss is : 0.0550944\n",
      "6045-th loss is : 0.000210581\n",
      "6046-th loss is : 0.00513598\n",
      "6047-th loss is : 0.135491\n",
      "6048-th loss is : 0.0171118\n",
      "6049-th loss is : 0.0117531\n",
      "6050-th loss is : 0.185821\n",
      "6051-th loss is : 0.116536\n",
      "6052-th loss is : 0.104302\n",
      "6053-th loss is : 0.00276862\n",
      "6054-th loss is : 0.0158736\n",
      "6055-th loss is : 0.0668362\n",
      "6056-th loss is : 0.22316\n",
      "6057-th loss is : 0.0107722\n",
      "6058-th loss is : 0.246639\n",
      "6059-th loss is : 0.0864865\n",
      "6060-th loss is : 0.212246\n",
      "6061-th loss is : 0.242918\n",
      "6062-th loss is : 0.0127145\n",
      "6063-th loss is : 0.0311213\n",
      "6064-th loss is : 0.0115047\n",
      "6065-th loss is : 0.0392317\n",
      "6066-th loss is : 0.0113811\n",
      "6067-th loss is : 0.234052\n",
      "6068-th loss is : 0.0396451\n",
      "6069-th loss is : 0.0136045\n",
      "6070-th loss is : 0.045254\n",
      "6071-th loss is : 0.00225234\n",
      "6072-th loss is : 0.00230849\n",
      "6073-th loss is : 0.00487753\n",
      "6074-th loss is : 0.165665\n",
      "6075-th loss is : 0.129602\n",
      "6076-th loss is : 0.232575\n",
      "6077-th loss is : 0.00127597\n",
      "6078-th loss is : 0.222802\n",
      "6079-th loss is : 0.0929888\n",
      "6080-th loss is : 0.00809452\n",
      "6081-th loss is : 0.0929845\n",
      "6082-th loss is : 0.17615\n",
      "6083-th loss is : 0.242883\n",
      "6084-th loss is : 0.035871\n",
      "6085-th loss is : 0.0164953\n",
      "6086-th loss is : 0.0355506\n",
      "6087-th loss is : 0.00406873\n",
      "6088-th loss is : 0.0155929\n",
      "6089-th loss is : 0.15164\n",
      "6090-th loss is : 0.0449441\n",
      "6091-th loss is : 0.123175\n",
      "6092-th loss is : 0.145656\n",
      "6093-th loss is : 0.0876126\n",
      "6094-th loss is : 0.0111864\n",
      "6095-th loss is : 0.113997\n",
      "6096-th loss is : 0.0142862\n",
      "6097-th loss is : 0.086919\n",
      "6098-th loss is : 0.147934\n",
      "6099-th loss is : 0.0405891\n",
      "6100-th loss is : 0.18223\n",
      "6101-th loss is : 0.000618181\n",
      "6102-th loss is : 0.231204\n",
      "6103-th loss is : 0.193878\n",
      "6104-th loss is : 0.0157456\n",
      "6105-th loss is : 0.0546228\n",
      "6106-th loss is : 0.023806\n",
      "6107-th loss is : 0.0924913\n",
      "6108-th loss is : 0.017414\n",
      "6109-th loss is : 0.0256274\n",
      "6110-th loss is : 0.242476\n",
      "6111-th loss is : 0.199081\n",
      "6112-th loss is : 0.0225587\n",
      "6113-th loss is : 0.123759\n",
      "6114-th loss is : 0.0775026\n",
      "6115-th loss is : 0.0114514\n",
      "6116-th loss is : 0.0241994\n",
      "6117-th loss is : 0.0443301\n",
      "6118-th loss is : 0.195896\n",
      "6119-th loss is : 0.00205259\n",
      "6120-th loss is : 0.00658199\n",
      "6121-th loss is : 0.0307496\n",
      "6122-th loss is : 0.200952\n",
      "6123-th loss is : 0.0199473\n",
      "6124-th loss is : 0.0703581\n",
      "6125-th loss is : 0.0103828\n",
      "6126-th loss is : 0.0495908\n",
      "6127-th loss is : 0.00162161\n",
      "6128-th loss is : 0.00308507\n",
      "6129-th loss is : 0.0185344\n",
      "6130-th loss is : 0.112089\n",
      "6131-th loss is : 0.00124521\n",
      "6132-th loss is : 0.000610481\n",
      "6133-th loss is : 0.101493\n",
      "6134-th loss is : 0.197613\n",
      "6135-th loss is : 0.0614717\n",
      "6136-th loss is : 0.176766\n",
      "6137-th loss is : 0.00247737\n",
      "6138-th loss is : 0.000171804\n",
      "6139-th loss is : 0.135585\n",
      "6140-th loss is : 0.130795\n",
      "6141-th loss is : 0.219354\n",
      "6142-th loss is : 0.00632917\n",
      "6143-th loss is : 0.149825\n",
      "6144-th loss is : 0.0522469\n",
      "6145-th loss is : 0.197597\n",
      "6146-th loss is : 0.0511875\n",
      "6147-th loss is : 0.0195016\n",
      "6148-th loss is : 0.206095\n",
      "6149-th loss is : 0.141052\n",
      "6150-th loss is : 0.178272\n",
      "6151-th loss is : 0.0270847\n",
      "6152-th loss is : 0.123254\n",
      "6153-th loss is : 0.000370989\n",
      "6154-th loss is : 0.159385\n",
      "6155-th loss is : 0.216967\n",
      "6156-th loss is : 0.125271\n",
      "6157-th loss is : 0.152082\n",
      "6158-th loss is : 0.0593445\n",
      "6159-th loss is : 0.0858262\n",
      "6160-th loss is : 0.220822\n",
      "6161-th loss is : 0.00206489\n",
      "6162-th loss is : 0.137386\n",
      "6163-th loss is : 0.0107119\n",
      "6164-th loss is : 0.197315\n",
      "6165-th loss is : 0.215578\n",
      "6166-th loss is : 0.122366\n",
      "6167-th loss is : 0.197309\n",
      "6168-th loss is : 0.0704685\n",
      "6169-th loss is : 0.101166\n",
      "6170-th loss is : 0.130336\n",
      "6171-th loss is : 0.0990075\n",
      "6172-th loss is : 0.0392405\n",
      "6173-th loss is : 0.01399\n",
      "6174-th loss is : 0.203724\n",
      "6175-th loss is : 0.174794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6176-th loss is : 0.00312194\n",
      "6177-th loss is : 0.00147351\n",
      "6178-th loss is : 0.119679\n",
      "6179-th loss is : 5.31824e-05\n",
      "6180-th loss is : 0.150335\n",
      "6181-th loss is : 0.144291\n",
      "6182-th loss is : 0.0116045\n",
      "6183-th loss is : 0.112117\n",
      "6184-th loss is : 0.0273892\n",
      "6185-th loss is : 0.050783\n",
      "6186-th loss is : 0.0905591\n",
      "6187-th loss is : 0.00392053\n",
      "6188-th loss is : 0.0193285\n",
      "6189-th loss is : 0.0493718\n",
      "6190-th loss is : 0.11505\n",
      "6191-th loss is : 0.0252851\n",
      "6192-th loss is : 0.100058\n",
      "6193-th loss is : 0.0282663\n",
      "6194-th loss is : 0.105051\n",
      "6195-th loss is : 0.0218771\n",
      "6196-th loss is : 0.00610051\n",
      "6197-th loss is : 0.231722\n",
      "6198-th loss is : 0.0554621\n",
      "6199-th loss is : 0.154413\n",
      "6200-th loss is : 0.0282441\n",
      "6201-th loss is : 0.149444\n",
      "6202-th loss is : 0.172958\n",
      "6203-th loss is : 0.0583563\n",
      "6204-th loss is : 0.00728888\n",
      "6205-th loss is : 0.163754\n",
      "6206-th loss is : 0.000410288\n",
      "6207-th loss is : 0.090592\n",
      "6208-th loss is : 0.1202\n",
      "6209-th loss is : 0.077234\n",
      "6210-th loss is : 0.119309\n",
      "6211-th loss is : 0.139754\n",
      "6212-th loss is : 0.156673\n",
      "6213-th loss is : 0.149195\n",
      "6214-th loss is : 0.0122459\n",
      "6215-th loss is : 0.0155041\n",
      "6216-th loss is : 0.0933624\n",
      "6217-th loss is : 0.00401284\n",
      "6218-th loss is : 0.0283923\n",
      "6219-th loss is : 0.00157645\n",
      "6220-th loss is : 0.027463\n",
      "6221-th loss is : 0.162532\n",
      "6222-th loss is : 0.226989\n",
      "6223-th loss is : 0.0812137\n",
      "6224-th loss is : 0.0155094\n",
      "6225-th loss is : 0.00221947\n",
      "6226-th loss is : 0.0450906\n",
      "6227-th loss is : 0.0946845\n",
      "6228-th loss is : 0.00361876\n",
      "6229-th loss is : 0.131282\n",
      "6230-th loss is : 0.0790761\n",
      "6231-th loss is : 0.0977085\n",
      "6232-th loss is : 0.000511132\n",
      "6233-th loss is : 0.0318474\n",
      "6234-th loss is : 0.0865901\n",
      "6235-th loss is : 0.0246965\n",
      "6236-th loss is : 0.177362\n",
      "6237-th loss is : 0.144596\n",
      "6238-th loss is : 0.0633285\n",
      "6239-th loss is : 0.000927046\n",
      "6240-th loss is : 0.106264\n",
      "6241-th loss is : 0.184301\n",
      "6242-th loss is : 0.0784837\n",
      "6243-th loss is : 0.0421083\n",
      "6244-th loss is : 0.0729154\n",
      "6245-th loss is : 0.006489\n",
      "6246-th loss is : 0.00604387\n",
      "6247-th loss is : 0.0683648\n",
      "6248-th loss is : 0.00274252\n",
      "6249-th loss is : 0.0896871\n",
      "6250-th loss is : 0.0116567\n",
      "6251-th loss is : 0.00500819\n",
      "6252-th loss is : 0.0993107\n",
      "6253-th loss is : 0.117512\n",
      "6254-th loss is : 0.04809\n",
      "6255-th loss is : 5.6428e-05\n",
      "6256-th loss is : 0.212483\n",
      "6257-th loss is : 0.178585\n",
      "6258-th loss is : 0.0462769\n",
      "6259-th loss is : 0.0046729\n",
      "6260-th loss is : 0.0550418\n",
      "6261-th loss is : 0.0808263\n",
      "6262-th loss is : 0.0207042\n",
      "6263-th loss is : 0.0481514\n",
      "6264-th loss is : 0.124717\n",
      "6265-th loss is : 1.41115e-05\n",
      "6266-th loss is : 0.0825517\n",
      "6267-th loss is : 0.0114706\n",
      "6268-th loss is : 0.0546004\n",
      "6269-th loss is : 0.0110743\n",
      "6270-th loss is : 0.0300017\n",
      "6271-th loss is : 0.153622\n",
      "6272-th loss is : 0.144935\n",
      "6273-th loss is : 0.0766557\n",
      "6274-th loss is : 0.0106309\n",
      "6275-th loss is : 0.220044\n",
      "6276-th loss is : 0.187434\n",
      "6277-th loss is : 0.132971\n",
      "6278-th loss is : 0.145055\n",
      "6279-th loss is : 0.206537\n",
      "6280-th loss is : 0.000178399\n",
      "6281-th loss is : 0.0564206\n",
      "6282-th loss is : 0.109178\n",
      "6283-th loss is : 0.1961\n",
      "6284-th loss is : 0.00331024\n",
      "6285-th loss is : 0.196594\n",
      "6286-th loss is : 0.0892368\n",
      "6287-th loss is : 0.000406693\n",
      "6288-th loss is : 0.0972895\n",
      "6289-th loss is : 0.111326\n",
      "6290-th loss is : 0.0390563\n",
      "6291-th loss is : 0.0381891\n",
      "6292-th loss is : 0.000721299\n",
      "6293-th loss is : 0.15983\n",
      "6294-th loss is : 0.0103576\n",
      "6295-th loss is : 0.0453325\n",
      "6296-th loss is : 0.215674\n",
      "6297-th loss is : 0.0456538\n",
      "6298-th loss is : 0.0250735\n",
      "6299-th loss is : 0.0279227\n",
      "6300-th loss is : 0.0308027\n",
      "6301-th loss is : 0.103883\n",
      "6302-th loss is : 0.158554\n",
      "6303-th loss is : 0.000844044\n",
      "6304-th loss is : 0.0858537\n",
      "6305-th loss is : 6.25259e-05\n",
      "6306-th loss is : 0.0890676\n",
      "6307-th loss is : 0.109031\n",
      "6308-th loss is : 0.0746639\n",
      "6309-th loss is : 0.0303887\n",
      "6310-th loss is : 1.2912e-05\n",
      "6311-th loss is : 0.00220587\n",
      "6312-th loss is : 0.0066269\n",
      "6313-th loss is : 0.0384225\n",
      "6314-th loss is : 0.123806\n",
      "6315-th loss is : 0.0827106\n",
      "6316-th loss is : 0.0404552\n",
      "6317-th loss is : 0.00460732\n",
      "6318-th loss is : 0.212625\n",
      "6319-th loss is : 0.0198563\n",
      "6320-th loss is : 0.00732311\n",
      "6321-th loss is : 0.0142959\n",
      "6322-th loss is : 0.0254779\n",
      "6323-th loss is : 0.217041\n",
      "6324-th loss is : 0.121261\n",
      "6325-th loss is : 0.0966235\n",
      "6326-th loss is : 0.047644\n",
      "6327-th loss is : 0.167127\n",
      "6328-th loss is : 0.169148\n",
      "6329-th loss is : 0.0569279\n",
      "6330-th loss is : 0.109076\n",
      "6331-th loss is : 0.0151885\n",
      "6332-th loss is : 0.128649\n",
      "6333-th loss is : 0.173304\n",
      "6334-th loss is : 0.000562727\n",
      "6335-th loss is : 0.0227874\n",
      "6336-th loss is : 0.00868442\n",
      "6337-th loss is : 0.129624\n",
      "6338-th loss is : 0.0180092\n",
      "6339-th loss is : 0.173319\n",
      "6340-th loss is : 0.194886\n",
      "6341-th loss is : 0.101769\n",
      "6342-th loss is : 0.00197088\n",
      "6343-th loss is : 0.137814\n",
      "6344-th loss is : 0.0055686\n",
      "6345-th loss is : 0.0317614\n",
      "6346-th loss is : 0.211982\n",
      "6347-th loss is : 0.000195933\n",
      "6348-th loss is : 0.216592\n",
      "6349-th loss is : 0.0941446\n",
      "6350-th loss is : 0.115992\n",
      "6351-th loss is : 0.123395\n",
      "6352-th loss is : 0.0499185\n",
      "6353-th loss is : 0.155639\n",
      "6354-th loss is : 0.0972883\n",
      "6355-th loss is : 0.0129455\n",
      "6356-th loss is : 0.0923273\n",
      "6357-th loss is : 0.100958\n",
      "6358-th loss is : 0.0639739\n",
      "6359-th loss is : 0.0841791\n",
      "6360-th loss is : 0.0538041\n",
      "6361-th loss is : 0.155513\n",
      "6362-th loss is : 0.0596056\n",
      "6363-th loss is : 0.0069695\n",
      "6364-th loss is : 0.0901071\n",
      "6365-th loss is : 0.175526\n",
      "6366-th loss is : 0.000400562\n",
      "6367-th loss is : 0.0862995\n",
      "6368-th loss is : 0.0286701\n",
      "6369-th loss is : 0.125665\n",
      "6370-th loss is : 0.112235\n",
      "6371-th loss is : 0.0366634\n",
      "6372-th loss is : 0.0152983\n",
      "6373-th loss is : 0.00458834\n",
      "6374-th loss is : 0.031409\n",
      "6375-th loss is : 4.63968e-06\n",
      "6376-th loss is : 0.0458536\n",
      "6377-th loss is : 0.155279\n",
      "6378-th loss is : 0.108334\n",
      "6379-th loss is : 0.0851429\n",
      "6380-th loss is : 0.0972841\n",
      "6381-th loss is : 0.0443742\n",
      "6382-th loss is : 0.0516955\n",
      "6383-th loss is : 0.218179\n",
      "6384-th loss is : 0.11003\n",
      "6385-th loss is : 0.108352\n",
      "6386-th loss is : 0.0033579\n",
      "6387-th loss is : 0.0570297\n",
      "6388-th loss is : 0.00135379\n",
      "6389-th loss is : 0.0457199\n",
      "6390-th loss is : 0.000359572\n",
      "6391-th loss is : 0.169227\n",
      "6392-th loss is : 0.0520541\n",
      "6393-th loss is : 0.0632387\n",
      "6394-th loss is : 0.105343\n",
      "6395-th loss is : 0.00654179\n",
      "6396-th loss is : 0.000160285\n",
      "6397-th loss is : 0.044799\n",
      "6398-th loss is : 0.0571653\n",
      "6399-th loss is : 0.0091667\n",
      "6400-th loss is : 0.00443839\n",
      "6401-th loss is : 0.138125\n",
      "6402-th loss is : 0.132575\n",
      "6403-th loss is : 0.0830458\n",
      "6404-th loss is : 0.0803684\n",
      "6405-th loss is : 0.112546\n",
      "6406-th loss is : 0.115973\n",
      "6407-th loss is : 0.067736\n",
      "6408-th loss is : 0.0098994\n",
      "6409-th loss is : 0.0559217\n",
      "6410-th loss is : 0.0578039\n",
      "6411-th loss is : 0.0502658\n",
      "6412-th loss is : 0.0845511\n",
      "6413-th loss is : 0.0680404\n",
      "6414-th loss is : 0.0477791\n",
      "6415-th loss is : 0.017375\n",
      "6416-th loss is : 0.0336526\n",
      "6417-th loss is : 0.103407\n",
      "6418-th loss is : 0.16836\n",
      "6419-th loss is : 0.123126\n",
      "6420-th loss is : 0.0711339\n",
      "6421-th loss is : 0.00662408\n",
      "6422-th loss is : 0.149342\n",
      "6423-th loss is : 0.195175\n",
      "6424-th loss is : 1.13628e-05\n",
      "6425-th loss is : 0.000330002\n",
      "6426-th loss is : 0.0605258\n",
      "6427-th loss is : 0.0843164\n",
      "6428-th loss is : 0.0113076\n",
      "6429-th loss is : 0.0907818\n",
      "6430-th loss is : 0.182742\n",
      "6431-th loss is : 0.193493\n",
      "6432-th loss is : 0.118842\n",
      "6433-th loss is : 0.13043\n",
      "6434-th loss is : 0.0441172\n",
      "6435-th loss is : 0.0535484\n",
      "6436-th loss is : 0.0338356\n",
      "6437-th loss is : 0.000114451\n",
      "6438-th loss is : 0.076695\n",
      "6439-th loss is : 0.0323865\n",
      "6440-th loss is : 0.0390811\n",
      "6441-th loss is : 0.028317\n",
      "6442-th loss is : 0.00364864\n",
      "6443-th loss is : 0.0118716\n",
      "6444-th loss is : 0.1828\n",
      "6445-th loss is : 0.141022\n",
      "6446-th loss is : 0.181184\n",
      "6447-th loss is : 0.0185253\n",
      "6448-th loss is : 0.01507\n",
      "6449-th loss is : 0.104902\n",
      "6450-th loss is : 2.45425e-05\n",
      "6451-th loss is : 0.114416\n",
      "6452-th loss is : 0.0173769\n",
      "6453-th loss is : 0.0171286\n",
      "6454-th loss is : 0.0300258\n",
      "6455-th loss is : 0.00481581\n",
      "6456-th loss is : 0.115327\n",
      "6457-th loss is : 0.101062\n",
      "6458-th loss is : 0.189292\n",
      "6459-th loss is : 0.122922\n",
      "6460-th loss is : 7.83116e-05\n",
      "6461-th loss is : 0.139886\n",
      "6462-th loss is : 0.198441\n",
      "6463-th loss is : 0.0177065\n",
      "6464-th loss is : 0.127161\n",
      "6465-th loss is : 0.0407897\n",
      "6466-th loss is : 0.164496\n",
      "6467-th loss is : 0.14887\n",
      "6468-th loss is : 0.0702867\n",
      "6469-th loss is : 3.25138e-06\n",
      "6470-th loss is : 0.00246765\n",
      "6471-th loss is : 0.0155319\n",
      "6472-th loss is : 0.0277739\n",
      "6473-th loss is : 0.100921\n",
      "6474-th loss is : 0.0260803\n",
      "6475-th loss is : 3.31009e-05\n",
      "6476-th loss is : 0.0498496\n",
      "6477-th loss is : 0.012709\n",
      "6478-th loss is : 0.117164\n",
      "6479-th loss is : 0.0201644\n",
      "6480-th loss is : 0.187776\n",
      "6481-th loss is : 0.0123701\n",
      "6482-th loss is : 0.018509\n",
      "6483-th loss is : 0.000694911\n",
      "6484-th loss is : 0.02447\n",
      "6485-th loss is : 0.0149786\n",
      "6486-th loss is : 0.0090812\n",
      "6487-th loss is : 0.110588\n",
      "6488-th loss is : 0.0719137\n",
      "6489-th loss is : 2.55598e-07\n",
      "6490-th loss is : 0.0195414\n",
      "6491-th loss is : 0.17233\n",
      "6492-th loss is : 0.0379461\n",
      "6493-th loss is : 0.0793436\n",
      "6494-th loss is : 0.167079\n",
      "6495-th loss is : 0.0511764\n",
      "6496-th loss is : 0.162504\n",
      "6497-th loss is : 0.0182732\n",
      "6498-th loss is : 0.0143554\n",
      "6499-th loss is : 0.135797\n",
      "6500-th loss is : 0.00336658\n",
      "6501-th loss is : 0.00314458\n",
      "6502-th loss is : 0.0962675\n",
      "6503-th loss is : 0.141857\n",
      "6504-th loss is : 0.0140069\n",
      "6505-th loss is : 0.00118716\n",
      "6506-th loss is : 0.119319\n",
      "6507-th loss is : 0.044112\n",
      "6508-th loss is : 0.111974\n",
      "6509-th loss is : 4.85251e-07\n",
      "6510-th loss is : 0.21527\n",
      "6511-th loss is : 0.000362321\n",
      "6512-th loss is : 0.00266562\n",
      "6513-th loss is : 0.0378864\n",
      "6514-th loss is : 0.000874423\n",
      "6515-th loss is : 0.0928261\n",
      "6516-th loss is : 0.0135132\n",
      "6517-th loss is : 0.0103476\n",
      "6518-th loss is : 0.0405735\n",
      "6519-th loss is : 0.0120523\n",
      "6520-th loss is : 0.0793787\n",
      "6521-th loss is : 0.105163\n",
      "6522-th loss is : 0.0575023\n",
      "6523-th loss is : 0.000307408\n",
      "6524-th loss is : 0.134202\n",
      "6525-th loss is : 0.118002\n",
      "6526-th loss is : 0.0483675\n",
      "6527-th loss is : 0.0535011\n",
      "6528-th loss is : 0.0943796\n",
      "6529-th loss is : 0.139773\n",
      "6530-th loss is : 0.157925\n",
      "6531-th loss is : 0.0333629\n",
      "6532-th loss is : 0.171945\n",
      "6533-th loss is : 0.000203043\n",
      "6534-th loss is : 0.0123165\n",
      "6535-th loss is : 0.000493946\n",
      "6536-th loss is : 0.0264045\n",
      "6537-th loss is : 0.00865354\n",
      "6538-th loss is : 0.048322\n",
      "6539-th loss is : 0.00691168\n",
      "6540-th loss is : 0.188568\n",
      "6541-th loss is : 0.0416941\n",
      "6542-th loss is : 0.114254\n",
      "6543-th loss is : 0.20126\n",
      "6544-th loss is : 0.199894\n",
      "6545-th loss is : 0.0751553\n",
      "6546-th loss is : 0.0369964\n",
      "6547-th loss is : 0.019748\n",
      "6548-th loss is : 0.170754\n",
      "6549-th loss is : 0.066112\n",
      "6550-th loss is : 0.20724\n",
      "6551-th loss is : 6.13696e-06\n",
      "6552-th loss is : 0.0217642\n",
      "6553-th loss is : 0.106716\n",
      "6554-th loss is : 0.18834\n",
      "6555-th loss is : 0.00578261\n",
      "6556-th loss is : 0.108356\n",
      "6557-th loss is : 0.00236305\n",
      "6558-th loss is : 0.0492882\n",
      "6559-th loss is : 0.180547\n",
      "6560-th loss is : 0.00144365\n",
      "6561-th loss is : 0.0468354\n",
      "6562-th loss is : 0.000610876\n",
      "6563-th loss is : 0.013151\n",
      "6564-th loss is : 0.00191664\n",
      "6565-th loss is : 0.0646105\n",
      "6566-th loss is : 0.0255263\n",
      "6567-th loss is : 0.140023\n",
      "6568-th loss is : 0.0326778\n",
      "6569-th loss is : 0.131344\n",
      "6570-th loss is : 0.0157481\n",
      "6571-th loss is : 0.00721473\n",
      "6572-th loss is : 0.0139696\n",
      "6573-th loss is : 0.201635\n",
      "6574-th loss is : 0.0296353\n",
      "6575-th loss is : 0.10703\n",
      "6576-th loss is : 0.107658\n",
      "6577-th loss is : 0.0108451\n",
      "6578-th loss is : 0.06965\n",
      "6579-th loss is : 0.130431\n",
      "6580-th loss is : 0.0122804\n",
      "6581-th loss is : 0.155768\n",
      "6582-th loss is : 0.0445445\n",
      "6583-th loss is : 0.00326368\n",
      "6584-th loss is : 0.101893\n",
      "6585-th loss is : 0.0993598\n",
      "6586-th loss is : 0.0591245\n",
      "6587-th loss is : 0.0179438\n",
      "6588-th loss is : 0.0695976\n",
      "6589-th loss is : 0.000273573\n",
      "6590-th loss is : 0.0125546\n",
      "6591-th loss is : 0.0109821\n",
      "6592-th loss is : 0.00116499\n",
      "6593-th loss is : 0.004421\n",
      "6594-th loss is : 0.054688\n",
      "6595-th loss is : 0.0492164\n",
      "6596-th loss is : 0.147355\n",
      "6597-th loss is : 0.0455583\n",
      "6598-th loss is : 0.0995767\n",
      "6599-th loss is : 0.0476314\n",
      "6600-th loss is : 0.0905759\n",
      "6601-th loss is : 0.00657026\n",
      "6602-th loss is : 0.0891387\n",
      "6603-th loss is : 0.0257638\n",
      "6604-th loss is : 0.120237\n",
      "6605-th loss is : 0.125973\n",
      "6606-th loss is : 0.00114902\n",
      "6607-th loss is : 0.0590126\n",
      "6608-th loss is : 5.81458e-05\n",
      "6609-th loss is : 0.00101751\n",
      "6610-th loss is : 0.137658\n",
      "6611-th loss is : 0.0450459\n",
      "6612-th loss is : 0.006882\n",
      "6613-th loss is : 0.000117373\n",
      "6614-th loss is : 1.69356e-05\n",
      "6615-th loss is : 0.147685\n",
      "6616-th loss is : 0.154424\n",
      "6617-th loss is : 0.000175242\n",
      "6618-th loss is : 0.00221281\n",
      "6619-th loss is : 0.195308\n",
      "6620-th loss is : 0.0161547\n",
      "6621-th loss is : 0.177258\n",
      "6622-th loss is : 0.0313521\n",
      "6623-th loss is : 0.009664\n",
      "6624-th loss is : 0.155116\n",
      "6625-th loss is : 0.000651491\n",
      "6626-th loss is : 0.065751\n",
      "6627-th loss is : 0.0166573\n",
      "6628-th loss is : 0.080326\n",
      "6629-th loss is : 0.018817\n",
      "6630-th loss is : 0.0575862\n",
      "6631-th loss is : 0.161594\n",
      "6632-th loss is : 0.0348229\n",
      "6633-th loss is : 0.091505\n",
      "6634-th loss is : 0.030497\n",
      "6635-th loss is : 0.014589\n",
      "6636-th loss is : 0.0139106\n",
      "6637-th loss is : 0.148844\n",
      "6638-th loss is : 0.0338926\n",
      "6639-th loss is : 0.0472637\n",
      "6640-th loss is : 0.00016274\n",
      "6641-th loss is : 0.0169075\n",
      "6642-th loss is : 0.000311481\n",
      "6643-th loss is : 0.0749533\n",
      "6644-th loss is : 0.103246\n",
      "6645-th loss is : 0.17796\n",
      "6646-th loss is : 0.140592\n",
      "6647-th loss is : 0.14311\n",
      "6648-th loss is : 0.0339205\n",
      "6649-th loss is : 0.0237611\n",
      "6650-th loss is : 0.14702\n",
      "6651-th loss is : 0.145179\n",
      "6652-th loss is : 0.0024528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6653-th loss is : 0.0887804\n",
      "6654-th loss is : 0.136832\n",
      "6655-th loss is : 0.0238283\n",
      "6656-th loss is : 0.135291\n",
      "6657-th loss is : 0.0945181\n",
      "6658-th loss is : 0.103697\n",
      "6659-th loss is : 0.0618526\n",
      "6660-th loss is : 0.0460561\n",
      "6661-th loss is : 0.192727\n",
      "6662-th loss is : 0.162709\n",
      "6663-th loss is : 0.0155478\n",
      "6664-th loss is : 0.0824558\n",
      "6665-th loss is : 0.186783\n",
      "6666-th loss is : 0.205312\n",
      "6667-th loss is : 0.00960345\n",
      "6668-th loss is : 0.0480378\n",
      "6669-th loss is : 0.0823034\n",
      "6670-th loss is : 0.0267084\n",
      "6671-th loss is : 0.0593953\n",
      "6672-th loss is : 0.0672907\n",
      "6673-th loss is : 0.00518154\n",
      "6674-th loss is : 0.133516\n",
      "6675-th loss is : 0.00268519\n",
      "6676-th loss is : 0.177744\n",
      "6677-th loss is : 0.0721486\n",
      "6678-th loss is : 0.0205711\n",
      "6679-th loss is : 0.0419147\n",
      "6680-th loss is : 0.000417203\n",
      "6681-th loss is : 0.0288303\n",
      "6682-th loss is : 0.0475097\n",
      "6683-th loss is : 0.00700769\n",
      "6684-th loss is : 0.15242\n",
      "6685-th loss is : 0.146663\n",
      "6686-th loss is : 0.000365403\n",
      "6687-th loss is : 0.000488533\n",
      "6688-th loss is : 0.137714\n",
      "6689-th loss is : 0.0735474\n",
      "6690-th loss is : 0.0301162\n",
      "6691-th loss is : 0.0948897\n",
      "6692-th loss is : 0.140507\n",
      "6693-th loss is : 0.0142989\n",
      "6694-th loss is : 0.000401414\n",
      "6695-th loss is : 0.000256035\n",
      "6696-th loss is : 0.188896\n",
      "6697-th loss is : 0.00975634\n",
      "6698-th loss is : 0.14003\n",
      "6699-th loss is : 0.128974\n",
      "6700-th loss is : 0.0752229\n",
      "6701-th loss is : 0.00390446\n",
      "6702-th loss is : 0.00162767\n",
      "6703-th loss is : 0.043192\n",
      "6704-th loss is : 0.116676\n",
      "6705-th loss is : 0.0522174\n",
      "6706-th loss is : 0.0051705\n",
      "6707-th loss is : 0.0724749\n",
      "6708-th loss is : 0.010738\n",
      "6709-th loss is : 0.00202861\n",
      "6710-th loss is : 0.0594836\n",
      "6711-th loss is : 0.000751712\n",
      "6712-th loss is : 0.125916\n",
      "6713-th loss is : 2.41525e-05\n",
      "6714-th loss is : 0.00777961\n",
      "6715-th loss is : 0.00242052\n",
      "6716-th loss is : 0.0583697\n",
      "6717-th loss is : 0.0571318\n",
      "6718-th loss is : 0.141583\n",
      "6719-th loss is : 0.0837837\n",
      "6720-th loss is : 0.0858612\n",
      "6721-th loss is : 0.190978\n",
      "6722-th loss is : 6.3268e-05\n",
      "6723-th loss is : 0.154742\n",
      "6724-th loss is : 0.00108341\n",
      "6725-th loss is : 0.0285346\n",
      "6726-th loss is : 0.000717986\n",
      "6727-th loss is : 0.00271921\n",
      "6728-th loss is : 1.86308e-08\n",
      "6729-th loss is : 0.14798\n",
      "6730-th loss is : 0.000984154\n",
      "6731-th loss is : 0.0249102\n",
      "6732-th loss is : 0.0379707\n",
      "6733-th loss is : 0.107253\n",
      "6734-th loss is : 0.000967731\n",
      "6735-th loss is : 0.0177676\n",
      "6736-th loss is : 0.00456452\n",
      "6737-th loss is : 0.0721357\n",
      "6738-th loss is : 0.0286342\n",
      "6739-th loss is : 0.00200253\n",
      "6740-th loss is : 6.77465e-06\n",
      "6741-th loss is : 0.0025335\n",
      "6742-th loss is : 0.00689786\n",
      "6743-th loss is : 0.0227883\n",
      "6744-th loss is : 0.0818986\n",
      "6745-th loss is : 0.0203691\n",
      "6746-th loss is : 0.0349684\n",
      "6747-th loss is : 0.154767\n",
      "6748-th loss is : 0.031275\n",
      "6749-th loss is : 0.102923\n",
      "6750-th loss is : 0.0587165\n",
      "6751-th loss is : 0.189586\n",
      "6752-th loss is : 0.00512105\n",
      "6753-th loss is : 0.166735\n",
      "6754-th loss is : 0.00109869\n",
      "6755-th loss is : 0.0218594\n",
      "6756-th loss is : 0.0576719\n",
      "6757-th loss is : 0.150809\n",
      "6758-th loss is : 0.0256738\n",
      "6759-th loss is : 0.185602\n",
      "6760-th loss is : 0.19455\n",
      "6761-th loss is : 0.0309959\n",
      "6762-th loss is : 0.010431\n",
      "6763-th loss is : 0.00552002\n",
      "6764-th loss is : 0.00600616\n",
      "6765-th loss is : 0.157997\n",
      "6766-th loss is : 0.0505829\n",
      "6767-th loss is : 0.0199417\n",
      "6768-th loss is : 0.0656786\n",
      "6769-th loss is : 0.0729836\n",
      "6770-th loss is : 0.101097\n",
      "6771-th loss is : 0.184309\n",
      "6772-th loss is : 0.0834457\n",
      "6773-th loss is : 0.0714765\n",
      "6774-th loss is : 0.134379\n",
      "6775-th loss is : 0.0291214\n",
      "6776-th loss is : 0.031616\n",
      "6777-th loss is : 0.0826053\n",
      "6778-th loss is : 0.000104154\n",
      "6779-th loss is : 0.00299631\n",
      "6780-th loss is : 0.00614855\n",
      "6781-th loss is : 0.0217562\n",
      "6782-th loss is : 0.0245138\n",
      "6783-th loss is : 0.00206439\n",
      "6784-th loss is : 0.0648255\n",
      "6785-th loss is : 0.00148045\n",
      "6786-th loss is : 0.129523\n",
      "6787-th loss is : 0.00682095\n",
      "6788-th loss is : 0.0847948\n",
      "6789-th loss is : 0.0569973\n",
      "6790-th loss is : 0.0943806\n",
      "6791-th loss is : 0.03621\n",
      "6792-th loss is : 0.0240883\n",
      "6793-th loss is : 0.167796\n",
      "6794-th loss is : 0.130133\n",
      "6795-th loss is : 0.000480563\n",
      "6796-th loss is : 0.0197655\n",
      "6797-th loss is : 0.014924\n",
      "6798-th loss is : 0.0320399\n",
      "6799-th loss is : 0.00735478\n",
      "6800-th loss is : 0.0113477\n",
      "6801-th loss is : 0.153211\n",
      "6802-th loss is : 0.0105342\n",
      "6803-th loss is : 0.00466041\n",
      "6804-th loss is : 0.126232\n",
      "6805-th loss is : 0.0859264\n",
      "6806-th loss is : 0.161569\n",
      "6807-th loss is : 0.029905\n",
      "6808-th loss is : 0.157446\n",
      "6809-th loss is : 0.106541\n",
      "6810-th loss is : 0.0145797\n",
      "6811-th loss is : 0.000183473\n",
      "6812-th loss is : 0.00183694\n",
      "6813-th loss is : 0.124741\n",
      "6814-th loss is : 0.0593015\n",
      "6815-th loss is : 0.153665\n",
      "6816-th loss is : 0.0218509\n",
      "6817-th loss is : 0.0230807\n",
      "6818-th loss is : 0.0052657\n",
      "6819-th loss is : 0.0748135\n",
      "6820-th loss is : 0.0621791\n",
      "6821-th loss is : 0.00538193\n",
      "6822-th loss is : 0.0111034\n",
      "6823-th loss is : 0.0355388\n",
      "6824-th loss is : 0.0273593\n",
      "6825-th loss is : 0.154073\n",
      "6826-th loss is : 0.000853309\n",
      "6827-th loss is : 0.121867\n",
      "6828-th loss is : 0.0122888\n",
      "6829-th loss is : 0.0902462\n",
      "6830-th loss is : 0.0406843\n",
      "6831-th loss is : 0.0241179\n",
      "6832-th loss is : 0.014743\n",
      "6833-th loss is : 0.085168\n",
      "6834-th loss is : 0.0803386\n",
      "6835-th loss is : 0.173869\n",
      "6836-th loss is : 0.0264445\n",
      "6837-th loss is : 0.0225907\n",
      "6838-th loss is : 0.141735\n",
      "6839-th loss is : 0.157831\n",
      "6840-th loss is : 0.0910092\n",
      "6841-th loss is : 0.195472\n",
      "6842-th loss is : 0.00395383\n",
      "6843-th loss is : 0.133712\n",
      "6844-th loss is : 0.00626381\n",
      "6845-th loss is : 0.146794\n",
      "6846-th loss is : 0.015292\n",
      "6847-th loss is : 0.0135074\n",
      "6848-th loss is : 0.159414\n",
      "6849-th loss is : 0.0773149\n",
      "6850-th loss is : 0.00636907\n",
      "6851-th loss is : 0.00960191\n",
      "6852-th loss is : 0.170447\n",
      "6853-th loss is : 0.00831222\n",
      "6854-th loss is : 0.103887\n",
      "6855-th loss is : 0.120708\n",
      "6856-th loss is : 0.155047\n",
      "6857-th loss is : 0.0467227\n",
      "6858-th loss is : 0.00435286\n",
      "6859-th loss is : 0.140776\n",
      "6860-th loss is : 0.0919891\n",
      "6861-th loss is : 0.144534\n",
      "6862-th loss is : 0.0721034\n",
      "6863-th loss is : 0.113338\n",
      "6864-th loss is : 0.185853\n",
      "6865-th loss is : 0.000702888\n",
      "6866-th loss is : 0.0423024\n",
      "6867-th loss is : 0.00398245\n",
      "6868-th loss is : 0.0830948\n",
      "6869-th loss is : 0.0657067\n",
      "6870-th loss is : 0.0281043\n",
      "6871-th loss is : 0.108066\n",
      "6872-th loss is : 0.190805\n",
      "6873-th loss is : 0.0968696\n",
      "6874-th loss is : 0.0441451\n",
      "6875-th loss is : 0.0249026\n",
      "6876-th loss is : 0.00429271\n",
      "6877-th loss is : 0.0062311\n",
      "6878-th loss is : 0.0485601\n",
      "6879-th loss is : 0.15929\n",
      "6880-th loss is : 0.0931959\n",
      "6881-th loss is : 0.0920414\n",
      "6882-th loss is : 0.00522455\n",
      "6883-th loss is : 0.00102908\n",
      "6884-th loss is : 0.00157603\n",
      "6885-th loss is : 0.0204737\n",
      "6886-th loss is : 0.0186637\n",
      "6887-th loss is : 0.0104527\n",
      "6888-th loss is : 8.73936e-05\n",
      "6889-th loss is : 0.0705361\n",
      "6890-th loss is : 0.161829\n",
      "6891-th loss is : 0.129457\n",
      "6892-th loss is : 1.00069e-06\n",
      "6893-th loss is : 0.0516717\n",
      "6894-th loss is : 0.12897\n",
      "6895-th loss is : 0.0582485\n",
      "6896-th loss is : 0.176401\n",
      "6897-th loss is : 0.052221\n",
      "6898-th loss is : 0.125964\n",
      "6899-th loss is : 0.0459349\n",
      "6900-th loss is : 0.0299809\n",
      "6901-th loss is : 0.0331682\n",
      "6902-th loss is : 0.171418\n",
      "6903-th loss is : 0.0500197\n",
      "6904-th loss is : 0.0123097\n",
      "6905-th loss is : 0.117401\n",
      "6906-th loss is : 0.00134536\n",
      "6907-th loss is : 0.0235907\n",
      "6908-th loss is : 0.0135227\n",
      "6909-th loss is : 0.0720636\n",
      "6910-th loss is : 0.120316\n",
      "6911-th loss is : 0.0434552\n",
      "6912-th loss is : 0.050624\n",
      "6913-th loss is : 0.050353\n",
      "6914-th loss is : 0.059956\n",
      "6915-th loss is : 0.0534555\n",
      "6916-th loss is : 0.00801332\n",
      "6917-th loss is : 0.0308621\n",
      "6918-th loss is : 0.00861186\n",
      "6919-th loss is : 0.000499321\n",
      "6920-th loss is : 0.172959\n",
      "6921-th loss is : 0.00298195\n",
      "6922-th loss is : 0.000665944\n",
      "6923-th loss is : 0.129437\n",
      "6924-th loss is : 0.0744663\n",
      "6925-th loss is : 0.150801\n",
      "6926-th loss is : 0.0406593\n",
      "6927-th loss is : 0.0692641\n",
      "6928-th loss is : 0.0569511\n",
      "6929-th loss is : 0.00581581\n",
      "6930-th loss is : 0.0545515\n",
      "6931-th loss is : 0.00505003\n",
      "6932-th loss is : 0.00249715\n",
      "6933-th loss is : 0.0907161\n",
      "6934-th loss is : 9.86167e-06\n",
      "6935-th loss is : 0.14969\n",
      "6936-th loss is : 0.147988\n",
      "6937-th loss is : 0.00246722\n",
      "6938-th loss is : 0.00993565\n",
      "6939-th loss is : 0.0211822\n",
      "6940-th loss is : 0.0249295\n",
      "6941-th loss is : 0.00191514\n",
      "6942-th loss is : 0.0642277\n",
      "6943-th loss is : 0.171309\n",
      "6944-th loss is : 0.00318423\n",
      "6945-th loss is : 7.07674e-06\n",
      "6946-th loss is : 0.154387\n",
      "6947-th loss is : 0.0164411\n",
      "6948-th loss is : 0.0319737\n",
      "6949-th loss is : 0.0029162\n",
      "6950-th loss is : 0.132523\n",
      "6951-th loss is : 0.0646677\n",
      "6952-th loss is : 0.0948056\n",
      "6953-th loss is : 0.0987437\n",
      "6954-th loss is : 0.000353867\n",
      "6955-th loss is : 0.00585319\n",
      "6956-th loss is : 0.131056\n",
      "6957-th loss is : 0.164462\n",
      "6958-th loss is : 0.0761315\n",
      "6959-th loss is : 0.0411986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960-th loss is : 0.0707626\n",
      "6961-th loss is : 0.0821629\n",
      "6962-th loss is : 0.0162906\n",
      "6963-th loss is : 0.0112503\n",
      "6964-th loss is : 0.182301\n",
      "6965-th loss is : 0.00804271\n",
      "6966-th loss is : 0.0225701\n",
      "6967-th loss is : 0.0229684\n",
      "6968-th loss is : 0.000172151\n",
      "6969-th loss is : 0.0126779\n",
      "6970-th loss is : 0.000226501\n",
      "6971-th loss is : 0.043469\n",
      "6972-th loss is : 0.151938\n",
      "6973-th loss is : 0.000669329\n",
      "6974-th loss is : 0.0463766\n",
      "6975-th loss is : 0.153392\n",
      "6976-th loss is : 0.0067567\n",
      "6977-th loss is : 0.135121\n",
      "6978-th loss is : 0.152208\n",
      "6979-th loss is : 0.0154577\n",
      "6980-th loss is : 0.150973\n",
      "6981-th loss is : 0.041767\n",
      "6982-th loss is : 0.00125256\n",
      "6983-th loss is : 0.0953429\n",
      "6984-th loss is : 0.0207486\n",
      "6985-th loss is : 0.123871\n",
      "6986-th loss is : 0.0766313\n",
      "6987-th loss is : 8.78294e-06\n",
      "6988-th loss is : 0.0156867\n",
      "6989-th loss is : 0.000483379\n",
      "6990-th loss is : 0.0720782\n",
      "6991-th loss is : 0.174241\n",
      "6992-th loss is : 0.103924\n",
      "6993-th loss is : 0.0966843\n",
      "6994-th loss is : 0.040766\n",
      "6995-th loss is : 0.000389406\n",
      "6996-th loss is : 0.0157935\n",
      "6997-th loss is : 0.0281469\n",
      "6998-th loss is : 0.102917\n",
      "6999-th loss is : 0.0213342\n",
      "7000-th loss is : 0.0328552\n",
      "7001-th loss is : 0.000711692\n",
      "7002-th loss is : 0.0456691\n",
      "7003-th loss is : 7.71328e-06\n",
      "7004-th loss is : 0.0118235\n",
      "7005-th loss is : 0.000123998\n",
      "7006-th loss is : 0.0242025\n",
      "7007-th loss is : 0.00063429\n",
      "7008-th loss is : 0.00745853\n",
      "7009-th loss is : 0.0194535\n",
      "7010-th loss is : 0.043383\n",
      "7011-th loss is : 0.148147\n",
      "7012-th loss is : 0.114858\n",
      "7013-th loss is : 0.0734132\n",
      "7014-th loss is : 0.000415809\n",
      "7015-th loss is : 0.044475\n",
      "7016-th loss is : 0.118484\n",
      "7017-th loss is : 0.0238922\n",
      "7018-th loss is : 0.159251\n",
      "7019-th loss is : 0.0133764\n",
      "7020-th loss is : 0.0105628\n",
      "7021-th loss is : 0.140369\n",
      "7022-th loss is : 0.143318\n",
      "7023-th loss is : 0.065475\n",
      "7024-th loss is : 0.0917711\n",
      "7025-th loss is : 7.69342e-06\n",
      "7026-th loss is : 0.0493288\n",
      "7027-th loss is : 0.148687\n",
      "7028-th loss is : 0.126841\n",
      "7029-th loss is : 0.0163885\n",
      "7030-th loss is : 0.0346593\n",
      "7031-th loss is : 0.0184428\n",
      "7032-th loss is : 0.039241\n",
      "7033-th loss is : 0.125809\n",
      "7034-th loss is : 0.026544\n",
      "7035-th loss is : 0.00997364\n",
      "7036-th loss is : 0.069191\n",
      "7037-th loss is : 0.00340854\n",
      "7038-th loss is : 0.072252\n",
      "7039-th loss is : 0.146059\n",
      "7040-th loss is : 0.0598614\n",
      "7041-th loss is : 0.0313007\n",
      "7042-th loss is : 0.147147\n",
      "7043-th loss is : 0.0936253\n",
      "7044-th loss is : 0.0262489\n",
      "7045-th loss is : 0.100346\n",
      "7046-th loss is : 0.159503\n",
      "7047-th loss is : 0.012178\n",
      "7048-th loss is : 0.141361\n",
      "7049-th loss is : 0.000135408\n",
      "7050-th loss is : 0.126036\n",
      "7051-th loss is : 0.00111163\n",
      "7052-th loss is : 0.000501865\n",
      "7053-th loss is : 0.0343637\n",
      "7054-th loss is : 0.0053797\n",
      "7055-th loss is : 5.77537e-06\n",
      "7056-th loss is : 0.0479729\n",
      "7057-th loss is : 0.0275113\n",
      "7058-th loss is : 1.13033e-06\n",
      "7059-th loss is : 0.0160414\n",
      "7060-th loss is : 0.00301121\n",
      "7061-th loss is : 0.0865231\n",
      "7062-th loss is : 0.181167\n",
      "7063-th loss is : 0.179425\n",
      "7064-th loss is : 0.000466717\n",
      "7065-th loss is : 0.0386392\n",
      "7066-th loss is : 0.00216479\n",
      "7067-th loss is : 0.127194\n",
      "7068-th loss is : 0.0275602\n",
      "7069-th loss is : 0.00132514\n",
      "7070-th loss is : 0.0446002\n",
      "7071-th loss is : 0.149368\n",
      "7072-th loss is : 0.113777\n",
      "7073-th loss is : 0.0160845\n",
      "7074-th loss is : 0.03013\n",
      "7075-th loss is : 0.00420536\n",
      "7076-th loss is : 0.120856\n",
      "7077-th loss is : 0.0715323\n",
      "7078-th loss is : 6.32102e-05\n",
      "7079-th loss is : 0.00585008\n",
      "7080-th loss is : 0.0491965\n",
      "7081-th loss is : 0.000947123\n",
      "7082-th loss is : 0.0554546\n",
      "7083-th loss is : 0.149515\n",
      "7084-th loss is : 0.0253826\n",
      "7085-th loss is : 0.174143\n",
      "7086-th loss is : 0.156939\n",
      "7087-th loss is : 0.143289\n",
      "7088-th loss is : 0.00413361\n",
      "7089-th loss is : 0.119767\n",
      "7090-th loss is : 0.000313913\n",
      "7091-th loss is : 3.33022e-05\n",
      "7092-th loss is : 0.00164926\n",
      "7093-th loss is : 0.000317992\n",
      "7094-th loss is : 0.10965\n",
      "7095-th loss is : 0.0476059\n",
      "7096-th loss is : 0.0368527\n",
      "7097-th loss is : 0.0100659\n",
      "7098-th loss is : 0.129369\n",
      "7099-th loss is : 0.0406404\n",
      "7100-th loss is : 0.0181421\n",
      "7101-th loss is : 0.0996651\n",
      "7102-th loss is : 0.00524902\n",
      "7103-th loss is : 0.000449488\n",
      "7104-th loss is : 0.0179043\n",
      "7105-th loss is : 0.00177569\n",
      "7106-th loss is : 0.0221016\n",
      "7107-th loss is : 0.0379881\n",
      "7108-th loss is : 0.00778295\n",
      "7109-th loss is : 0.000543376\n",
      "7110-th loss is : 0.138622\n",
      "7111-th loss is : 0.0877011\n",
      "7112-th loss is : 0.120735\n",
      "7113-th loss is : 0.00752047\n",
      "7114-th loss is : 0.0203841\n",
      "7115-th loss is : 0.0916016\n",
      "7116-th loss is : 0.163675\n",
      "7117-th loss is : 0.00041741\n",
      "7118-th loss is : 0.0402082\n",
      "7119-th loss is : 0.000340947\n",
      "7120-th loss is : 0.103871\n",
      "7121-th loss is : 0.171831\n",
      "7122-th loss is : 0.0893511\n",
      "7123-th loss is : 6.74394e-05\n",
      "7124-th loss is : 0.0212583\n",
      "7125-th loss is : 0.0807817\n",
      "7126-th loss is : 0.129007\n",
      "7127-th loss is : 0.0974592\n",
      "7128-th loss is : 0.118696\n",
      "7129-th loss is : 0.165426\n",
      "7130-th loss is : 0.00510775\n",
      "7131-th loss is : 0.00259219\n",
      "7132-th loss is : 0.00146989\n",
      "7133-th loss is : 0.000111934\n",
      "7134-th loss is : 0.142294\n",
      "7135-th loss is : 0.106806\n",
      "7136-th loss is : 0.172813\n",
      "7137-th loss is : 4.89975e-06\n",
      "7138-th loss is : 0.0413401\n",
      "7139-th loss is : 0.115611\n",
      "7140-th loss is : 0.000174997\n",
      "7141-th loss is : 0.0152581\n",
      "7142-th loss is : 0.000134797\n",
      "7143-th loss is : 0.00121143\n",
      "7144-th loss is : 0.0838174\n",
      "7145-th loss is : 0.158718\n",
      "7146-th loss is : 0.00695674\n",
      "7147-th loss is : 0.0128261\n",
      "7148-th loss is : 0.0750221\n",
      "7149-th loss is : 0.0433177\n",
      "7150-th loss is : 0.00260187\n",
      "7151-th loss is : 0.000318884\n",
      "7152-th loss is : 0.13437\n",
      "7153-th loss is : 0.171275\n",
      "7154-th loss is : 0.105102\n",
      "7155-th loss is : 0.000234319\n",
      "7156-th loss is : 0.169783\n",
      "7157-th loss is : 0.00334554\n",
      "7158-th loss is : 0.0838356\n",
      "7159-th loss is : 0.0108456\n",
      "7160-th loss is : 0.061203\n",
      "7161-th loss is : 0.0906812\n",
      "7162-th loss is : 1.9132e-06\n",
      "7163-th loss is : 0.000131524\n",
      "7164-th loss is : 0.167119\n",
      "7165-th loss is : 0.0443258\n",
      "7166-th loss is : 0.000149707\n",
      "7167-th loss is : 0.00092301\n",
      "7168-th loss is : 0.00728365\n",
      "7169-th loss is : 0.045052\n",
      "7170-th loss is : 0.019039\n",
      "7171-th loss is : 0.0404258\n",
      "7172-th loss is : 0.0239531\n",
      "7173-th loss is : 0.0334058\n",
      "7174-th loss is : 0.0560097\n",
      "7175-th loss is : 0.172999\n",
      "7176-th loss is : 0.0262121\n",
      "7177-th loss is : 0.020717\n",
      "7178-th loss is : 0.104035\n",
      "7179-th loss is : 0.00191235\n",
      "7180-th loss is : 0.0854968\n",
      "7181-th loss is : 0.0602569\n",
      "7182-th loss is : 0.0646861\n",
      "7183-th loss is : 0.0646352\n",
      "7184-th loss is : 0.00877566\n",
      "7185-th loss is : 0.0723532\n",
      "7186-th loss is : 8.57376e-05\n",
      "7187-th loss is : 0.0783381\n",
      "7188-th loss is : 0.104608\n",
      "7189-th loss is : 0.0189955\n",
      "7190-th loss is : 0.0806918\n",
      "7191-th loss is : 0.00067691\n",
      "7192-th loss is : 0.0741024\n",
      "7193-th loss is : 0.0108097\n",
      "7194-th loss is : 0.0378269\n",
      "7195-th loss is : 0.123343\n",
      "7196-th loss is : 0.104969\n",
      "7197-th loss is : 0.0246294\n",
      "7198-th loss is : 0.000475637\n",
      "7199-th loss is : 0.163096\n",
      "7200-th loss is : 0.156335\n",
      "7201-th loss is : 0.0872646\n",
      "7202-th loss is : 4.75477e-05\n",
      "7203-th loss is : 0.159674\n",
      "7204-th loss is : 0.103776\n",
      "7205-th loss is : 0.169818\n",
      "7206-th loss is : 0.00318788\n",
      "7207-th loss is : 0.0676883\n",
      "7208-th loss is : 0.0137849\n",
      "7209-th loss is : 0.0951931\n",
      "7210-th loss is : 0.0651975\n",
      "7211-th loss is : 2.72807e-05\n",
      "7212-th loss is : 0.00086328\n",
      "7213-th loss is : 0.00220796\n",
      "7214-th loss is : 0.15908\n",
      "7215-th loss is : 0.000140852\n",
      "7216-th loss is : 0.158598\n",
      "7217-th loss is : 0.0151025\n",
      "7218-th loss is : 0.0294241\n",
      "7219-th loss is : 0.16556\n",
      "7220-th loss is : 0.0760834\n",
      "7221-th loss is : 0.00476797\n",
      "7222-th loss is : 0.013787\n",
      "7223-th loss is : 0.0660756\n",
      "7224-th loss is : 0.0840358\n",
      "7225-th loss is : 8.43492e-05\n",
      "7226-th loss is : 0.0462321\n",
      "7227-th loss is : 0.00132214\n",
      "7228-th loss is : 0.0819318\n",
      "7229-th loss is : 0.00473941\n",
      "7230-th loss is : 0.047878\n",
      "7231-th loss is : 0.0196205\n",
      "7232-th loss is : 0.0109845\n",
      "7233-th loss is : 0.0972494\n",
      "7234-th loss is : 0.127878\n",
      "7235-th loss is : 0.0681861\n",
      "7236-th loss is : 6.59421e-05\n",
      "7237-th loss is : 0.0430346\n",
      "7238-th loss is : 0.0539387\n",
      "7239-th loss is : 0.0121038\n",
      "7240-th loss is : 2.77817e-06\n",
      "7241-th loss is : 0.14095\n",
      "7242-th loss is : 0.0594918\n",
      "7243-th loss is : 0.0910822\n",
      "7244-th loss is : 0.0756504\n",
      "7245-th loss is : 0.05483\n",
      "7246-th loss is : 0.104204\n",
      "7247-th loss is : 0.0800269\n",
      "7248-th loss is : 0.164704\n",
      "7249-th loss is : 0.042616\n",
      "7250-th loss is : 0.0469464\n",
      "7251-th loss is : 0.151613\n",
      "7252-th loss is : 4.60464e-05\n",
      "7253-th loss is : 0.000738381\n",
      "7254-th loss is : 0.00285235\n",
      "7255-th loss is : 0.0654086\n",
      "7256-th loss is : 0.00899138\n",
      "7257-th loss is : 0.000134863\n",
      "7258-th loss is : 0.000699147\n",
      "7259-th loss is : 5.5576e-05\n",
      "7260-th loss is : 0.0168581\n",
      "7261-th loss is : 0.103838\n",
      "7262-th loss is : 0.151691\n",
      "7263-th loss is : 0.113033\n",
      "7264-th loss is : 0.128618\n",
      "7265-th loss is : 0.0102254\n",
      "7266-th loss is : 0.163271\n",
      "7267-th loss is : 0.0433035\n",
      "7268-th loss is : 0.16428\n",
      "7269-th loss is : 0.000774479\n",
      "7270-th loss is : 0.0641301\n",
      "7271-th loss is : 0.0258251\n",
      "7272-th loss is : 0.168693\n",
      "7273-th loss is : 0.137119\n",
      "7274-th loss is : 0.00247397\n",
      "7275-th loss is : 0.0587755\n",
      "7276-th loss is : 0.00363656\n",
      "7277-th loss is : 0.0342465\n",
      "7278-th loss is : 0.166933\n",
      "7279-th loss is : 0.000192\n",
      "7280-th loss is : 0.166283\n",
      "7281-th loss is : 0.0391352\n",
      "7282-th loss is : 0.0210657\n",
      "7283-th loss is : 0.0357672\n",
      "7284-th loss is : 0.0660467\n",
      "7285-th loss is : 0.116562\n",
      "7286-th loss is : 0.0408645\n",
      "7287-th loss is : 0.101276\n",
      "7288-th loss is : 0.0507611\n",
      "7289-th loss is : 0.000114406\n",
      "7290-th loss is : 0.00131891\n",
      "7291-th loss is : 0.0194156\n",
      "7292-th loss is : 0.000118529\n",
      "7293-th loss is : 0.00316081\n",
      "7294-th loss is : 0.00830433\n",
      "7295-th loss is : 0.161666\n",
      "7296-th loss is : 0.00010728\n",
      "7297-th loss is : 0.0318486\n",
      "7298-th loss is : 0.0648455\n",
      "7299-th loss is : 0.0423313\n",
      "7300-th loss is : 0.126137\n",
      "7301-th loss is : 0.071419\n",
      "7302-th loss is : 0.0671246\n",
      "7303-th loss is : 0.0676033\n",
      "7304-th loss is : 0.0328108\n",
      "7305-th loss is : 3.27077e-05\n",
      "7306-th loss is : 0.125169\n",
      "7307-th loss is : 0.0501007\n",
      "7308-th loss is : 0.0800613\n",
      "7309-th loss is : 0.0303859\n",
      "7310-th loss is : 0.0687847\n",
      "7311-th loss is : 0.0259043\n",
      "7312-th loss is : 0.0292491\n",
      "7313-th loss is : 0.00833182\n",
      "7314-th loss is : 0.0986954\n",
      "7315-th loss is : 0.0762479\n",
      "7316-th loss is : 0.0227673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7317-th loss is : 0.00488498\n",
      "7318-th loss is : 0.050612\n",
      "7319-th loss is : 0.0125019\n",
      "7320-th loss is : 0.111656\n",
      "7321-th loss is : 0.000122018\n",
      "7322-th loss is : 0.163166\n",
      "7323-th loss is : 0.0698479\n",
      "7324-th loss is : 0.0338813\n",
      "7325-th loss is : 1.09599e-06\n",
      "7326-th loss is : 0.151088\n",
      "7327-th loss is : 0.0727241\n",
      "7328-th loss is : 0.136994\n",
      "7329-th loss is : 0.00014451\n",
      "7330-th loss is : 0.0573702\n",
      "7331-th loss is : 8.79561e-05\n",
      "7332-th loss is : 0.0808577\n",
      "7333-th loss is : 0.0197653\n",
      "7334-th loss is : 0.0408477\n",
      "7335-th loss is : 0.00267831\n",
      "7336-th loss is : 0.0125304\n",
      "7337-th loss is : 0.0664095\n",
      "7338-th loss is : 7.13738e-05\n",
      "7339-th loss is : 0.11664\n",
      "7340-th loss is : 0.0143865\n",
      "7341-th loss is : 0.137859\n",
      "7342-th loss is : 0.0399828\n",
      "7343-th loss is : 0.052931\n",
      "7344-th loss is : 0.0177542\n",
      "7345-th loss is : 0.038911\n",
      "7346-th loss is : 0.123699\n",
      "7347-th loss is : 0.0659442\n",
      "7348-th loss is : 0.0948627\n",
      "7349-th loss is : 0.0923551\n",
      "7350-th loss is : 0.0148354\n",
      "7351-th loss is : 0.12086\n",
      "7352-th loss is : 0.153151\n",
      "7353-th loss is : 0.00518112\n",
      "7354-th loss is : 0.000880716\n",
      "7355-th loss is : 5.15452e-05\n",
      "7356-th loss is : 0.118115\n",
      "7357-th loss is : 0.0524352\n",
      "7358-th loss is : 0.000624662\n",
      "7359-th loss is : 0.0823816\n",
      "7360-th loss is : 0.000300734\n",
      "7361-th loss is : 0.0293878\n",
      "7362-th loss is : 0.0098357\n",
      "7363-th loss is : 0.0403616\n",
      "7364-th loss is : 0.00110384\n",
      "7365-th loss is : 0.0323397\n",
      "7366-th loss is : 0.0681131\n",
      "7367-th loss is : 0.133668\n",
      "7368-th loss is : 0.0759099\n",
      "7369-th loss is : 0.0239221\n",
      "7370-th loss is : 0.0985696\n",
      "7371-th loss is : 0.00720629\n",
      "7372-th loss is : 0.000136719\n",
      "7373-th loss is : 0.0464275\n",
      "7374-th loss is : 0.123373\n",
      "7375-th loss is : 0.00203043\n",
      "7376-th loss is : 0.00102684\n",
      "7377-th loss is : 0.0371759\n",
      "7378-th loss is : 0.146171\n",
      "7379-th loss is : 0.0142655\n",
      "7380-th loss is : 0.133924\n",
      "7381-th loss is : 1.3513e-05\n",
      "7382-th loss is : 0.0440912\n",
      "7383-th loss is : 0.015007\n",
      "7384-th loss is : 0.101556\n",
      "7385-th loss is : 0.0521736\n",
      "7386-th loss is : 0.0106236\n",
      "7387-th loss is : 0.0739823\n",
      "7388-th loss is : 0.152512\n",
      "7389-th loss is : 0.0360167\n",
      "7390-th loss is : 0.0261369\n",
      "7391-th loss is : 0.00763425\n",
      "7392-th loss is : 0.0027072\n",
      "7393-th loss is : 0.00102353\n",
      "7394-th loss is : 0.00365758\n",
      "7395-th loss is : 0.00160625\n",
      "7396-th loss is : 2.4913e-07\n",
      "7397-th loss is : 0.149636\n",
      "7398-th loss is : 0.130556\n",
      "7399-th loss is : 0.111404\n",
      "7400-th loss is : 0.146626\n",
      "7401-th loss is : 0.126029\n",
      "7402-th loss is : 0.0351341\n",
      "7403-th loss is : 0.133428\n",
      "7404-th loss is : 0.0442804\n",
      "7405-th loss is : 0.00869637\n",
      "7406-th loss is : 0.00359373\n",
      "7407-th loss is : 0.0573926\n",
      "7408-th loss is : 0.000212146\n",
      "7409-th loss is : 0.000794549\n",
      "7410-th loss is : 0.0502796\n",
      "7411-th loss is : 0.0647429\n",
      "7412-th loss is : 0.0205966\n",
      "7413-th loss is : 0.0225221\n",
      "7414-th loss is : 0.00785415\n",
      "7415-th loss is : 0.0641688\n",
      "7416-th loss is : 0.0185542\n",
      "7417-th loss is : 0.136798\n",
      "7418-th loss is : 0.159665\n",
      "7419-th loss is : 0.134584\n",
      "7420-th loss is : 0.0688875\n",
      "7421-th loss is : 2.3793e-05\n",
      "7422-th loss is : 0.0325546\n",
      "7423-th loss is : 0.000204527\n",
      "7424-th loss is : 0.0507855\n",
      "7425-th loss is : 0.00780299\n",
      "7426-th loss is : 0.128299\n",
      "7427-th loss is : 0.0160114\n",
      "7428-th loss is : 0.0712113\n",
      "7429-th loss is : 8.35638e-05\n",
      "7430-th loss is : 0.0227942\n",
      "7431-th loss is : 0.0743891\n",
      "7432-th loss is : 0.00243765\n",
      "7433-th loss is : 0.0295978\n",
      "7434-th loss is : 3.18476e-07\n",
      "7435-th loss is : 0.0148185\n",
      "7436-th loss is : 0.00027166\n",
      "7437-th loss is : 0.095512\n",
      "7438-th loss is : 0.0141164\n",
      "7439-th loss is : 0.000504705\n",
      "7440-th loss is : 0.160294\n",
      "7441-th loss is : 0.0824349\n",
      "7442-th loss is : 0.0309317\n",
      "7443-th loss is : 0.00132622\n",
      "7444-th loss is : 0.000197575\n",
      "7445-th loss is : 0.00099202\n",
      "7446-th loss is : 0.0281353\n",
      "7447-th loss is : 0.0404\n",
      "7448-th loss is : 0.0694738\n",
      "7449-th loss is : 0.15763\n",
      "7450-th loss is : 0.0696907\n",
      "7451-th loss is : 0.14746\n",
      "7452-th loss is : 0.00480213\n",
      "7453-th loss is : 0.147706\n",
      "7454-th loss is : 0.0563801\n",
      "7455-th loss is : 0.000632214\n",
      "7456-th loss is : 0.0237185\n",
      "7457-th loss is : 0.0472929\n",
      "7458-th loss is : 0.0181684\n",
      "7459-th loss is : 0.157795\n",
      "7460-th loss is : 0.0644043\n",
      "7461-th loss is : 0.00654246\n",
      "7462-th loss is : 0.0555708\n",
      "7463-th loss is : 0.00234183\n",
      "7464-th loss is : 0.154142\n",
      "7465-th loss is : 0.0339426\n",
      "7466-th loss is : 0.0571735\n",
      "7467-th loss is : 0.127517\n",
      "7468-th loss is : 0.0861214\n",
      "7469-th loss is : 0.0593715\n",
      "7470-th loss is : 0.0367055\n",
      "7471-th loss is : 0.0281387\n",
      "7472-th loss is : 5.79596e-05\n",
      "7473-th loss is : 0.0426026\n",
      "7474-th loss is : 0.1516\n",
      "7475-th loss is : 0.0283107\n",
      "7476-th loss is : 0.13029\n",
      "7477-th loss is : 0.0144247\n",
      "7478-th loss is : 0.0078664\n",
      "7479-th loss is : 0.0438314\n",
      "7480-th loss is : 0.00068303\n",
      "7481-th loss is : 0.137181\n",
      "7482-th loss is : 0.0352665\n",
      "7483-th loss is : 0.0126803\n",
      "7484-th loss is : 0.000724816\n",
      "7485-th loss is : 0.0168239\n",
      "7486-th loss is : 1.215e-06\n",
      "7487-th loss is : 0.035006\n",
      "7488-th loss is : 0.000790197\n",
      "7489-th loss is : 0.0155951\n",
      "7490-th loss is : 0.0859873\n",
      "7491-th loss is : 0.0428282\n",
      "7492-th loss is : 0.0163927\n",
      "7493-th loss is : 0.000197252\n",
      "7494-th loss is : 0.0059491\n",
      "7495-th loss is : 0.0877038\n",
      "7496-th loss is : 0.0974488\n",
      "7497-th loss is : 0.104218\n",
      "7498-th loss is : 0.0876191\n",
      "7499-th loss is : 0.15499\n",
      "7500-th loss is : 0.0352907\n",
      "7501-th loss is : 0.0177815\n",
      "7502-th loss is : 0.100106\n",
      "7503-th loss is : 0.056357\n",
      "7504-th loss is : 0.00185698\n",
      "7505-th loss is : 0.0153986\n",
      "7506-th loss is : 0.101024\n",
      "7507-th loss is : 0.0921412\n",
      "7508-th loss is : 0.0405163\n",
      "7509-th loss is : 0.111218\n",
      "7510-th loss is : 0.0146111\n",
      "7511-th loss is : 0.0232906\n",
      "7512-th loss is : 0.0597504\n",
      "7513-th loss is : 0.150123\n",
      "7514-th loss is : 0.00026244\n",
      "7515-th loss is : 0.010654\n",
      "7516-th loss is : 0.124872\n",
      "7517-th loss is : 0.0374477\n",
      "7518-th loss is : 0.00670349\n",
      "7519-th loss is : 0.0363775\n",
      "7520-th loss is : 0.154292\n",
      "7521-th loss is : 0.0228863\n",
      "7522-th loss is : 0.00157268\n",
      "7523-th loss is : 0.0345105\n",
      "7524-th loss is : 0.0352123\n",
      "7525-th loss is : 0.00565295\n",
      "7526-th loss is : 0.002112\n",
      "7527-th loss is : 0.00962088\n",
      "7528-th loss is : 0.144564\n",
      "7529-th loss is : 0.117703\n",
      "7530-th loss is : 0.0872984\n",
      "7531-th loss is : 0.0220905\n",
      "7532-th loss is : 0.0634555\n",
      "7533-th loss is : 0.0395567\n",
      "7534-th loss is : 0.00390998\n",
      "7535-th loss is : 0.153278\n",
      "7536-th loss is : 0.0765328\n",
      "7537-th loss is : 0.0146548\n",
      "7538-th loss is : 0.0298881\n",
      "7539-th loss is : 0.00597458\n",
      "7540-th loss is : 0.000105463\n",
      "7541-th loss is : 0.152814\n",
      "7542-th loss is : 0.111146\n",
      "7543-th loss is : 0.0018254\n",
      "7544-th loss is : 0.016553\n",
      "7545-th loss is : 0.0372609\n",
      "7546-th loss is : 0.00252525\n",
      "7547-th loss is : 0.0341391\n",
      "7548-th loss is : 0.0574911\n",
      "7549-th loss is : 0.00678547\n",
      "7550-th loss is : 0.0388595\n",
      "7551-th loss is : 0.147295\n",
      "7552-th loss is : 0.120323\n",
      "7553-th loss is : 0.0257859\n",
      "7554-th loss is : 0.000746524\n",
      "7555-th loss is : 0.0082027\n",
      "7556-th loss is : 0.0690474\n",
      "7557-th loss is : 0.0103696\n",
      "7558-th loss is : 0.0307495\n",
      "7559-th loss is : 0.026849\n",
      "7560-th loss is : 4.55543e-05\n",
      "7561-th loss is : 0.00035308\n",
      "7562-th loss is : 0.0200685\n",
      "7563-th loss is : 0.000313768\n",
      "7564-th loss is : 0.0109556\n",
      "7565-th loss is : 0.0876903\n",
      "7566-th loss is : 0.143048\n",
      "7567-th loss is : 0.0136715\n",
      "7568-th loss is : 0.00143941\n",
      "7569-th loss is : 0.0127229\n",
      "7570-th loss is : 0.00938704\n",
      "7571-th loss is : 0.119318\n",
      "7572-th loss is : 0.00757966\n",
      "7573-th loss is : 0.106604\n",
      "7574-th loss is : 0.088539\n",
      "7575-th loss is : 0.00605418\n",
      "7576-th loss is : 0.00038747\n",
      "7577-th loss is : 0.0997022\n",
      "7578-th loss is : 0.133141\n",
      "7579-th loss is : 0.0709855\n",
      "7580-th loss is : 0.140942\n",
      "7581-th loss is : 9.55317e-05\n",
      "7582-th loss is : 5.54534e-05\n",
      "7583-th loss is : 0.0580846\n",
      "7584-th loss is : 0.00724445\n",
      "7585-th loss is : 4.81637e-05\n",
      "7586-th loss is : 0.0116278\n",
      "7587-th loss is : 0.0679977\n",
      "7588-th loss is : 0.0690277\n",
      "7589-th loss is : 0.00925203\n",
      "7590-th loss is : 0.0017514\n",
      "7591-th loss is : 0.0612349\n",
      "7592-th loss is : 0.116486\n",
      "7593-th loss is : 0.0857335\n",
      "7594-th loss is : 0.12029\n",
      "7595-th loss is : 4.93915e-06\n",
      "7596-th loss is : 0.114867\n",
      "7597-th loss is : 0.0114317\n",
      "7598-th loss is : 0.0340425\n",
      "7599-th loss is : 0.00852443\n",
      "7600-th loss is : 0.0583567\n",
      "7601-th loss is : 6.90505e-05\n",
      "7602-th loss is : 0.00633723\n",
      "7603-th loss is : 0.00270996\n",
      "7604-th loss is : 8.47888e-05\n",
      "7605-th loss is : 0.0768828\n",
      "7606-th loss is : 0.0196972\n",
      "7607-th loss is : 0.0273699\n",
      "7608-th loss is : 0.0767149\n",
      "7609-th loss is : 0.00348339\n",
      "7610-th loss is : 0.11223\n",
      "7611-th loss is : 0.0119402\n",
      "7612-th loss is : 0.00145916\n",
      "7613-th loss is : 0.0101313\n",
      "7614-th loss is : 0.0748435\n",
      "7615-th loss is : 0.00277092\n",
      "7616-th loss is : 0.024869\n",
      "7617-th loss is : 5.78744e-05\n",
      "7618-th loss is : 0.0230636\n",
      "7619-th loss is : 0.0134663\n",
      "7620-th loss is : 0.111562\n",
      "7621-th loss is : 0.0119144\n",
      "7622-th loss is : 0.0365708\n",
      "7623-th loss is : 0.100498\n",
      "7624-th loss is : 0.13017\n",
      "7625-th loss is : 0.00111396\n",
      "7626-th loss is : 0.0618996\n",
      "7627-th loss is : 0.0186317\n",
      "7628-th loss is : 0.000246604\n",
      "7629-th loss is : 0.00129325\n",
      "7630-th loss is : 0.0562326\n",
      "7631-th loss is : 0.00157289\n",
      "7632-th loss is : 0.00465395\n",
      "7633-th loss is : 0.0642514\n",
      "7634-th loss is : 0.0538645\n",
      "7635-th loss is : 0.00101637\n",
      "7636-th loss is : 0.0281663\n",
      "7637-th loss is : 0.0121693\n",
      "7638-th loss is : 0.00218669\n",
      "7639-th loss is : 0.0263825\n",
      "7640-th loss is : 0.00274865\n",
      "7641-th loss is : 0.014058\n",
      "7642-th loss is : 0.0676942\n",
      "7643-th loss is : 0.0920246\n",
      "7644-th loss is : 0.139434\n",
      "7645-th loss is : 0.0747915\n",
      "7646-th loss is : 0.000178255\n",
      "7647-th loss is : 0.0538561\n",
      "7648-th loss is : 0.0807207\n",
      "7649-th loss is : 0.0101077\n",
      "7650-th loss is : 0.150263\n",
      "7651-th loss is : 0.000221074\n",
      "7652-th loss is : 0.0559479\n",
      "7653-th loss is : 0.0334384\n",
      "7654-th loss is : 0.0136147\n",
      "7655-th loss is : 0.00828002\n",
      "7656-th loss is : 0.00176954\n",
      "7657-th loss is : 0.0734227\n",
      "7658-th loss is : 3.22735e-06\n",
      "7659-th loss is : 0.0189055\n",
      "7660-th loss is : 0.055263\n",
      "7661-th loss is : 0.077302\n",
      "7662-th loss is : 0.0149351\n",
      "7663-th loss is : 0.108482\n",
      "7664-th loss is : 0.0272157\n",
      "7665-th loss is : 0.0173583\n",
      "7666-th loss is : 0.0072923\n",
      "7667-th loss is : 0.0233974\n",
      "7668-th loss is : 7.01504e-06\n",
      "7669-th loss is : 0.0839994\n",
      "7670-th loss is : 0.0296451\n",
      "7671-th loss is : 7.10341e-06\n",
      "7672-th loss is : 0.055285\n",
      "7673-th loss is : 0.128479\n",
      "7674-th loss is : 0.0539121\n",
      "7675-th loss is : 0.000894959\n",
      "7676-th loss is : 0.00448321\n",
      "7677-th loss is : 0.0491297\n",
      "7678-th loss is : 0.0225813\n",
      "7679-th loss is : 0.0591903\n",
      "7680-th loss is : 0.0355451\n",
      "7681-th loss is : 0.0112622\n",
      "7682-th loss is : 1.15278e-05\n",
      "7683-th loss is : 0.111232\n",
      "7684-th loss is : 0.0494924\n",
      "7685-th loss is : 0.000467516\n",
      "7686-th loss is : 0.00738394\n",
      "7687-th loss is : 0.000737299\n",
      "7688-th loss is : 0.00601634\n",
      "7689-th loss is : 0.0200957\n",
      "7690-th loss is : 0.0610912\n",
      "7691-th loss is : 0.0588199\n",
      "7692-th loss is : 0.126267\n",
      "7693-th loss is : 0.0563316\n",
      "7694-th loss is : 0.0170725\n",
      "7695-th loss is : 0.000373991\n",
      "7696-th loss is : 0.0691119\n",
      "7697-th loss is : 0.126877\n",
      "7698-th loss is : 0.00426433\n",
      "7699-th loss is : 0.00270417\n",
      "7700-th loss is : 0.00420751\n",
      "7701-th loss is : 0.00302934\n",
      "7702-th loss is : 0.00218157\n",
      "7703-th loss is : 0.0111479\n",
      "7704-th loss is : 0.000777172\n",
      "7705-th loss is : 0.10555\n",
      "7706-th loss is : 0.0229593\n",
      "7707-th loss is : 0.133131\n",
      "7708-th loss is : 0.00180586\n",
      "7709-th loss is : 0.0434601\n",
      "7710-th loss is : 0.0857254\n",
      "7711-th loss is : 0.046912\n",
      "7712-th loss is : 0.0570456\n",
      "7713-th loss is : 0.0325021\n",
      "7714-th loss is : 0.125995\n",
      "7715-th loss is : 0.0959428\n",
      "7716-th loss is : 0.0119908\n",
      "7717-th loss is : 0.11041\n",
      "7718-th loss is : 0.0384704\n",
      "7719-th loss is : 0.143371\n",
      "7720-th loss is : 0.000234801\n",
      "7721-th loss is : 0.0290467\n",
      "7722-th loss is : 0.0069798\n",
      "7723-th loss is : 0.0575272\n",
      "7724-th loss is : 0.000597272\n",
      "7725-th loss is : 0.0466594\n",
      "7726-th loss is : 0.132197\n",
      "7727-th loss is : 0.0711257\n",
      "7728-th loss is : 0.00791172\n",
      "7729-th loss is : 0.00399151\n",
      "7730-th loss is : 0.00888216\n",
      "7731-th loss is : 0.00171924\n",
      "7732-th loss is : 0.0352037\n",
      "7733-th loss is : 0.0577313\n",
      "7734-th loss is : 0.00348918\n",
      "7735-th loss is : 0.127712\n",
      "7736-th loss is : 0.0220728\n",
      "7737-th loss is : 0.0307887\n",
      "7738-th loss is : 0.115797\n",
      "7739-th loss is : 0.00733634\n",
      "7740-th loss is : 0.0827302\n",
      "7741-th loss is : 5.10977e-05\n",
      "7742-th loss is : 0.0049142\n",
      "7743-th loss is : 0.00753242\n",
      "7744-th loss is : 0.0138974\n",
      "7745-th loss is : 0.0996975\n",
      "7746-th loss is : 0.0977285\n",
      "7747-th loss is : 0.0415452\n",
      "7748-th loss is : 0.00128814\n",
      "7749-th loss is : 0.00463873\n",
      "7750-th loss is : 0.031854\n",
      "7751-th loss is : 0.000245327\n",
      "7752-th loss is : 0.0374239\n",
      "7753-th loss is : 0.00977686\n",
      "7754-th loss is : 0.00234038\n",
      "7755-th loss is : 0.0921895\n",
      "7756-th loss is : 0.08484\n",
      "7757-th loss is : 0.00360129\n",
      "7758-th loss is : 0.141252\n",
      "7759-th loss is : 0.08256\n",
      "7760-th loss is : 0.000519953\n",
      "7761-th loss is : 0.053288\n",
      "7762-th loss is : 1.11811e-05\n",
      "7763-th loss is : 0.0168137\n",
      "7764-th loss is : 0.00586372\n",
      "7765-th loss is : 5.84052e-05\n",
      "7766-th loss is : 0.0412141\n",
      "7767-th loss is : 0.0478219\n",
      "7768-th loss is : 0.125843\n",
      "7769-th loss is : 0.106386\n",
      "7770-th loss is : 0.0966568\n",
      "7771-th loss is : 0.047092\n",
      "7772-th loss is : 0.070594\n",
      "7773-th loss is : 0.00122411\n",
      "7774-th loss is : 0.116451\n",
      "7775-th loss is : 0.0491619\n",
      "7776-th loss is : 0.0335553\n",
      "7777-th loss is : 0.032426\n",
      "7778-th loss is : 0.0180937\n",
      "7779-th loss is : 0.00856555\n",
      "7780-th loss is : 0.0807788\n",
      "7781-th loss is : 0.00948095\n",
      "7782-th loss is : 0.00556612\n",
      "7783-th loss is : 0.0786327\n",
      "7784-th loss is : 0.0292326\n",
      "7785-th loss is : 0.0201917\n",
      "7786-th loss is : 0.0774895\n",
      "7787-th loss is : 0.091051\n",
      "7788-th loss is : 0.0479744\n",
      "7789-th loss is : 0.0350208\n",
      "7790-th loss is : 0.000642162\n",
      "7791-th loss is : 0.076832\n",
      "7792-th loss is : 0.100227\n",
      "7793-th loss is : 0.0015753\n",
      "7794-th loss is : 0.039194\n",
      "7795-th loss is : 0.078714\n",
      "7796-th loss is : 0.00182846\n",
      "7797-th loss is : 0.0421907\n",
      "7798-th loss is : 0.00107942\n",
      "7799-th loss is : 0.0221079\n",
      "7800-th loss is : 0.000166006\n",
      "7801-th loss is : 0.0218072\n",
      "7802-th loss is : 0.000808579\n",
      "7803-th loss is : 0.00206873\n",
      "7804-th loss is : 0.00740375\n",
      "7805-th loss is : 0.0354186\n",
      "7806-th loss is : 0.114896\n",
      "7807-th loss is : 0.0244678\n",
      "7808-th loss is : 0.000995417\n",
      "7809-th loss is : 0.079249\n",
      "7810-th loss is : 0.00636488\n",
      "7811-th loss is : 0.0302504\n",
      "7812-th loss is : 0.0525149\n",
      "7813-th loss is : 0.0522913\n",
      "7814-th loss is : 0.000588067\n",
      "7815-th loss is : 0.0521826\n",
      "7816-th loss is : 0.000107715\n",
      "7817-th loss is : 0.00022162\n",
      "7818-th loss is : 0.13553\n",
      "7819-th loss is : 0.0382911\n",
      "7820-th loss is : 0.035836\n",
      "7821-th loss is : 0.000666981\n",
      "7822-th loss is : 0.000753095\n",
      "7823-th loss is : 0.126207\n",
      "7824-th loss is : 0.0317823\n",
      "7825-th loss is : 0.0144722\n",
      "7826-th loss is : 0.0987068\n",
      "7827-th loss is : 0.0025591\n",
      "7828-th loss is : 0.013779\n",
      "7829-th loss is : 0.0193284\n",
      "7830-th loss is : 5.11506e-07\n",
      "7831-th loss is : 0.00675017\n",
      "7832-th loss is : 0.00288135\n",
      "7833-th loss is : 0.061743\n",
      "7834-th loss is : 0.0364326\n",
      "7835-th loss is : 0.0155477\n",
      "7836-th loss is : 0.013147\n",
      "7837-th loss is : 0.0034768\n",
      "7838-th loss is : 0.00603739\n",
      "7839-th loss is : 1.58797e-05\n",
      "7840-th loss is : 0.00412776\n",
      "7841-th loss is : 0.0700014\n",
      "7842-th loss is : 0.0175959\n",
      "7843-th loss is : 0.000145084\n",
      "7844-th loss is : 0.0189565\n",
      "7845-th loss is : 0.012523\n",
      "7846-th loss is : 5.54224e-09\n",
      "7847-th loss is : 0.13273\n",
      "7848-th loss is : 0.139026\n",
      "7849-th loss is : 0.113801\n",
      "7850-th loss is : 0.0942049\n",
      "7851-th loss is : 0.0938886\n",
      "7852-th loss is : 0.0770597\n",
      "7853-th loss is : 0.0143373\n",
      "7854-th loss is : 0.047675\n",
      "7855-th loss is : 0.0159928\n",
      "7856-th loss is : 0.116552\n",
      "7857-th loss is : 0.0587676\n",
      "7858-th loss is : 0.000504898\n",
      "7859-th loss is : 0.037148\n",
      "7860-th loss is : 0.0182577\n",
      "7861-th loss is : 0.029502\n",
      "7862-th loss is : 0.00171882\n",
      "7863-th loss is : 0.0936899\n",
      "7864-th loss is : 0.0303554\n",
      "7865-th loss is : 0.0363046\n",
      "7866-th loss is : 0.0310791\n",
      "7867-th loss is : 0.000224451\n",
      "7868-th loss is : 0.0281226\n",
      "7869-th loss is : 0.0936958\n",
      "7870-th loss is : 0.0132446\n",
      "7871-th loss is : 0.0605394\n",
      "7872-th loss is : 0.0286504\n",
      "7873-th loss is : 0.00373963\n",
      "7874-th loss is : 0.0143375\n",
      "7875-th loss is : 2.22006e-07\n",
      "7876-th loss is : 0.0212328\n",
      "7877-th loss is : 0.0431876\n",
      "7878-th loss is : 0.0378332\n",
      "7879-th loss is : 0.00758835\n",
      "7880-th loss is : 0.065696\n",
      "7881-th loss is : 0.0225061\n",
      "7882-th loss is : 0.0210579\n",
      "7883-th loss is : 0.0516446\n",
      "7884-th loss is : 0.00270055\n",
      "7885-th loss is : 0.0491506\n",
      "7886-th loss is : 0.0560094\n",
      "7887-th loss is : 0.0878579\n",
      "7888-th loss is : 0.00194717\n",
      "7889-th loss is : 0.000418312\n",
      "7890-th loss is : 0.00367663\n",
      "7891-th loss is : 0.00114552\n",
      "7892-th loss is : 0.0010385\n",
      "7893-th loss is : 0.00668147\n",
      "7894-th loss is : 0.0408034\n",
      "7895-th loss is : 0.0290555\n",
      "7896-th loss is : 0.00308284\n",
      "7897-th loss is : 0.126448\n",
      "7898-th loss is : 0.0258808\n",
      "7899-th loss is : 0.0992943\n",
      "7900-th loss is : 0.102174\n",
      "7901-th loss is : 0.0133157\n",
      "7902-th loss is : 0.108103\n",
      "7903-th loss is : 0.00657641\n",
      "7904-th loss is : 0.0316796\n",
      "7905-th loss is : 0.0218859\n",
      "7906-th loss is : 2.65382e-06\n",
      "7907-th loss is : 0.00194213\n",
      "7908-th loss is : 0.0889266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7909-th loss is : 0.0180387\n",
      "7910-th loss is : 0.0246519\n",
      "7911-th loss is : 0.0291783\n",
      "7912-th loss is : 0.0234809\n",
      "7913-th loss is : 0.00471768\n",
      "7914-th loss is : 0.100997\n",
      "7915-th loss is : 0.0593996\n",
      "7916-th loss is : 0.00360479\n",
      "7917-th loss is : 0.00338139\n",
      "7918-th loss is : 0.0870038\n",
      "7919-th loss is : 0.0266977\n",
      "7920-th loss is : 0.00911875\n",
      "7921-th loss is : 0.0135932\n",
      "7922-th loss is : 0.00086026\n",
      "7923-th loss is : 0.123395\n",
      "7924-th loss is : 0.116463\n",
      "7925-th loss is : 0.00806755\n",
      "7926-th loss is : 4.23036e-05\n",
      "7927-th loss is : 0.0869279\n",
      "7928-th loss is : 0.0880857\n",
      "7929-th loss is : 0.0687248\n",
      "7930-th loss is : 0.00521988\n",
      "7931-th loss is : 0.000302726\n",
      "7932-th loss is : 0.0019688\n",
      "7933-th loss is : 0.00120396\n",
      "7934-th loss is : 0.00031707\n",
      "7935-th loss is : 0.0676853\n",
      "7936-th loss is : 0.00317786\n",
      "7937-th loss is : 0.00288832\n",
      "7938-th loss is : 0.00345648\n",
      "7939-th loss is : 0.000262322\n",
      "7940-th loss is : 0.0121983\n",
      "7941-th loss is : 0.025964\n",
      "7942-th loss is : 0.0120681\n",
      "7943-th loss is : 0.0433731\n",
      "7944-th loss is : 0.0547081\n",
      "7945-th loss is : 0.105996\n",
      "7946-th loss is : 0.0267371\n",
      "7947-th loss is : 0.0460374\n",
      "7948-th loss is : 6.27833e-06\n",
      "7949-th loss is : 0.0120968\n",
      "7950-th loss is : 0.109453\n",
      "7951-th loss is : 0.00034181\n",
      "7952-th loss is : 0.0933164\n",
      "7953-th loss is : 0.134488\n",
      "7954-th loss is : 0.0124732\n",
      "7955-th loss is : 0.0322583\n",
      "7956-th loss is : 0.000498594\n",
      "7957-th loss is : 0.0463795\n",
      "7958-th loss is : 0.0106424\n",
      "7959-th loss is : 0.000735843\n",
      "7960-th loss is : 0.00201705\n",
      "7961-th loss is : 0.0478818\n",
      "7962-th loss is : 0.102144\n",
      "7963-th loss is : 0.0219776\n",
      "7964-th loss is : 0.00156499\n",
      "7965-th loss is : 0.018396\n",
      "7966-th loss is : 0.0338147\n",
      "7967-th loss is : 0.100406\n",
      "7968-th loss is : 0.0169782\n",
      "7969-th loss is : 0.00276839\n",
      "7970-th loss is : 0.0219875\n",
      "7971-th loss is : 0.000781648\n",
      "7972-th loss is : 0.0551822\n",
      "7973-th loss is : 0.0686367\n",
      "7974-th loss is : 0.00349414\n",
      "7975-th loss is : 0.00300618\n",
      "7976-th loss is : 0.00185774\n",
      "7977-th loss is : 0.093798\n",
      "7978-th loss is : 0.0512537\n",
      "7979-th loss is : 0.00104064\n",
      "7980-th loss is : 0.135176\n",
      "7981-th loss is : 0.0974818\n",
      "7982-th loss is : 5.36878e-07\n",
      "7983-th loss is : 0.105259\n",
      "7984-th loss is : 0.0124\n",
      "7985-th loss is : 0.0477787\n",
      "7986-th loss is : 0.087737\n",
      "7987-th loss is : 0.00453491\n",
      "7988-th loss is : 1.03755e-05\n",
      "7989-th loss is : 0.114875\n",
      "7990-th loss is : 0.119168\n",
      "7991-th loss is : 0.00192967\n",
      "7992-th loss is : 0.00937801\n",
      "7993-th loss is : 0.00584138\n",
      "7994-th loss is : 4.63081e-05\n",
      "7995-th loss is : 0.0928062\n",
      "7996-th loss is : 0.0659343\n",
      "7997-th loss is : 0.101634\n",
      "7998-th loss is : 0.011996\n",
      "7999-th loss is : 0.0622521\n",
      "8000-th loss is : 0.0197366\n",
      "8001-th loss is : 0.00236547\n",
      "8002-th loss is : 0.00133667\n",
      "8003-th loss is : 0.0279971\n",
      "8004-th loss is : 0.0180795\n",
      "8005-th loss is : 0.00441781\n",
      "8006-th loss is : 0.0753011\n",
      "8007-th loss is : 0.00298386\n",
      "8008-th loss is : 0.0905134\n",
      "8009-th loss is : 0.0213724\n",
      "8010-th loss is : 0.0943596\n",
      "8011-th loss is : 0.126596\n",
      "8012-th loss is : 0.00214275\n",
      "8013-th loss is : 0.123324\n",
      "8014-th loss is : 0.0857338\n",
      "8015-th loss is : 0.0226557\n",
      "8016-th loss is : 0.132715\n",
      "8017-th loss is : 0.0453955\n",
      "8018-th loss is : 0.111501\n",
      "8019-th loss is : 0.0280612\n",
      "8020-th loss is : 0.00164581\n",
      "8021-th loss is : 0.00203288\n",
      "8022-th loss is : 0.00392036\n",
      "8023-th loss is : 0.0443856\n",
      "8024-th loss is : 0.0304591\n",
      "8025-th loss is : 0.00226682\n",
      "8026-th loss is : 0.0316793\n",
      "8027-th loss is : 0.0209434\n",
      "8028-th loss is : 0.0233177\n",
      "8029-th loss is : 0.0284833\n",
      "8030-th loss is : 0.0407327\n",
      "8031-th loss is : 0.134332\n",
      "8032-th loss is : 0.0979058\n",
      "8033-th loss is : 0.0551533\n",
      "8034-th loss is : 0.0868059\n",
      "8035-th loss is : 0.00382583\n",
      "8036-th loss is : 0.000102113\n",
      "8037-th loss is : 0.00114668\n",
      "8038-th loss is : 0.00119134\n",
      "8039-th loss is : 0.00554453\n",
      "8040-th loss is : 0.0371534\n",
      "8041-th loss is : 0.0114214\n",
      "8042-th loss is : 0.0376873\n",
      "8043-th loss is : 0.0223256\n",
      "8044-th loss is : 0.0800532\n",
      "8045-th loss is : 0.00158632\n",
      "8046-th loss is : 0.0165741\n",
      "8047-th loss is : 0.017173\n",
      "8048-th loss is : 0.0127385\n",
      "8049-th loss is : 0.073412\n",
      "8050-th loss is : 0.00823244\n",
      "8051-th loss is : 0.00971104\n",
      "8052-th loss is : 0.0310599\n",
      "8053-th loss is : 0.0799302\n",
      "8054-th loss is : 0.117744\n",
      "8055-th loss is : 1.47124e-05\n",
      "8056-th loss is : 0.0456622\n",
      "8057-th loss is : 0.0735332\n",
      "8058-th loss is : 0.0545034\n",
      "8059-th loss is : 0.00989637\n",
      "8060-th loss is : 0.0411\n",
      "8061-th loss is : 0.106744\n",
      "8062-th loss is : 0.03344\n",
      "8063-th loss is : 0.102348\n",
      "8064-th loss is : 0.0276606\n",
      "8065-th loss is : 0.0451037\n",
      "8066-th loss is : 0.0037902\n",
      "8067-th loss is : 0.042401\n",
      "8068-th loss is : 0.0437182\n",
      "8069-th loss is : 0.00861744\n",
      "8070-th loss is : 0.103502\n",
      "8071-th loss is : 0.00764609\n",
      "8072-th loss is : 0.0797819\n",
      "8073-th loss is : 0.0450186\n",
      "8074-th loss is : 0.00224738\n",
      "8075-th loss is : 0.0436527\n",
      "8076-th loss is : 0.129592\n",
      "8077-th loss is : 0.0676045\n",
      "8078-th loss is : 2.998e-05\n",
      "8079-th loss is : 0.0110264\n",
      "8080-th loss is : 0.0277191\n",
      "8081-th loss is : 0.00147128\n",
      "8082-th loss is : 0.0572197\n",
      "8083-th loss is : 0.104606\n",
      "8084-th loss is : 0.118143\n",
      "8085-th loss is : 0.00276965\n",
      "8086-th loss is : 8.87641e-05\n",
      "8087-th loss is : 0.115382\n",
      "8088-th loss is : 0.00396225\n",
      "8089-th loss is : 0.006908\n",
      "8090-th loss is : 0.000223595\n",
      "8091-th loss is : 0.0848198\n",
      "8092-th loss is : 0.000957128\n",
      "8093-th loss is : 0.00333128\n",
      "8094-th loss is : 0.0689025\n",
      "8095-th loss is : 0.000129943\n",
      "8096-th loss is : 0.000111425\n",
      "8097-th loss is : 0.00640611\n",
      "8098-th loss is : 0.0488045\n",
      "8099-th loss is : 0.0216957\n",
      "8100-th loss is : 0.00016176\n",
      "8101-th loss is : 0.0362578\n",
      "8102-th loss is : 0.0988809\n",
      "8103-th loss is : 0.0650232\n",
      "8104-th loss is : 0.0435518\n",
      "8105-th loss is : 0.0261047\n",
      "8106-th loss is : 0.0693535\n",
      "8107-th loss is : 0.00377547\n",
      "8108-th loss is : 0.0157666\n",
      "8109-th loss is : 0.0576303\n",
      "8110-th loss is : 0.116923\n",
      "8111-th loss is : 0.112821\n",
      "8112-th loss is : 0.0310082\n",
      "8113-th loss is : 0.102917\n",
      "8114-th loss is : 0.00064692\n",
      "8115-th loss is : 0.0396177\n",
      "8116-th loss is : 0.00607126\n",
      "8117-th loss is : 9.42488e-06\n",
      "8118-th loss is : 0.0838334\n",
      "8119-th loss is : 0.0297685\n",
      "8120-th loss is : 0.0480865\n",
      "8121-th loss is : 0.0010706\n",
      "8122-th loss is : 0.129814\n",
      "8123-th loss is : 0.00303016\n",
      "8124-th loss is : 0.0560359\n",
      "8125-th loss is : 0.0502236\n",
      "8126-th loss is : 0.00174781\n",
      "8127-th loss is : 0.00255599\n",
      "8128-th loss is : 0.0519951\n",
      "8129-th loss is : 0.000604001\n",
      "8130-th loss is : 0.0812581\n",
      "8131-th loss is : 0.0542453\n",
      "8132-th loss is : 0.00201931\n",
      "8133-th loss is : 1.05196e-05\n",
      "8134-th loss is : 4.41381e-05\n",
      "8135-th loss is : 0.00969371\n",
      "8136-th loss is : 0.00177795\n",
      "8137-th loss is : 0.108497\n",
      "8138-th loss is : 3.05455e-06\n",
      "8139-th loss is : 0.0912243\n",
      "8140-th loss is : 0.0484546\n",
      "8141-th loss is : 0.10544\n",
      "8142-th loss is : 0.0609478\n",
      "8143-th loss is : 0.0149862\n",
      "8144-th loss is : 0.0164696\n",
      "8145-th loss is : 3.81726e-06\n",
      "8146-th loss is : 0.000605141\n",
      "8147-th loss is : 0.0701436\n",
      "8148-th loss is : 0.000111818\n",
      "8149-th loss is : 0.0860655\n",
      "8150-th loss is : 0.00827522\n",
      "8151-th loss is : 0.00491685\n",
      "8152-th loss is : 0.128925\n",
      "8153-th loss is : 4.87238e-05\n",
      "8154-th loss is : 0.0562484\n",
      "8155-th loss is : 0.00405861\n",
      "8156-th loss is : 0.087274\n",
      "8157-th loss is : 0.00336317\n",
      "8158-th loss is : 0.0859693\n",
      "8159-th loss is : 0.00316269\n",
      "8160-th loss is : 2.4671e-06\n",
      "8161-th loss is : 0.00318939\n",
      "8162-th loss is : 0.0120487\n",
      "8163-th loss is : 0.0554414\n",
      "8164-th loss is : 0.00282025\n",
      "8165-th loss is : 0.0730457\n",
      "8166-th loss is : 0.0172157\n",
      "8167-th loss is : 0.00996368\n",
      "8168-th loss is : 0.000130228\n",
      "8169-th loss is : 0.0037436\n",
      "8170-th loss is : 0.0936596\n",
      "8171-th loss is : 0.0453536\n",
      "8172-th loss is : 0.00254151\n",
      "8173-th loss is : 0.0379349\n",
      "8174-th loss is : 0.000662816\n",
      "8175-th loss is : 1.3456e-05\n",
      "8176-th loss is : 0.00216394\n",
      "8177-th loss is : 0.05419\n",
      "8178-th loss is : 0.0666854\n",
      "8179-th loss is : 0.0890081\n",
      "8180-th loss is : 0.00164137\n",
      "8181-th loss is : 0.0974393\n",
      "8182-th loss is : 0.0155747\n",
      "8183-th loss is : 0.000100347\n",
      "8184-th loss is : 0.00124671\n",
      "8185-th loss is : 0.0530175\n",
      "8186-th loss is : 0.0851308\n",
      "8187-th loss is : 0.0754278\n",
      "8188-th loss is : 0.0989011\n",
      "8189-th loss is : 1.11807e-06\n",
      "8190-th loss is : 0.00337548\n",
      "8191-th loss is : 0.00138767\n",
      "8192-th loss is : 0.0197097\n",
      "8193-th loss is : 0.00430879\n",
      "8194-th loss is : 0.00380982\n",
      "8195-th loss is : 0.0291393\n",
      "8196-th loss is : 0.0747439\n",
      "8197-th loss is : 0.0134893\n",
      "8198-th loss is : 0.00559699\n",
      "8199-th loss is : 0.0726797\n",
      "8200-th loss is : 0.0121798\n",
      "8201-th loss is : 0.000515415\n",
      "8202-th loss is : 3.20653e-05\n",
      "8203-th loss is : 0.000105111\n",
      "8204-th loss is : 0.0159019\n",
      "8205-th loss is : 0.114401\n",
      "8206-th loss is : 0.000425757\n",
      "8207-th loss is : 0.00465254\n",
      "8208-th loss is : 0.000825576\n",
      "8209-th loss is : 0.00130787\n",
      "8210-th loss is : 0.0695656\n",
      "8211-th loss is : 0.0468092\n",
      "8212-th loss is : 0.0642607\n",
      "8213-th loss is : 0.0138024\n",
      "8214-th loss is : 0.000111507\n",
      "8215-th loss is : 0.0974705\n",
      "8216-th loss is : 0.000937926\n",
      "8217-th loss is : 0.0059355\n",
      "8218-th loss is : 0.000356651\n",
      "8219-th loss is : 0.0162293\n",
      "8220-th loss is : 0.071556\n",
      "8221-th loss is : 0.0236901\n",
      "8222-th loss is : 0.0240404\n",
      "8223-th loss is : 0.0489187\n",
      "8224-th loss is : 0.0484218\n",
      "8225-th loss is : 0.00295446\n",
      "8226-th loss is : 0.0138134\n",
      "8227-th loss is : 0.00763794\n",
      "8228-th loss is : 6.11824e-05\n",
      "8229-th loss is : 0.0998812\n",
      "8230-th loss is : 0.0225504\n",
      "8231-th loss is : 7.10529e-05\n",
      "8232-th loss is : 0.100688\n",
      "8233-th loss is : 2.02551e-05\n",
      "8234-th loss is : 0.0746875\n",
      "8235-th loss is : 0.027258\n",
      "8236-th loss is : 0.0174064\n",
      "8237-th loss is : 0.0741752\n",
      "8238-th loss is : 0.00838319\n",
      "8239-th loss is : 0.00123658\n",
      "8240-th loss is : 0.00677046\n",
      "8241-th loss is : 0.00293541\n",
      "8242-th loss is : 0.00396658\n",
      "8243-th loss is : 0.00284803\n",
      "8244-th loss is : 0.102551\n",
      "8245-th loss is : 0.00131107\n",
      "8246-th loss is : 0.0883665\n",
      "8247-th loss is : 0.000374448\n",
      "8248-th loss is : 0.0293525\n",
      "8249-th loss is : 0.00188724\n",
      "8250-th loss is : 0.0709586\n",
      "8251-th loss is : 0.000165564\n",
      "8252-th loss is : 0.111312\n",
      "8253-th loss is : 0.019699\n",
      "8254-th loss is : 0.00736406\n",
      "8255-th loss is : 0.0495236\n",
      "8256-th loss is : 0.00281786\n",
      "8257-th loss is : 0.00135105\n",
      "8258-th loss is : 0.0152698\n",
      "8259-th loss is : 0.0117446\n",
      "8260-th loss is : 0.00128178\n",
      "8261-th loss is : 0.0144463\n",
      "8262-th loss is : 0.049174\n",
      "8263-th loss is : 0.00388499\n",
      "8264-th loss is : 0.0413604\n",
      "8265-th loss is : 0.00377716\n",
      "8266-th loss is : 0.110338\n",
      "8267-th loss is : 0.0563878\n",
      "8268-th loss is : 0.00133652\n",
      "8269-th loss is : 0.00205322\n",
      "8270-th loss is : 0.000101747\n",
      "8271-th loss is : 0.000431178\n",
      "8272-th loss is : 0.0398169\n",
      "8273-th loss is : 0.00373973\n",
      "8274-th loss is : 0.0370761\n",
      "8275-th loss is : 0.0472733\n",
      "8276-th loss is : 0.00222374\n",
      "8277-th loss is : 0.0692162\n",
      "8278-th loss is : 0.0724165\n",
      "8279-th loss is : 0.0434492\n",
      "8280-th loss is : 2.13771e-05\n",
      "8281-th loss is : 0.080401\n",
      "8282-th loss is : 0.0582462\n",
      "8283-th loss is : 0.00713932\n",
      "8284-th loss is : 0.0394956\n",
      "8285-th loss is : 0.000221429\n",
      "8286-th loss is : 5.65023e-05\n",
      "8287-th loss is : 0.0193133\n",
      "8288-th loss is : 0.0207009\n",
      "8289-th loss is : 0.00215063\n",
      "8290-th loss is : 0.045598\n",
      "8291-th loss is : 0.0481266\n",
      "8292-th loss is : 0.00174874\n",
      "8293-th loss is : 0.0053474\n",
      "8294-th loss is : 0.00768245\n",
      "8295-th loss is : 0.120107\n",
      "8296-th loss is : 0.0247859\n",
      "8297-th loss is : 0.124768\n",
      "8298-th loss is : 0.105266\n",
      "8299-th loss is : 0.0042176\n",
      "8300-th loss is : 0.00101664\n",
      "8301-th loss is : 1.51305e-06\n",
      "8302-th loss is : 0.00339649\n",
      "8303-th loss is : 0.0542854\n",
      "8304-th loss is : 4.20937e-05\n",
      "8305-th loss is : 0.0470261\n",
      "8306-th loss is : 0.0051132\n",
      "8307-th loss is : 0.0317563\n",
      "8308-th loss is : 0.0976335\n",
      "8309-th loss is : 0.00069905\n",
      "8310-th loss is : 0.0483468\n",
      "8311-th loss is : 0.0545986\n",
      "8312-th loss is : 0.123715\n",
      "8313-th loss is : 0.0118716\n",
      "8314-th loss is : 0.0856795\n",
      "8315-th loss is : 0.0327661\n",
      "8316-th loss is : 0.118899\n",
      "8317-th loss is : 0.0314303\n",
      "8318-th loss is : 0.00219353\n",
      "8319-th loss is : 0.108694\n",
      "8320-th loss is : 0.0178541\n",
      "8321-th loss is : 0.100932\n",
      "8322-th loss is : 0.037929\n",
      "8323-th loss is : 0.111327\n",
      "8324-th loss is : 9.95759e-05\n",
      "8325-th loss is : 0.065239\n",
      "8326-th loss is : 0.0219858\n",
      "8327-th loss is : 5.27218e-05\n",
      "8328-th loss is : 0.00270495\n",
      "8329-th loss is : 0.0017711\n",
      "8330-th loss is : 0.0836137\n",
      "8331-th loss is : 0.111285\n",
      "8332-th loss is : 0.0195685\n",
      "8333-th loss is : 0.0048884\n",
      "8334-th loss is : 0.00253601\n",
      "8335-th loss is : 2.95624e-05\n",
      "8336-th loss is : 0.0833756\n",
      "8337-th loss is : 0.00166757\n",
      "8338-th loss is : 0.00118249\n",
      "8339-th loss is : 0.063106\n",
      "8340-th loss is : 0.0994405\n",
      "8341-th loss is : 0.0320646\n",
      "8342-th loss is : 0.111464\n",
      "8343-th loss is : 0.0686715\n",
      "8344-th loss is : 0.0241591\n",
      "8345-th loss is : 0.00360403\n",
      "8346-th loss is : 0.0931017\n",
      "8347-th loss is : 0.00557086\n",
      "8348-th loss is : 0.0920937\n",
      "8349-th loss is : 0.0518926\n",
      "8350-th loss is : 0.105831\n",
      "8351-th loss is : 0.0676496\n",
      "8352-th loss is : 7.45866e-05\n",
      "8353-th loss is : 0.03336\n",
      "8354-th loss is : 0.00090346\n",
      "8355-th loss is : 0.00950715\n",
      "8356-th loss is : 0.0120563\n",
      "8357-th loss is : 0.00345254\n",
      "8358-th loss is : 0.0676247\n",
      "8359-th loss is : 0.0751959\n",
      "8360-th loss is : 0.0423029\n",
      "8361-th loss is : 0.000802125\n",
      "8362-th loss is : 0.00211167\n",
      "8363-th loss is : 0.00998513\n",
      "8364-th loss is : 0.0257621\n",
      "8365-th loss is : 0.07973\n",
      "8366-th loss is : 0.0811667\n",
      "8367-th loss is : 0.00105413\n",
      "8368-th loss is : 0.00471997\n",
      "8369-th loss is : 0.0702671\n",
      "8370-th loss is : 0.0453306\n",
      "8371-th loss is : 0.00505236\n",
      "8372-th loss is : 0.015282\n",
      "8373-th loss is : 0.00137751\n",
      "8374-th loss is : 2.84874e-05\n",
      "8375-th loss is : 0.00401802\n",
      "8376-th loss is : 0.0055956\n",
      "8377-th loss is : 0.0492336\n",
      "8378-th loss is : 0.119114\n",
      "8379-th loss is : 0.0335104\n",
      "8380-th loss is : 0.000126658\n",
      "8381-th loss is : 0.00163832\n",
      "8382-th loss is : 0.037598\n",
      "8383-th loss is : 0.000114176\n",
      "8384-th loss is : 0.0304326\n",
      "8385-th loss is : 0.0446818\n",
      "8386-th loss is : 0.0022055\n",
      "8387-th loss is : 0.0202546\n",
      "8388-th loss is : 0.100539\n",
      "8389-th loss is : 0.0156101\n",
      "8390-th loss is : 0.00538347\n",
      "8391-th loss is : 0.117568\n",
      "8392-th loss is : 0.0784187\n",
      "8393-th loss is : 0.0199753\n",
      "8394-th loss is : 0.0030356\n",
      "8395-th loss is : 0.000265716\n",
      "8396-th loss is : 0.00350037\n",
      "8397-th loss is : 0.00121919\n",
      "8398-th loss is : 0.0377816\n",
      "8399-th loss is : 0.0889579\n",
      "8400-th loss is : 0.0352549\n",
      "8401-th loss is : 0.000101438\n",
      "8402-th loss is : 0.0144452\n",
      "8403-th loss is : 9.66781e-05\n",
      "8404-th loss is : 0.0364003\n",
      "8405-th loss is : 0.113916\n",
      "8406-th loss is : 0.0699857\n",
      "8407-th loss is : 0.0662726\n",
      "8408-th loss is : 0.00471886\n",
      "8409-th loss is : 0.112664\n",
      "8410-th loss is : 9.21448e-05\n",
      "8411-th loss is : 0.00037382\n",
      "8412-th loss is : 0.0279932\n",
      "8413-th loss is : 0.00024551\n",
      "8414-th loss is : 0.0923291\n",
      "8415-th loss is : 0.0986551\n",
      "8416-th loss is : 0.0389209\n",
      "8417-th loss is : 3.6459e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8418-th loss is : 0.122084\n",
      "8419-th loss is : 0.0017813\n",
      "8420-th loss is : 0.0455286\n",
      "8421-th loss is : 0.0620111\n",
      "8422-th loss is : 0.0105548\n",
      "8423-th loss is : 0.000941625\n",
      "8424-th loss is : 0.00435794\n",
      "8425-th loss is : 0.0032734\n",
      "8426-th loss is : 0.000647423\n",
      "8427-th loss is : 0.0495171\n",
      "8428-th loss is : 0.0683894\n",
      "8429-th loss is : 0.0759362\n",
      "8430-th loss is : 0.0629542\n",
      "8431-th loss is : 0.067468\n",
      "8432-th loss is : 0.0485608\n",
      "8433-th loss is : 0.075197\n",
      "8434-th loss is : 0.017679\n",
      "8435-th loss is : 0.000224953\n",
      "8436-th loss is : 0.0339609\n",
      "8437-th loss is : 0.110115\n",
      "8438-th loss is : 0.0657657\n",
      "8439-th loss is : 0.0418283\n",
      "8440-th loss is : 0.0131691\n",
      "8441-th loss is : 0.1185\n",
      "8442-th loss is : 0.0257285\n",
      "8443-th loss is : 0.0692331\n",
      "8444-th loss is : 2.75616e-06\n",
      "8445-th loss is : 0.00298465\n",
      "8446-th loss is : 0.000698596\n",
      "8447-th loss is : 0.00715952\n",
      "8448-th loss is : 0.0181472\n",
      "8449-th loss is : 0.00917098\n",
      "8450-th loss is : 0.0442551\n",
      "8451-th loss is : 0.0262887\n",
      "8452-th loss is : 0.000135881\n",
      "8453-th loss is : 0.0829059\n",
      "8454-th loss is : 0.00662987\n",
      "8455-th loss is : 0.00202335\n",
      "8456-th loss is : 0.0645803\n",
      "8457-th loss is : 0.0206841\n",
      "8458-th loss is : 0.00343009\n",
      "8459-th loss is : 0.0701501\n",
      "8460-th loss is : 0.00236356\n",
      "8461-th loss is : 0.00526842\n",
      "8462-th loss is : 0.0333663\n",
      "8463-th loss is : 0.0307317\n",
      "8464-th loss is : 0.0185738\n",
      "8465-th loss is : 0.0730264\n",
      "8466-th loss is : 0.112551\n",
      "8467-th loss is : 1.69223e-05\n",
      "8468-th loss is : 0.057467\n",
      "8469-th loss is : 0.113613\n",
      "8470-th loss is : 0.00447759\n",
      "8471-th loss is : 2.95844e-06\n",
      "8472-th loss is : 0.00560532\n",
      "8473-th loss is : 0.00637305\n",
      "8474-th loss is : 0.0580708\n",
      "8475-th loss is : 0.00365934\n",
      "8476-th loss is : 2.48304e-05\n",
      "8477-th loss is : 0.00187473\n",
      "8478-th loss is : 0.0228809\n",
      "8479-th loss is : 0.00131811\n",
      "8480-th loss is : 0.000260416\n",
      "8481-th loss is : 0.0113097\n",
      "8482-th loss is : 0.000145338\n",
      "8483-th loss is : 0.0376863\n",
      "8484-th loss is : 0.000116005\n",
      "8485-th loss is : 0.0375464\n",
      "8486-th loss is : 0.0204935\n",
      "8487-th loss is : 0.0950618\n",
      "8488-th loss is : 0.00204853\n",
      "8489-th loss is : 0.0196101\n",
      "8490-th loss is : 0.00274226\n",
      "8491-th loss is : 0.0277123\n",
      "8492-th loss is : 7.92289e-05\n",
      "8493-th loss is : 0.00238733\n",
      "8494-th loss is : 0.00669551\n",
      "8495-th loss is : 0.00286819\n",
      "8496-th loss is : 0.0953716\n",
      "8497-th loss is : 0.041625\n",
      "8498-th loss is : 0.00371536\n",
      "8499-th loss is : 0.00385794\n",
      "8500-th loss is : 0.00552803\n",
      "8501-th loss is : 0.00435225\n",
      "8502-th loss is : 0.00903545\n",
      "8503-th loss is : 0.00129652\n",
      "8504-th loss is : 0.0529404\n",
      "8505-th loss is : 0.0578713\n",
      "8506-th loss is : 0.00356263\n",
      "8507-th loss is : 0.00263447\n",
      "8508-th loss is : 0.0687065\n",
      "8509-th loss is : 0.00341742\n",
      "8510-th loss is : 0.00124517\n",
      "8511-th loss is : 0.0662143\n",
      "8512-th loss is : 0.0604867\n",
      "8513-th loss is : 0.0842818\n",
      "8514-th loss is : 0.106895\n",
      "8515-th loss is : 0.0149865\n",
      "8516-th loss is : 0.106086\n",
      "8517-th loss is : 0.0673999\n",
      "8518-th loss is : 0.0568438\n",
      "8519-th loss is : 0.0145706\n",
      "8520-th loss is : 0.0660619\n",
      "8521-th loss is : 0.0420064\n",
      "8522-th loss is : 0.00149105\n",
      "8523-th loss is : 0.0950753\n",
      "8524-th loss is : 0.0219596\n",
      "8525-th loss is : 0.0332735\n",
      "8526-th loss is : 0.00190203\n",
      "8527-th loss is : 0.00411574\n",
      "8528-th loss is : 0.0819073\n",
      "8529-th loss is : 0.0145666\n",
      "8530-th loss is : 0.00130479\n",
      "8531-th loss is : 0.00108308\n",
      "8532-th loss is : 0.000661135\n",
      "8533-th loss is : 0.0299016\n",
      "8534-th loss is : 0.100046\n",
      "8535-th loss is : 0.0728296\n",
      "8536-th loss is : 5.16149e-06\n",
      "8537-th loss is : 0.00298737\n",
      "8538-th loss is : 0.0349137\n",
      "8539-th loss is : 0.00404385\n",
      "8540-th loss is : 0.0938228\n",
      "8541-th loss is : 0.00197469\n",
      "8542-th loss is : 0.00336095\n",
      "8543-th loss is : 0.0461947\n",
      "8544-th loss is : 0.0158486\n",
      "8545-th loss is : 0.00157625\n",
      "8546-th loss is : 0.0055852\n",
      "8547-th loss is : 0.00104168\n",
      "8548-th loss is : 0.0459152\n",
      "8549-th loss is : 0.0705757\n",
      "8550-th loss is : 0.000662064\n",
      "8551-th loss is : 0.0759452\n",
      "8552-th loss is : 0.072674\n",
      "8553-th loss is : 0.101714\n",
      "8554-th loss is : 0.00130657\n",
      "8555-th loss is : 0.0356539\n",
      "8556-th loss is : 0.105173\n",
      "8557-th loss is : 0.0926427\n",
      "8558-th loss is : 0.0826609\n",
      "8559-th loss is : 0.0596002\n",
      "8560-th loss is : 0.00920123\n",
      "8561-th loss is : 0.000553487\n",
      "8562-th loss is : 1.67848e-05\n",
      "8563-th loss is : 0.0607079\n",
      "8564-th loss is : 0.00375826\n",
      "8565-th loss is : 0.0040593\n",
      "8566-th loss is : 0.0907934\n",
      "8567-th loss is : 0.0892354\n",
      "8568-th loss is : 0.0339937\n",
      "8569-th loss is : 6.97446e-05\n",
      "8570-th loss is : 0.00237375\n",
      "8571-th loss is : 0.0854742\n",
      "8572-th loss is : 0.00380892\n",
      "8573-th loss is : 0.0768557\n",
      "8574-th loss is : 1.63698e-05\n",
      "8575-th loss is : 0.070238\n",
      "8576-th loss is : 0.0987573\n",
      "8577-th loss is : 0.0824357\n",
      "8578-th loss is : 0.0221635\n",
      "8579-th loss is : 0.0219524\n",
      "8580-th loss is : 0.00458123\n",
      "8581-th loss is : 0.0336694\n",
      "8582-th loss is : 0.00704827\n",
      "8583-th loss is : 0.00172755\n",
      "8584-th loss is : 0.00763959\n",
      "8585-th loss is : 0.00176844\n",
      "8586-th loss is : 0.0797623\n",
      "8587-th loss is : 0.00331409\n",
      "8588-th loss is : 0.00616628\n",
      "8589-th loss is : 0.0702993\n",
      "8590-th loss is : 0.00264116\n",
      "8591-th loss is : 0.00153723\n",
      "8592-th loss is : 0.0439835\n",
      "8593-th loss is : 0.0107876\n",
      "8594-th loss is : 0.00276205\n",
      "8595-th loss is : 0.116171\n",
      "8596-th loss is : 0.0472682\n",
      "8597-th loss is : 0.000178154\n",
      "8598-th loss is : 0.00396866\n",
      "8599-th loss is : 0.0441468\n",
      "8600-th loss is : 0.0500219\n",
      "8601-th loss is : 9.54524e-05\n",
      "8602-th loss is : 0.0506098\n",
      "8603-th loss is : 0.0946171\n",
      "8604-th loss is : 0.0505278\n",
      "8605-th loss is : 0.0088523\n",
      "8606-th loss is : 0.000640969\n",
      "8607-th loss is : 0.0952778\n",
      "8608-th loss is : 0.0512819\n",
      "8609-th loss is : 0.019608\n",
      "8610-th loss is : 0.064409\n",
      "8611-th loss is : 0.0465068\n",
      "8612-th loss is : 6.41081e-05\n",
      "8613-th loss is : 0.0742818\n",
      "8614-th loss is : 0.0374075\n",
      "8615-th loss is : 0.00305941\n",
      "8616-th loss is : 0.0653219\n",
      "8617-th loss is : 0.00346609\n",
      "8618-th loss is : 0.0594507\n",
      "8619-th loss is : 0.0208752\n",
      "8620-th loss is : 0.0524677\n",
      "8621-th loss is : 0.000749889\n",
      "8622-th loss is : 0.027568\n",
      "8623-th loss is : 8.33515e-05\n",
      "8624-th loss is : 0.0973524\n",
      "8625-th loss is : 0.0509278\n",
      "8626-th loss is : 0.0748147\n",
      "8627-th loss is : 0.0167468\n",
      "8628-th loss is : 0.0026539\n",
      "8629-th loss is : 0.00058396\n",
      "8630-th loss is : 0.109679\n",
      "8631-th loss is : 0.0164646\n",
      "8632-th loss is : 0.00220055\n",
      "8633-th loss is : 0.0166035\n",
      "8634-th loss is : 0.00182553\n",
      "8635-th loss is : 0.00147639\n",
      "8636-th loss is : 3.63676e-05\n",
      "8637-th loss is : 0.0846046\n",
      "8638-th loss is : 0.000195266\n",
      "8639-th loss is : 0.000680099\n",
      "8640-th loss is : 7.3182e-06\n",
      "8641-th loss is : 0.00662339\n",
      "8642-th loss is : 0.000449774\n",
      "8643-th loss is : 0.00101944\n",
      "8644-th loss is : 0.0518744\n",
      "8645-th loss is : 0.000617683\n",
      "8646-th loss is : 0.00619334\n",
      "8647-th loss is : 0.0166629\n",
      "8648-th loss is : 0.0515701\n",
      "8649-th loss is : 0.000619664\n",
      "8650-th loss is : 0.00346232\n",
      "8651-th loss is : 0.000327568\n",
      "8652-th loss is : 0.00161681\n",
      "8653-th loss is : 0.000235776\n",
      "8654-th loss is : 0.0122174\n",
      "8655-th loss is : 0.0130747\n",
      "8656-th loss is : 0.0107725\n",
      "8657-th loss is : 0.00961696\n",
      "8658-th loss is : 0.0404087\n",
      "8659-th loss is : 0.00839708\n",
      "8660-th loss is : 0.00673884\n",
      "8661-th loss is : 0.000928661\n",
      "8662-th loss is : 0.11345\n",
      "8663-th loss is : 0.00427744\n",
      "8664-th loss is : 0.00683547\n",
      "8665-th loss is : 0.000257543\n",
      "8666-th loss is : 0.0790884\n",
      "8667-th loss is : 0.00250463\n",
      "8668-th loss is : 0.0174623\n",
      "8669-th loss is : 0.0645732\n",
      "8670-th loss is : 0.000250087\n",
      "8671-th loss is : 0.000164512\n",
      "8672-th loss is : 0.104697\n",
      "8673-th loss is : 0.00120852\n",
      "8674-th loss is : 0.0754688\n",
      "8675-th loss is : 0.00508859\n",
      "8676-th loss is : 0.0420069\n",
      "8677-th loss is : 1.84956e-05\n",
      "8678-th loss is : 0.00207038\n",
      "8679-th loss is : 0.00311945\n",
      "8680-th loss is : 0.00082446\n",
      "8681-th loss is : 1.42921e-05\n",
      "8682-th loss is : 0.0595356\n",
      "8683-th loss is : 0.00132884\n",
      "8684-th loss is : 0.0789638\n",
      "8685-th loss is : 0.0220637\n",
      "8686-th loss is : 0.0769094\n",
      "8687-th loss is : 0.0440137\n",
      "8688-th loss is : 0.00285601\n",
      "8689-th loss is : 0.00140348\n",
      "8690-th loss is : 0.0186216\n",
      "8691-th loss is : 0.0496987\n",
      "8692-th loss is : 0.070678\n",
      "8693-th loss is : 0.00681048\n",
      "8694-th loss is : 0.0798346\n",
      "8695-th loss is : 0.00953886\n",
      "8696-th loss is : 0.0386763\n",
      "8697-th loss is : 0.000641739\n",
      "8698-th loss is : 0.0194126\n",
      "8699-th loss is : 0.0545606\n",
      "8700-th loss is : 0.0561194\n",
      "8701-th loss is : 0.00186795\n",
      "8702-th loss is : 0.00355305\n",
      "8703-th loss is : 0.00567824\n",
      "8704-th loss is : 0.000130846\n",
      "8705-th loss is : 0.00136272\n",
      "8706-th loss is : 0.00164886\n",
      "8707-th loss is : 0.0862857\n",
      "8708-th loss is : 0.0546676\n",
      "8709-th loss is : 0.000561696\n",
      "8710-th loss is : 7.5397e-05\n",
      "8711-th loss is : 0.000121167\n",
      "8712-th loss is : 0.110276\n",
      "8713-th loss is : 0.000144437\n",
      "8714-th loss is : 0.103092\n",
      "8715-th loss is : 0.00210082\n",
      "8716-th loss is : 0.000671224\n",
      "8717-th loss is : 0.00530238\n",
      "8718-th loss is : 0.04043\n",
      "8719-th loss is : 0.0359174\n",
      "8720-th loss is : 8.29569e-05\n",
      "8721-th loss is : 0.0785766\n",
      "8722-th loss is : 0.01016\n",
      "8723-th loss is : 1.11378e-06\n",
      "8724-th loss is : 0.00222266\n",
      "8725-th loss is : 0.00384922\n",
      "8726-th loss is : 0.0294969\n",
      "8727-th loss is : 0.0127232\n",
      "8728-th loss is : 0.0140495\n",
      "8729-th loss is : 0.0644481\n",
      "8730-th loss is : 0.00312583\n",
      "8731-th loss is : 0.0720849\n",
      "8732-th loss is : 0.0382958\n",
      "8733-th loss is : 0.00241368\n",
      "8734-th loss is : 0.0171469\n",
      "8735-th loss is : 0.00959789\n",
      "8736-th loss is : 0.0244889\n",
      "8737-th loss is : 0.0769827\n",
      "8738-th loss is : 0.025389\n",
      "8739-th loss is : 0.0855742\n",
      "8740-th loss is : 0.0009569\n",
      "8741-th loss is : 0.0103091\n",
      "8742-th loss is : 0.0255213\n",
      "8743-th loss is : 1.54578e-06\n",
      "8744-th loss is : 0.00889049\n",
      "8745-th loss is : 0.0860551\n",
      "8746-th loss is : 0.00201697\n",
      "8747-th loss is : 0.00749586\n",
      "8748-th loss is : 0.00778035\n",
      "8749-th loss is : 0.00629434\n",
      "8750-th loss is : 0.00804673\n",
      "8751-th loss is : 0.00149365\n",
      "8752-th loss is : 0.0208713\n",
      "8753-th loss is : 0.00506043\n",
      "8754-th loss is : 0.00369663\n",
      "8755-th loss is : 0.000405862\n",
      "8756-th loss is : 0.075689\n",
      "8757-th loss is : 0.0270335\n",
      "8758-th loss is : 0.110682\n",
      "8759-th loss is : 0.0143291\n",
      "8760-th loss is : 0.00614737\n",
      "8761-th loss is : 3.30543e-05\n",
      "8762-th loss is : 0.000916387\n",
      "8763-th loss is : 0.00813708\n",
      "8764-th loss is : 0.0943514\n",
      "8765-th loss is : 0.0291589\n",
      "8766-th loss is : 0.00103706\n",
      "8767-th loss is : 0.0478494\n",
      "8768-th loss is : 0.00581264\n",
      "8769-th loss is : 0.011873\n",
      "8770-th loss is : 0.0254648\n",
      "8771-th loss is : 0.00934334\n",
      "8772-th loss is : 0.0595225\n",
      "8773-th loss is : 0.111161\n",
      "8774-th loss is : 0.0261676\n",
      "8775-th loss is : 0.00469077\n",
      "8776-th loss is : 0.031001\n",
      "8777-th loss is : 0.0106757\n",
      "8778-th loss is : 0.0658303\n",
      "8779-th loss is : 0.0127443\n",
      "8780-th loss is : 0.00313426\n",
      "8781-th loss is : 0.0724171\n",
      "8782-th loss is : 0.0294028\n",
      "8783-th loss is : 0.00073982\n",
      "8784-th loss is : 0.00568498\n",
      "8785-th loss is : 0.000188688\n",
      "8786-th loss is : 0.0797393\n",
      "8787-th loss is : 0.0719039\n",
      "8788-th loss is : 0.0432288\n",
      "8789-th loss is : 0.00223348\n",
      "8790-th loss is : 0.00979684\n",
      "8791-th loss is : 0.0692553\n",
      "8792-th loss is : 0.00197727\n",
      "8793-th loss is : 0.000545771\n",
      "8794-th loss is : 0.00320447\n",
      "8795-th loss is : 0.00153349\n",
      "8796-th loss is : 0.0538112\n",
      "8797-th loss is : 0.00295459\n",
      "8798-th loss is : 0.109614\n",
      "8799-th loss is : 0.00460346\n",
      "8800-th loss is : 0.00315524\n",
      "8801-th loss is : 0.06818\n",
      "8802-th loss is : 0.0151464\n",
      "8803-th loss is : 0.0274488\n",
      "8804-th loss is : 0.000106578\n",
      "8805-th loss is : 0.039116\n",
      "8806-th loss is : 0.00281948\n",
      "8807-th loss is : 0.010137\n",
      "8808-th loss is : 0.0987889\n",
      "8809-th loss is : 0.00021073\n",
      "8810-th loss is : 8.3122e-07\n",
      "8811-th loss is : 0.00242138\n",
      "8812-th loss is : 0.0827081\n",
      "8813-th loss is : 0.00427086\n",
      "8814-th loss is : 0.0145249\n",
      "8815-th loss is : 0.0234874\n",
      "8816-th loss is : 0.0878902\n",
      "8817-th loss is : 0.00053057\n",
      "8818-th loss is : 0.0955827\n",
      "8819-th loss is : 0.0289099\n",
      "8820-th loss is : 0.0308562\n",
      "8821-th loss is : 0.00036481\n",
      "8822-th loss is : 0.013994\n",
      "8823-th loss is : 0.0746178\n",
      "8824-th loss is : 0.01684\n",
      "8825-th loss is : 0.0757808\n",
      "8826-th loss is : 0.0100937\n",
      "8827-th loss is : 0.042532\n",
      "8828-th loss is : 0.109555\n",
      "8829-th loss is : 0.00365183\n",
      "8830-th loss is : 0.00157695\n",
      "8831-th loss is : 0.00129184\n",
      "8832-th loss is : 0.00366321\n",
      "8833-th loss is : 0.0730901\n",
      "8834-th loss is : 0.00236091\n",
      "8835-th loss is : 0.065444\n",
      "8836-th loss is : 0.0412826\n",
      "8837-th loss is : 0.0699825\n",
      "8838-th loss is : 0.00420556\n",
      "8839-th loss is : 0.0704536\n",
      "8840-th loss is : 0.000512348\n",
      "8841-th loss is : 1.43471e-05\n",
      "8842-th loss is : 0.0367094\n",
      "8843-th loss is : 0.0439647\n",
      "8844-th loss is : 0.0109152\n",
      "8845-th loss is : 0.0461322\n",
      "8846-th loss is : 0.0279049\n",
      "8847-th loss is : 0.071289\n",
      "8848-th loss is : 0.00383366\n",
      "8849-th loss is : 0.0912606\n",
      "8850-th loss is : 0.000247366\n",
      "8851-th loss is : 0.00474666\n",
      "8852-th loss is : 0.0487688\n",
      "8853-th loss is : 0.00359182\n",
      "8854-th loss is : 0.00609771\n",
      "8855-th loss is : 0.0171126\n",
      "8856-th loss is : 0.0785529\n",
      "8857-th loss is : 0.000100423\n",
      "8858-th loss is : 0.0428697\n",
      "8859-th loss is : 0.0899014\n",
      "8860-th loss is : 0.0535242\n",
      "8861-th loss is : 0.0050387\n",
      "8862-th loss is : 0.0647083\n",
      "8863-th loss is : 0.000487879\n",
      "8864-th loss is : 0.000659092\n",
      "8865-th loss is : 0.088974\n",
      "8866-th loss is : 0.0276333\n",
      "8867-th loss is : 4.60092e-09\n",
      "8868-th loss is : 0.0729611\n",
      "8869-th loss is : 0.000198119\n",
      "8870-th loss is : 0.0989461\n",
      "8871-th loss is : 0.000109276\n",
      "8872-th loss is : 0.0472277\n",
      "8873-th loss is : 0.0308161\n",
      "8874-th loss is : 2.02015e-05\n",
      "8875-th loss is : 0.000123231\n",
      "8876-th loss is : 0.044739\n",
      "8877-th loss is : 0.0338882\n",
      "8878-th loss is : 0.000343383\n",
      "8879-th loss is : 0.0555319\n",
      "8880-th loss is : 0.00587972\n",
      "8881-th loss is : 0.00774718\n",
      "8882-th loss is : 0.00292685\n",
      "8883-th loss is : 0.0722663\n",
      "8884-th loss is : 0.000107116\n",
      "8885-th loss is : 0.029769\n",
      "8886-th loss is : 4.26182e-05\n",
      "8887-th loss is : 0.0619204\n",
      "8888-th loss is : 0.00964054\n",
      "8889-th loss is : 0.0404476\n",
      "8890-th loss is : 0.0241671\n",
      "8891-th loss is : 0.00253889\n",
      "8892-th loss is : 0.00218846\n",
      "8893-th loss is : 0.0403766\n",
      "8894-th loss is : 0.000113461\n",
      "8895-th loss is : 0.0134244\n",
      "8896-th loss is : 0.00307617\n",
      "8897-th loss is : 0.0114728\n",
      "8898-th loss is : 0.0360824\n",
      "8899-th loss is : 0.00100968\n",
      "8900-th loss is : 0.064342\n",
      "8901-th loss is : 0.0631845\n",
      "8902-th loss is : 0.0034226\n",
      "8903-th loss is : 0.0155667\n",
      "8904-th loss is : 0.0919459\n",
      "8905-th loss is : 0.0280045\n",
      "8906-th loss is : 0.00349897\n",
      "8907-th loss is : 2.99657e-07\n",
      "8908-th loss is : 0.0473356\n",
      "8909-th loss is : 0.00186182\n",
      "8910-th loss is : 0.000312338\n",
      "8911-th loss is : 0.000590234\n",
      "8912-th loss is : 0.105752\n",
      "8913-th loss is : 0.00744325\n",
      "8914-th loss is : 0.0311665\n",
      "8915-th loss is : 0.0665492\n",
      "8916-th loss is : 0.0922778\n",
      "8917-th loss is : 0.00604319\n",
      "8918-th loss is : 0.0343612\n",
      "8919-th loss is : 0.0478511\n",
      "8920-th loss is : 0.0962177\n",
      "8921-th loss is : 0.0202726\n",
      "8922-th loss is : 0.016361\n",
      "8923-th loss is : 0.0801628\n",
      "8924-th loss is : 0.00115675\n",
      "8925-th loss is : 0.0758898\n",
      "8926-th loss is : 0.0100929\n",
      "8927-th loss is : 0.000217672\n",
      "8928-th loss is : 0.0765994\n",
      "8929-th loss is : 0.062679\n",
      "8930-th loss is : 0.000816766\n",
      "8931-th loss is : 0.000191465\n",
      "8932-th loss is : 0.00034371\n",
      "8933-th loss is : 0.00539663\n",
      "8934-th loss is : 0.0479752\n",
      "8935-th loss is : 0.00105216\n",
      "8936-th loss is : 0.05197\n",
      "8937-th loss is : 0.0125225\n",
      "8938-th loss is : 0.000870641\n",
      "8939-th loss is : 0.000745814\n",
      "8940-th loss is : 0.00427506\n",
      "8941-th loss is : 0.00240098\n",
      "8942-th loss is : 0.00104308\n",
      "8943-th loss is : 0.105812\n",
      "8944-th loss is : 0.0503135\n",
      "8945-th loss is : 0.0012059\n",
      "8946-th loss is : 0.00112054\n",
      "8947-th loss is : 0.000140356\n",
      "8948-th loss is : 2.64442e-05\n",
      "8949-th loss is : 0.0451459\n",
      "8950-th loss is : 0.0151463\n",
      "8951-th loss is : 0.000628885\n",
      "8952-th loss is : 0.0363173\n",
      "8953-th loss is : 0.0274471\n",
      "8954-th loss is : 0.00269736\n",
      "8955-th loss is : 3.31112e-07\n",
      "8956-th loss is : 0.0248021\n",
      "8957-th loss is : 0.000105344\n",
      "8958-th loss is : 0.000986886\n",
      "8959-th loss is : 0.0543065\n",
      "8960-th loss is : 0.0150105\n",
      "8961-th loss is : 0.0315784\n",
      "8962-th loss is : 0.00950736\n",
      "8963-th loss is : 0.00313999\n",
      "8964-th loss is : 0.0378609\n",
      "8965-th loss is : 0.00102649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8966-th loss is : 0.00360905\n",
      "8967-th loss is : 0.0708885\n",
      "8968-th loss is : 0.0002046\n",
      "8969-th loss is : 0.00292141\n",
      "8970-th loss is : 0.00191931\n",
      "8971-th loss is : 0.0640133\n",
      "8972-th loss is : 0.0209751\n",
      "8973-th loss is : 0.00581511\n",
      "8974-th loss is : 0.0784666\n",
      "8975-th loss is : 0.103488\n",
      "8976-th loss is : 0.0608634\n",
      "8977-th loss is : 0.00359763\n",
      "8978-th loss is : 0.00955713\n",
      "8979-th loss is : 0.0170803\n",
      "8980-th loss is : 0.00436652\n",
      "8981-th loss is : 0.0941001\n",
      "8982-th loss is : 0.0970804\n",
      "8983-th loss is : 0.0694486\n",
      "8984-th loss is : 0.00176084\n",
      "8985-th loss is : 0.02116\n",
      "8986-th loss is : 0.000150511\n",
      "8987-th loss is : 0.0649708\n",
      "8988-th loss is : 0.0753393\n",
      "8989-th loss is : 0.0347721\n",
      "8990-th loss is : 0.0792053\n",
      "8991-th loss is : 0.00754132\n",
      "8992-th loss is : 0.0128362\n",
      "8993-th loss is : 0.0142073\n",
      "8994-th loss is : 0.0299436\n",
      "8995-th loss is : 0.0754414\n",
      "8996-th loss is : 0.00115642\n",
      "8997-th loss is : 0.0204012\n",
      "8998-th loss is : 0.00421278\n",
      "8999-th loss is : 0.00782974\n",
      "9000-th loss is : 0.020063\n",
      "9001-th loss is : 0.00291255\n",
      "9002-th loss is : 0.0631372\n",
      "9003-th loss is : 5.31077e-05\n",
      "9004-th loss is : 0.000250298\n",
      "9005-th loss is : 0.00261618\n",
      "9006-th loss is : 0.0291811\n",
      "9007-th loss is : 0.0745991\n",
      "9008-th loss is : 0.000985292\n",
      "9009-th loss is : 0.0137711\n",
      "9010-th loss is : 0.0949438\n",
      "9011-th loss is : 0.00176306\n",
      "9012-th loss is : 0.00382124\n",
      "9013-th loss is : 0.00507269\n",
      "9014-th loss is : 0.0103149\n",
      "9015-th loss is : 6.89902e-06\n",
      "9016-th loss is : 0.0266207\n",
      "9017-th loss is : 0.0335757\n",
      "9018-th loss is : 0.0531245\n",
      "9019-th loss is : 0.00102613\n",
      "9020-th loss is : 0.00758431\n",
      "9021-th loss is : 0.00296306\n",
      "9022-th loss is : 0.0170985\n",
      "9023-th loss is : 0.05539\n",
      "9024-th loss is : 0.00615019\n",
      "9025-th loss is : 0.000334803\n",
      "9026-th loss is : 0.00593268\n",
      "9027-th loss is : 0.0133419\n",
      "9028-th loss is : 0.0621079\n",
      "9029-th loss is : 0.0709144\n",
      "9030-th loss is : 0.0800448\n",
      "9031-th loss is : 0.00740727\n",
      "9032-th loss is : 0.0019452\n",
      "9033-th loss is : 0.0770331\n",
      "9034-th loss is : 0.0131581\n",
      "9035-th loss is : 0.065055\n",
      "9036-th loss is : 0.0116429\n",
      "9037-th loss is : 0.00135517\n",
      "9038-th loss is : 0.0164805\n",
      "9039-th loss is : 0.0262346\n",
      "9040-th loss is : 0.0370925\n",
      "9041-th loss is : 3.2892e-05\n",
      "9042-th loss is : 0.0001038\n",
      "9043-th loss is : 0.0344054\n",
      "9044-th loss is : 0.0522925\n",
      "9045-th loss is : 0.0519867\n",
      "9046-th loss is : 0.0166736\n",
      "9047-th loss is : 0.0593789\n",
      "9048-th loss is : 0.0367486\n",
      "9049-th loss is : 0.0038646\n",
      "9050-th loss is : 0.0308558\n",
      "9051-th loss is : 0.0103866\n",
      "9052-th loss is : 0.00362205\n",
      "9053-th loss is : 0.00381403\n",
      "9054-th loss is : 0.00439097\n",
      "9055-th loss is : 8.04346e-05\n",
      "9056-th loss is : 0.000808393\n",
      "9057-th loss is : 0.000954884\n",
      "9058-th loss is : 0.000591063\n",
      "9059-th loss is : 6.79622e-05\n",
      "9060-th loss is : 0.0131881\n",
      "9061-th loss is : 0.00199983\n",
      "9062-th loss is : 0.0231011\n",
      "9063-th loss is : 0.00423881\n",
      "9064-th loss is : 0.00151625\n",
      "9065-th loss is : 0.00753058\n",
      "9066-th loss is : 0.0553198\n",
      "9067-th loss is : 0.0563054\n",
      "9068-th loss is : 0.00172616\n",
      "9069-th loss is : 0.000895676\n",
      "9070-th loss is : 0.0119191\n",
      "9071-th loss is : 0.00546886\n",
      "9072-th loss is : 0.0496444\n",
      "9073-th loss is : 0.000151695\n",
      "9074-th loss is : 0.0147411\n",
      "9075-th loss is : 0.0166535\n",
      "9076-th loss is : 0.0524283\n",
      "9077-th loss is : 0.00391915\n",
      "9078-th loss is : 0.0106985\n",
      "9079-th loss is : 0.0265945\n",
      "9080-th loss is : 0.0648443\n",
      "9081-th loss is : 0.0527949\n",
      "9082-th loss is : 0.012048\n",
      "9083-th loss is : 0.00125415\n",
      "9084-th loss is : 0.00423392\n",
      "9085-th loss is : 0.0555616\n",
      "9086-th loss is : 0.000761585\n",
      "9087-th loss is : 0.0073685\n",
      "9088-th loss is : 0.000482693\n",
      "9089-th loss is : 0.0460973\n",
      "9090-th loss is : 0.00528269\n",
      "9091-th loss is : 0.0364188\n",
      "9092-th loss is : 0.00494125\n",
      "9093-th loss is : 0.0225488\n",
      "9094-th loss is : 0.101673\n",
      "9095-th loss is : 0.0020787\n",
      "9096-th loss is : 0.0161149\n",
      "9097-th loss is : 0.039548\n",
      "9098-th loss is : 0.0372335\n",
      "9099-th loss is : 0.00032757\n",
      "9100-th loss is : 0.000965008\n",
      "9101-th loss is : 0.0728943\n",
      "9102-th loss is : 0.0831312\n",
      "9103-th loss is : 0.00339841\n",
      "9104-th loss is : 0.0690565\n",
      "9105-th loss is : 0.00837894\n",
      "9106-th loss is : 1.17441e-05\n",
      "9107-th loss is : 0.00415131\n",
      "9108-th loss is : 0.0126453\n",
      "9109-th loss is : 0.0394645\n",
      "9110-th loss is : 0.0277263\n",
      "9111-th loss is : 0.00355048\n",
      "9112-th loss is : 0.023001\n",
      "9113-th loss is : 0.00762373\n",
      "9114-th loss is : 0.0463741\n",
      "9115-th loss is : 0.00679596\n",
      "9116-th loss is : 0.0155118\n",
      "9117-th loss is : 0.0184273\n",
      "9118-th loss is : 0.0486831\n",
      "9119-th loss is : 1.29639e-05\n",
      "9120-th loss is : 0.00187597\n",
      "9121-th loss is : 0.000873418\n",
      "9122-th loss is : 0.0750679\n",
      "9123-th loss is : 0.0440297\n",
      "9124-th loss is : 0.00304896\n",
      "9125-th loss is : 0.0460702\n",
      "9126-th loss is : 0.049889\n",
      "9127-th loss is : 0.0246866\n",
      "9128-th loss is : 0.0516709\n",
      "9129-th loss is : 0.0520367\n",
      "9130-th loss is : 0.0102067\n",
      "9131-th loss is : 0.000327533\n",
      "9132-th loss is : 0.0387898\n",
      "9133-th loss is : 0.00312864\n",
      "9134-th loss is : 0.016667\n",
      "9135-th loss is : 0.00200421\n",
      "9136-th loss is : 0.00234225\n",
      "9137-th loss is : 0.00839234\n",
      "9138-th loss is : 0.0036617\n",
      "9139-th loss is : 0.0356737\n",
      "9140-th loss is : 0.00235068\n",
      "9141-th loss is : 0.0548427\n",
      "9142-th loss is : 6.14251e-07\n",
      "9143-th loss is : 0.00844881\n",
      "9144-th loss is : 0.054952\n",
      "9145-th loss is : 0.0117414\n",
      "9146-th loss is : 3.01258e-05\n",
      "9147-th loss is : 0.00231665\n",
      "9148-th loss is : 0.0645422\n",
      "9149-th loss is : 0.000658474\n",
      "9150-th loss is : 0.0697531\n",
      "9151-th loss is : 0.00606625\n",
      "9152-th loss is : 0.000596233\n",
      "9153-th loss is : 0.0663659\n",
      "9154-th loss is : 0.0680431\n",
      "9155-th loss is : 0.050304\n",
      "9156-th loss is : 0.0864844\n",
      "9157-th loss is : 0.00422753\n",
      "9158-th loss is : 8.50239e-07\n",
      "9159-th loss is : 0.0825318\n",
      "9160-th loss is : 0.00411676\n",
      "9161-th loss is : 0.00468315\n",
      "9162-th loss is : 0.000962472\n",
      "9163-th loss is : 0.0139978\n",
      "9164-th loss is : 0.041477\n",
      "9165-th loss is : 0.0115315\n",
      "9166-th loss is : 0.0185454\n",
      "9167-th loss is : 0.00738801\n",
      "9168-th loss is : 0.000456027\n",
      "9169-th loss is : 0.0531711\n",
      "9170-th loss is : 0.0701109\n",
      "9171-th loss is : 0.00623243\n",
      "9172-th loss is : 0.0118742\n",
      "9173-th loss is : 0.0714204\n",
      "9174-th loss is : 0.0147705\n",
      "9175-th loss is : 0.00392801\n",
      "9176-th loss is : 2.90821e-06\n",
      "9177-th loss is : 0.000117169\n",
      "9178-th loss is : 0.017166\n",
      "9179-th loss is : 0.0103628\n",
      "9180-th loss is : 0.0907084\n",
      "9181-th loss is : 0.00316614\n",
      "9182-th loss is : 0.0902586\n",
      "9183-th loss is : 0.0157173\n",
      "9184-th loss is : 0.0717014\n",
      "9185-th loss is : 0.00185523\n",
      "9186-th loss is : 0.005751\n",
      "9187-th loss is : 0.000707338\n",
      "9188-th loss is : 0.0939012\n",
      "9189-th loss is : 0.0207156\n",
      "9190-th loss is : 0.0670088\n",
      "9191-th loss is : 0.00166411\n",
      "9192-th loss is : 0.0496661\n",
      "9193-th loss is : 0.037133\n",
      "9194-th loss is : 0.00448528\n",
      "9195-th loss is : 0.000178341\n",
      "9196-th loss is : 0.00539245\n",
      "9197-th loss is : 0.0295692\n",
      "9198-th loss is : 0.0560804\n",
      "9199-th loss is : 0.100036\n",
      "9200-th loss is : 0.0463694\n",
      "9201-th loss is : 0.000195311\n",
      "9202-th loss is : 0.00971541\n",
      "9203-th loss is : 0.0753577\n",
      "9204-th loss is : 0.0834508\n",
      "9205-th loss is : 0.00708772\n",
      "9206-th loss is : 0.0360328\n",
      "9207-th loss is : 0.000106578\n",
      "9208-th loss is : 0.0889669\n",
      "9209-th loss is : 0.0027585\n",
      "9210-th loss is : 0.0801349\n",
      "9211-th loss is : 0.0495028\n",
      "9212-th loss is : 0.00454268\n",
      "9213-th loss is : 0.085731\n",
      "9214-th loss is : 0.0442926\n",
      "9215-th loss is : 0.0158813\n",
      "9216-th loss is : 0.0689307\n",
      "9217-th loss is : 0.0760881\n",
      "9218-th loss is : 0.05886\n",
      "9219-th loss is : 0.039391\n",
      "9220-th loss is : 0.0118704\n",
      "9221-th loss is : 0.066631\n",
      "9222-th loss is : 6.87289e-05\n",
      "9223-th loss is : 0.0726191\n",
      "9224-th loss is : 0.00494469\n",
      "9225-th loss is : 0.0535886\n",
      "9226-th loss is : 0.00167728\n",
      "9227-th loss is : 0.0778345\n",
      "9228-th loss is : 0.00484384\n",
      "9229-th loss is : 0.00185866\n",
      "9230-th loss is : 0.00208647\n",
      "9231-th loss is : 0.0036379\n",
      "9232-th loss is : 0.0172899\n",
      "9233-th loss is : 0.00152988\n",
      "9234-th loss is : 0.00667245\n",
      "9235-th loss is : 0.0093894\n",
      "9236-th loss is : 0.0456789\n",
      "9237-th loss is : 0.0132739\n",
      "9238-th loss is : 0.0414475\n",
      "9239-th loss is : 0.0697273\n",
      "9240-th loss is : 0.0933303\n",
      "9241-th loss is : 0.0902672\n",
      "9242-th loss is : 0.0129426\n",
      "9243-th loss is : 0.0812233\n",
      "9244-th loss is : 0.00338967\n",
      "9245-th loss is : 0.00882513\n",
      "9246-th loss is : 0.000260538\n",
      "9247-th loss is : 0.00144402\n",
      "9248-th loss is : 0.0673755\n",
      "9249-th loss is : 0.00163104\n",
      "9250-th loss is : 0.00364887\n",
      "9251-th loss is : 0.0010461\n",
      "9252-th loss is : 0.0926829\n",
      "9253-th loss is : 0.0233951\n",
      "9254-th loss is : 0.0402318\n",
      "9255-th loss is : 0.0215928\n",
      "9256-th loss is : 1.97142e-05\n",
      "9257-th loss is : 0.0791612\n",
      "9258-th loss is : 1.93503e-06\n",
      "9259-th loss is : 0.0343213\n",
      "9260-th loss is : 0.000182873\n",
      "9261-th loss is : 0.012615\n",
      "9262-th loss is : 0.0653829\n",
      "9263-th loss is : 0.0322524\n",
      "9264-th loss is : 1.35441e-05\n",
      "9265-th loss is : 0.0404525\n",
      "9266-th loss is : 0.00189603\n",
      "9267-th loss is : 0.000232754\n",
      "9268-th loss is : 0.0013825\n",
      "9269-th loss is : 0.000974559\n",
      "9270-th loss is : 0.00298763\n",
      "9271-th loss is : 0.0696374\n",
      "9272-th loss is : 0.0728091\n",
      "9273-th loss is : 0.00475061\n",
      "9274-th loss is : 0.00170353\n",
      "9275-th loss is : 0.00013954\n",
      "9276-th loss is : 0.0554223\n",
      "9277-th loss is : 0.00112898\n",
      "9278-th loss is : 0.0541986\n",
      "9279-th loss is : 0.0216043\n",
      "9280-th loss is : 0.00920263\n",
      "9281-th loss is : 0.0244692\n",
      "9282-th loss is : 3.98867e-05\n",
      "9283-th loss is : 0.0474885\n",
      "9284-th loss is : 0.0324137\n",
      "9285-th loss is : 0.00166981\n",
      "9286-th loss is : 0.0227451\n",
      "9287-th loss is : 0.0114904\n",
      "9288-th loss is : 0.0582661\n",
      "9289-th loss is : 0.0056448\n",
      "9290-th loss is : 0.0156374\n",
      "9291-th loss is : 0.00906895\n",
      "9292-th loss is : 0.0663279\n",
      "9293-th loss is : 0.0452722\n",
      "9294-th loss is : 0.0157055\n",
      "9295-th loss is : 0.00551984\n",
      "9296-th loss is : 0.00155943\n",
      "9297-th loss is : 0.0558002\n",
      "9298-th loss is : 0.00668441\n",
      "9299-th loss is : 0.00379698\n",
      "9300-th loss is : 0.090267\n",
      "9301-th loss is : 0.00228615\n",
      "9302-th loss is : 0.0219975\n",
      "9303-th loss is : 0.00234361\n",
      "9304-th loss is : 0.0208936\n",
      "9305-th loss is : 0.0684988\n",
      "9306-th loss is : 0.0608767\n",
      "9307-th loss is : 6.5741e-05\n",
      "9308-th loss is : 0.000127929\n",
      "9309-th loss is : 0.0218589\n",
      "9310-th loss is : 0.000775452\n",
      "9311-th loss is : 0.0695462\n",
      "9312-th loss is : 0.0927038\n",
      "9313-th loss is : 0.0518366\n",
      "9314-th loss is : 0.0736626\n",
      "9315-th loss is : 5.68352e-05\n",
      "9316-th loss is : 0.0656087\n",
      "9317-th loss is : 0.00678119\n",
      "9318-th loss is : 0.0244169\n",
      "9319-th loss is : 0.0190363\n",
      "9320-th loss is : 0.00177906\n",
      "9321-th loss is : 0.0015976\n",
      "9322-th loss is : 0.0024406\n",
      "9323-th loss is : 0.00590795\n",
      "9324-th loss is : 0.0281678\n",
      "9325-th loss is : 0.00642327\n",
      "9326-th loss is : 0.0650282\n",
      "9327-th loss is : 0.0778958\n",
      "9328-th loss is : 0.000182932\n",
      "9329-th loss is : 0.0708248\n",
      "9330-th loss is : 0.0119828\n",
      "9331-th loss is : 0.036849\n",
      "9332-th loss is : 0.000177428\n",
      "9333-th loss is : 0.000693984\n",
      "9334-th loss is : 0.0230632\n",
      "9335-th loss is : 0.00961852\n",
      "9336-th loss is : 0.000281479\n",
      "9337-th loss is : 0.00309477\n",
      "9338-th loss is : 0.0771465\n",
      "9339-th loss is : 0.061178\n",
      "9340-th loss is : 0.00132531\n",
      "9341-th loss is : 0.0106948\n",
      "9342-th loss is : 0.021552\n",
      "9343-th loss is : 0.0239501\n",
      "9344-th loss is : 0.00222419\n",
      "9345-th loss is : 0.000206284\n",
      "9346-th loss is : 0.0100741\n",
      "9347-th loss is : 0.0177739\n",
      "9348-th loss is : 0.058406\n",
      "9349-th loss is : 0.000667169\n",
      "9350-th loss is : 0.000220769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9351-th loss is : 0.034303\n",
      "9352-th loss is : 0.000271275\n",
      "9353-th loss is : 0.00128261\n",
      "9354-th loss is : 0.0325654\n",
      "9355-th loss is : 0.0460063\n",
      "9356-th loss is : 0.0138298\n",
      "9357-th loss is : 0.0199853\n",
      "9358-th loss is : 5.22701e-05\n",
      "9359-th loss is : 0.000258895\n",
      "9360-th loss is : 0.0226696\n",
      "9361-th loss is : 0.000259256\n",
      "9362-th loss is : 0.0920381\n",
      "9363-th loss is : 0.0190364\n",
      "9364-th loss is : 0.00230888\n",
      "9365-th loss is : 0.000523032\n",
      "9366-th loss is : 0.0201238\n",
      "9367-th loss is : 0.0378694\n",
      "9368-th loss is : 0.0210878\n",
      "9369-th loss is : 0.00280017\n",
      "9370-th loss is : 0.0203715\n",
      "9371-th loss is : 0.081206\n",
      "9372-th loss is : 2.80008e-05\n",
      "9373-th loss is : 0.00945048\n",
      "9374-th loss is : 0.00896087\n",
      "9375-th loss is : 0.00580699\n",
      "9376-th loss is : 0.000191587\n",
      "9377-th loss is : 0.00180219\n",
      "9378-th loss is : 0.0825091\n",
      "9379-th loss is : 0.00309591\n",
      "9380-th loss is : 0.0328481\n",
      "9381-th loss is : 0.0438883\n",
      "9382-th loss is : 0.00371335\n",
      "9383-th loss is : 0.0013142\n",
      "9384-th loss is : 0.0220535\n",
      "9385-th loss is : 0.00100092\n",
      "9386-th loss is : 0.00621912\n",
      "9387-th loss is : 0.0178145\n",
      "9388-th loss is : 0.000268901\n",
      "9389-th loss is : 0.000950976\n",
      "9390-th loss is : 0.0822476\n",
      "9391-th loss is : 0.0315641\n",
      "9392-th loss is : 0.0060066\n",
      "9393-th loss is : 7.30564e-07\n",
      "9394-th loss is : 0.00145395\n",
      "9395-th loss is : 0.00806066\n",
      "9396-th loss is : 6.58909e-05\n",
      "9397-th loss is : 0.00104981\n",
      "9398-th loss is : 0.00117902\n",
      "9399-th loss is : 0.0779545\n",
      "9400-th loss is : 2.48098e-06\n",
      "9401-th loss is : 0.00372993\n",
      "9402-th loss is : 0.0219464\n",
      "9403-th loss is : 0.011387\n",
      "9404-th loss is : 0.00078787\n",
      "9405-th loss is : 0.0799187\n",
      "9406-th loss is : 0.00127688\n",
      "9407-th loss is : 0.0705166\n",
      "9408-th loss is : 0.0222126\n",
      "9409-th loss is : 0.0288991\n",
      "9410-th loss is : 0.000336075\n",
      "9411-th loss is : 0.000455498\n",
      "9412-th loss is : 0.0899349\n",
      "9413-th loss is : 0.0062254\n",
      "9414-th loss is : 3.53377e-05\n",
      "9415-th loss is : 0.0530977\n",
      "9416-th loss is : 0.0494943\n",
      "9417-th loss is : 0.00538305\n",
      "9418-th loss is : 0.000608586\n",
      "9419-th loss is : 0.00493463\n",
      "9420-th loss is : 0.0468267\n",
      "9421-th loss is : 0.0515027\n",
      "9422-th loss is : 0.000144109\n",
      "9423-th loss is : 0.0338092\n",
      "9424-th loss is : 0.000444025\n",
      "9425-th loss is : 0.00610261\n",
      "9426-th loss is : 0.0632108\n",
      "9427-th loss is : 0.0829625\n",
      "9428-th loss is : 0.00663973\n",
      "9429-th loss is : 0.00026179\n",
      "9430-th loss is : 0.0111677\n",
      "9431-th loss is : 0.0338933\n",
      "9432-th loss is : 0.0147269\n",
      "9433-th loss is : 0.064118\n",
      "9434-th loss is : 0.000269043\n",
      "9435-th loss is : 0.000841417\n",
      "9436-th loss is : 0.000227724\n",
      "9437-th loss is : 0.00596344\n",
      "9438-th loss is : 0.00203073\n",
      "9439-th loss is : 0.0139883\n",
      "9440-th loss is : 0.000452909\n",
      "9441-th loss is : 2.79447e-05\n",
      "9442-th loss is : 0.0834477\n",
      "9443-th loss is : 0.0385642\n",
      "9444-th loss is : 0.00820869\n",
      "9445-th loss is : 0.035481\n",
      "9446-th loss is : 0.0318675\n",
      "9447-th loss is : 0.000529527\n",
      "9448-th loss is : 0.0518119\n",
      "9449-th loss is : 0.0338377\n",
      "9450-th loss is : 0.0818849\n",
      "9451-th loss is : 0.0354253\n",
      "9452-th loss is : 0.0469878\n",
      "9453-th loss is : 0.0704755\n",
      "9454-th loss is : 0.00841898\n",
      "9455-th loss is : 0.0152952\n",
      "9456-th loss is : 0.00192728\n",
      "9457-th loss is : 0.000301207\n",
      "9458-th loss is : 2.1333e-05\n",
      "9459-th loss is : 0.00311316\n",
      "9460-th loss is : 0.000161869\n",
      "9461-th loss is : 0.00834375\n",
      "9462-th loss is : 0.0862546\n",
      "9463-th loss is : 0.00162513\n",
      "9464-th loss is : 0.043774\n",
      "9465-th loss is : 0.0786511\n",
      "9466-th loss is : 0.00866114\n",
      "9467-th loss is : 0.0881829\n",
      "9468-th loss is : 0.00289966\n",
      "9469-th loss is : 0.0349939\n",
      "9470-th loss is : 0.00643636\n",
      "9471-th loss is : 0.0313611\n",
      "9472-th loss is : 5.69413e-07\n",
      "9473-th loss is : 0.0708414\n",
      "9474-th loss is : 0.00364714\n",
      "9475-th loss is : 1.34722e-07\n",
      "9476-th loss is : 0.0550879\n",
      "9477-th loss is : 0.00169627\n",
      "9478-th loss is : 0.00560415\n",
      "9479-th loss is : 0.00778035\n",
      "9480-th loss is : 0.0375742\n",
      "9481-th loss is : 0.0903193\n",
      "9482-th loss is : 0.0069347\n",
      "9483-th loss is : 0.00734854\n",
      "9484-th loss is : 0.0372306\n",
      "9485-th loss is : 0.000244437\n",
      "9486-th loss is : 0.0321794\n",
      "9487-th loss is : 0.0450205\n",
      "9488-th loss is : 0.046579\n",
      "9489-th loss is : 0.0263913\n",
      "9490-th loss is : 0.00829617\n",
      "9491-th loss is : 0.00402991\n",
      "9492-th loss is : 0.00372592\n",
      "9493-th loss is : 0.0182215\n",
      "9494-th loss is : 0.023531\n",
      "9495-th loss is : 0.0073075\n",
      "9496-th loss is : 0.00866008\n",
      "9497-th loss is : 0.000111025\n",
      "9498-th loss is : 0.0433529\n",
      "9499-th loss is : 0.032103\n",
      "9500-th loss is : 0.0218577\n",
      "9501-th loss is : 0.00267298\n",
      "9502-th loss is : 0.00186454\n",
      "9503-th loss is : 0.00431354\n",
      "9504-th loss is : 0.010811\n",
      "9505-th loss is : 0.0556282\n",
      "9506-th loss is : 0.002194\n",
      "9507-th loss is : 0.000147838\n",
      "9508-th loss is : 0.011264\n",
      "9509-th loss is : 0.0162918\n",
      "9510-th loss is : 0.0905018\n",
      "9511-th loss is : 0.0360465\n",
      "9512-th loss is : 0.000470713\n",
      "9513-th loss is : 0.0694576\n",
      "9514-th loss is : 0.00293513\n",
      "9515-th loss is : 0.000433796\n",
      "9516-th loss is : 0.0220092\n",
      "9517-th loss is : 0.00320265\n",
      "9518-th loss is : 0.0024683\n",
      "9519-th loss is : 0.000834778\n",
      "9520-th loss is : 0.0442756\n",
      "9521-th loss is : 0.0511935\n",
      "9522-th loss is : 0.0178685\n",
      "9523-th loss is : 0.035072\n",
      "9524-th loss is : 8.73278e-05\n",
      "9525-th loss is : 0.000262425\n",
      "9526-th loss is : 0.0175099\n",
      "9527-th loss is : 0.0844393\n",
      "9528-th loss is : 0.00204674\n",
      "9529-th loss is : 0.0407085\n",
      "9530-th loss is : 0.0607618\n",
      "9531-th loss is : 4.4972e-05\n",
      "9532-th loss is : 0.00125673\n",
      "9533-th loss is : 0.00318119\n",
      "9534-th loss is : 0.000177225\n",
      "9535-th loss is : 3.26137e-05\n",
      "9536-th loss is : 0.091161\n",
      "9537-th loss is : 0.0307415\n",
      "9538-th loss is : 0.00043001\n",
      "9539-th loss is : 0.0891662\n",
      "9540-th loss is : 0.000356743\n",
      "9541-th loss is : 8.56562e-06\n",
      "9542-th loss is : 0.000700071\n",
      "9543-th loss is : 0.000525658\n",
      "9544-th loss is : 0.00399668\n",
      "9545-th loss is : 0.000909597\n",
      "9546-th loss is : 0.00081588\n",
      "9547-th loss is : 0.0062909\n",
      "9548-th loss is : 0.00315756\n",
      "9549-th loss is : 0.0043386\n",
      "9550-th loss is : 0.0692658\n",
      "9551-th loss is : 0.0202589\n",
      "9552-th loss is : 0.00026919\n",
      "9553-th loss is : 0.0780376\n",
      "9554-th loss is : 0.025015\n",
      "9555-th loss is : 0.00122323\n",
      "9556-th loss is : 3.4799e-05\n",
      "9557-th loss is : 0.0011693\n",
      "9558-th loss is : 0.013441\n",
      "9559-th loss is : 0.0795376\n",
      "9560-th loss is : 0.0132919\n",
      "9561-th loss is : 0.00169355\n",
      "9562-th loss is : 0.0185112\n",
      "9563-th loss is : 0.00352646\n",
      "9564-th loss is : 0.0268237\n",
      "9565-th loss is : 0.00549387\n",
      "9566-th loss is : 0.0580625\n",
      "9567-th loss is : 0.000943022\n",
      "9568-th loss is : 0.00078708\n",
      "9569-th loss is : 0.091642\n",
      "9570-th loss is : 0.0816157\n",
      "9571-th loss is : 0.00156077\n",
      "9572-th loss is : 0.00343145\n",
      "9573-th loss is : 0.0677945\n",
      "9574-th loss is : 0.0032393\n",
      "9575-th loss is : 0.0810075\n",
      "9576-th loss is : 0.0580544\n",
      "9577-th loss is : 0.0726428\n",
      "9578-th loss is : 0.052459\n",
      "9579-th loss is : 0.0513962\n",
      "9580-th loss is : 0.0741552\n",
      "9581-th loss is : 0.000210939\n",
      "9582-th loss is : 0.0588757\n",
      "9583-th loss is : 0.0016572\n",
      "9584-th loss is : 0.0150687\n",
      "9585-th loss is : 0.0849362\n",
      "9586-th loss is : 0.00237061\n",
      "9587-th loss is : 0.00247388\n",
      "9588-th loss is : 0.0167529\n",
      "9589-th loss is : 0.00159124\n",
      "9590-th loss is : 0.0630569\n",
      "9591-th loss is : 0.00814782\n",
      "9592-th loss is : 0.0227562\n",
      "9593-th loss is : 0.00514532\n",
      "9594-th loss is : 0.0473339\n",
      "9595-th loss is : 0.0107022\n",
      "9596-th loss is : 0.00424277\n",
      "9597-th loss is : 0.00257492\n",
      "9598-th loss is : 0.00215396\n",
      "9599-th loss is : 0.0112784\n",
      "9600-th loss is : 0.00250795\n",
      "9601-th loss is : 0.0447745\n",
      "9602-th loss is : 0.00145692\n",
      "9603-th loss is : 0.00284208\n",
      "9604-th loss is : 0.00108848\n",
      "9605-th loss is : 0.025153\n",
      "9606-th loss is : 0.0127111\n",
      "9607-th loss is : 0.00164126\n",
      "9608-th loss is : 0.0384939\n",
      "9609-th loss is : 0.0479838\n",
      "9610-th loss is : 0.023007\n",
      "9611-th loss is : 0.0175732\n",
      "9612-th loss is : 0.0582841\n",
      "9613-th loss is : 0.0014207\n",
      "9614-th loss is : 0.00277703\n",
      "9615-th loss is : 0.00872565\n",
      "9616-th loss is : 0.0334047\n",
      "9617-th loss is : 0.0741226\n",
      "9618-th loss is : 0.0846139\n",
      "9619-th loss is : 1.54082e-05\n",
      "9620-th loss is : 0.0514937\n",
      "9621-th loss is : 7.51168e-05\n",
      "9622-th loss is : 0.0361065\n",
      "9623-th loss is : 0.000697789\n",
      "9624-th loss is : 0.0632551\n",
      "9625-th loss is : 0.00429231\n",
      "9626-th loss is : 0.007229\n",
      "9627-th loss is : 0.0239047\n",
      "9628-th loss is : 0.00380158\n",
      "9629-th loss is : 0.0296646\n",
      "9630-th loss is : 0.00112913\n",
      "9631-th loss is : 0.0857755\n",
      "9632-th loss is : 0.0514781\n",
      "9633-th loss is : 0.00447214\n",
      "9634-th loss is : 0.00221291\n",
      "9635-th loss is : 0.0301404\n",
      "9636-th loss is : 0.00348306\n",
      "9637-th loss is : 0.0539425\n",
      "9638-th loss is : 0.0872882\n",
      "9639-th loss is : 0.0041138\n",
      "9640-th loss is : 0.0260556\n",
      "9641-th loss is : 0.00428567\n",
      "9642-th loss is : 0.0740959\n",
      "9643-th loss is : 0.00252792\n",
      "9644-th loss is : 0.0479581\n",
      "9645-th loss is : 0.0438156\n",
      "9646-th loss is : 0.00444909\n",
      "9647-th loss is : 0.0739184\n",
      "9648-th loss is : 0.014935\n",
      "9649-th loss is : 0.019539\n",
      "9650-th loss is : 0.0353169\n",
      "9651-th loss is : 0.0518208\n",
      "9652-th loss is : 0.0702434\n",
      "9653-th loss is : 0.000278461\n",
      "9654-th loss is : 0.0629374\n",
      "9655-th loss is : 0.0416376\n",
      "9656-th loss is : 5.16223e-05\n",
      "9657-th loss is : 0.00134989\n",
      "9658-th loss is : 0.0582447\n",
      "9659-th loss is : 0.00734842\n",
      "9660-th loss is : 0.0371244\n",
      "9661-th loss is : 0.0110997\n",
      "9662-th loss is : 0.00654775\n",
      "9663-th loss is : 0.0118423\n",
      "9664-th loss is : 0.00676665\n",
      "9665-th loss is : 0.0740562\n",
      "9666-th loss is : 0.00434076\n",
      "9667-th loss is : 0.0585941\n",
      "9668-th loss is : 0.0101496\n",
      "9669-th loss is : 0.0441114\n",
      "9670-th loss is : 1.67294e-06\n",
      "9671-th loss is : 0.0121414\n",
      "9672-th loss is : 0.00770189\n",
      "9673-th loss is : 0.0231003\n",
      "9674-th loss is : 6.2297e-05\n",
      "9675-th loss is : 0.0392701\n",
      "9676-th loss is : 0.00171941\n",
      "9677-th loss is : 0.00768937\n",
      "9678-th loss is : 0.019016\n",
      "9679-th loss is : 0.064653\n",
      "9680-th loss is : 0.045025\n",
      "9681-th loss is : 0.000167479\n",
      "9682-th loss is : 0.0341921\n",
      "9683-th loss is : 6.35766e-05\n",
      "9684-th loss is : 0.0489313\n",
      "9685-th loss is : 0.00440976\n",
      "9686-th loss is : 0.00360629\n",
      "9687-th loss is : 0.0137897\n",
      "9688-th loss is : 0.0162661\n",
      "9689-th loss is : 0.042788\n",
      "9690-th loss is : 0.0615145\n",
      "9691-th loss is : 0.000186061\n",
      "9692-th loss is : 0.0217591\n",
      "9693-th loss is : 0.000883346\n",
      "9694-th loss is : 0.00165815\n",
      "9695-th loss is : 0.0028593\n",
      "9696-th loss is : 0.0486107\n",
      "9697-th loss is : 0.0700582\n",
      "9698-th loss is : 0.00417972\n",
      "9699-th loss is : 0.00100921\n",
      "9700-th loss is : 4.29081e-05\n",
      "9701-th loss is : 0.00667142\n",
      "9702-th loss is : 0.017563\n",
      "9703-th loss is : 0.00114937\n",
      "9704-th loss is : 0.0156127\n",
      "9705-th loss is : 0.0821107\n",
      "9706-th loss is : 0.0377066\n",
      "9707-th loss is : 0.00251421\n",
      "9708-th loss is : 1.86266e-05\n",
      "9709-th loss is : 0.0148921\n",
      "9710-th loss is : 0.0112771\n",
      "9711-th loss is : 6.47655e-05\n",
      "9712-th loss is : 0.00120946\n",
      "9713-th loss is : 0.0696407\n",
      "9714-th loss is : 0.00736813\n",
      "9715-th loss is : 0.0875215\n",
      "9716-th loss is : 0.00170076\n",
      "9717-th loss is : 0.0666662\n",
      "9718-th loss is : 0.081969\n",
      "9719-th loss is : 6.57497e-07\n",
      "9720-th loss is : 0.0197258\n",
      "9721-th loss is : 0.0367087\n",
      "9722-th loss is : 0.00446412\n",
      "9723-th loss is : 0.0316649\n",
      "9724-th loss is : 0.0786957\n",
      "9725-th loss is : 0.0110446\n",
      "9726-th loss is : 0.0277073\n",
      "9727-th loss is : 0.0457863\n",
      "9728-th loss is : 0.00043321\n",
      "9729-th loss is : 0.0365566\n",
      "9730-th loss is : 0.000241018\n",
      "9731-th loss is : 0.00974259\n",
      "9732-th loss is : 0.0123485\n",
      "9733-th loss is : 0.0335792\n",
      "9734-th loss is : 0.030647\n",
      "9735-th loss is : 0.00495307\n",
      "9736-th loss is : 0.0355765\n",
      "9737-th loss is : 0.0260302\n",
      "9738-th loss is : 0.00529618\n",
      "9739-th loss is : 0.0618864\n",
      "9740-th loss is : 0.0563202\n",
      "9741-th loss is : 0.010379\n",
      "9742-th loss is : 0.0359755\n",
      "9743-th loss is : 7.18227e-05\n",
      "9744-th loss is : 0.00517315\n",
      "9745-th loss is : 0.00509968\n",
      "9746-th loss is : 0.000621261\n",
      "9747-th loss is : 0.030627\n",
      "9748-th loss is : 0.0027669\n",
      "9749-th loss is : 0.0111917\n",
      "9750-th loss is : 0.00117237\n",
      "9751-th loss is : 0.0676721\n",
      "9752-th loss is : 0.00228843\n",
      "9753-th loss is : 0.0701009\n",
      "9754-th loss is : 0.00883869\n",
      "9755-th loss is : 0.000182085\n",
      "9756-th loss is : 5.38434e-05\n",
      "9757-th loss is : 0.0634644\n",
      "9758-th loss is : 0.0207682\n",
      "9759-th loss is : 0.00450003\n",
      "9760-th loss is : 0.000343951\n",
      "9761-th loss is : 0.000450219\n",
      "9762-th loss is : 0.055506\n",
      "9763-th loss is : 0.000101691\n",
      "9764-th loss is : 0.00125587\n",
      "9765-th loss is : 0.00505908\n",
      "9766-th loss is : 0.0266793\n",
      "9767-th loss is : 0.0593087\n",
      "9768-th loss is : 0.00752243\n",
      "9769-th loss is : 0.0036152\n",
      "9770-th loss is : 1.60311e-05\n",
      "9771-th loss is : 0.00108526\n",
      "9772-th loss is : 0.0015672\n",
      "9773-th loss is : 0.0378177\n",
      "9774-th loss is : 0.000256463\n",
      "9775-th loss is : 0.0227771\n",
      "9776-th loss is : 0.0539202\n",
      "9777-th loss is : 0.0547674\n",
      "9778-th loss is : 0.0700243\n",
      "9779-th loss is : 0.00102592\n",
      "9780-th loss is : 0.0291342\n",
      "9781-th loss is : 0.00114514\n",
      "9782-th loss is : 0.00711295\n",
      "9783-th loss is : 0.0651838\n",
      "9784-th loss is : 0.0582308\n",
      "9785-th loss is : 0.0280583\n",
      "9786-th loss is : 0.00749828\n",
      "9787-th loss is : 0.0200969\n",
      "9788-th loss is : 0.00765061\n",
      "9789-th loss is : 0.00141442\n",
      "9790-th loss is : 0.0313062\n",
      "9791-th loss is : 0.000203285\n",
      "9792-th loss is : 0.0112519\n",
      "9793-th loss is : 0.0103193\n",
      "9794-th loss is : 0.00926228\n",
      "9795-th loss is : 0.0251227\n",
      "9796-th loss is : 0.00473892\n",
      "9797-th loss is : 0.0625119\n",
      "9798-th loss is : 0.00381216\n",
      "9799-th loss is : 0.00123838\n",
      "9800-th loss is : 0.000406753\n",
      "9801-th loss is : 0.00777137\n",
      "9802-th loss is : 0.000595744\n",
      "9803-th loss is : 0.0356817\n",
      "9804-th loss is : 0.0581626\n",
      "9805-th loss is : 0.00941129\n",
      "9806-th loss is : 0.00716041\n",
      "9807-th loss is : 0.00309669\n",
      "9808-th loss is : 0.0162309\n",
      "9809-th loss is : 6.79386e-05\n",
      "9810-th loss is : 0.0540871\n",
      "9811-th loss is : 0.039585\n",
      "9812-th loss is : 0.00390264\n",
      "9813-th loss is : 0.0190412\n",
      "9814-th loss is : 0.00297715\n",
      "9815-th loss is : 0.0318884\n",
      "9816-th loss is : 0.0607368\n",
      "9817-th loss is : 0.0349412\n",
      "9818-th loss is : 0.0564655\n",
      "9819-th loss is : 0.000700784\n",
      "9820-th loss is : 0.0371975\n",
      "9821-th loss is : 0.0842553\n",
      "9822-th loss is : 0.0124829\n",
      "9823-th loss is : 0.0366984\n",
      "9824-th loss is : 1.68158e-06\n",
      "9825-th loss is : 0.000330418\n",
      "9826-th loss is : 0.0766531\n",
      "9827-th loss is : 0.00180692\n",
      "9828-th loss is : 0.00386507\n",
      "9829-th loss is : 0.00889849\n",
      "9830-th loss is : 0.000448781\n",
      "9831-th loss is : 0.0170805\n",
      "9832-th loss is : 0.0226219\n",
      "9833-th loss is : 0.00378564\n",
      "9834-th loss is : 0.000817488\n",
      "9835-th loss is : 0.00233448\n",
      "9836-th loss is : 0.016346\n",
      "9837-th loss is : 0.00327153\n",
      "9838-th loss is : 0.0241883\n",
      "9839-th loss is : 0.00227519\n",
      "9840-th loss is : 0.00227033\n",
      "9841-th loss is : 0.0414422\n",
      "9842-th loss is : 0.0727732\n",
      "9843-th loss is : 0.0756095\n",
      "9844-th loss is : 0.000770262\n",
      "9845-th loss is : 0.0585246\n",
      "9846-th loss is : 0.00465086\n",
      "9847-th loss is : 0.0558406\n",
      "9848-th loss is : 0.0675061\n",
      "9849-th loss is : 0.00155923\n",
      "9850-th loss is : 0.0068787\n",
      "9851-th loss is : 0.014541\n",
      "9852-th loss is : 0.0127308\n",
      "9853-th loss is : 0.010578\n",
      "9854-th loss is : 0.0683723\n",
      "9855-th loss is : 0.00367831\n",
      "9856-th loss is : 0.000487027\n",
      "9857-th loss is : 0.000898493\n",
      "9858-th loss is : 0.000959453\n",
      "9859-th loss is : 0.00864555\n",
      "9860-th loss is : 0.0409437\n",
      "9861-th loss is : 0.00523441\n",
      "9862-th loss is : 0.0351056\n",
      "9863-th loss is : 0.00282239\n",
      "9864-th loss is : 0.000993162\n",
      "9865-th loss is : 0.000508061\n",
      "9866-th loss is : 0.013915\n",
      "9867-th loss is : 0.0516409\n",
      "9868-th loss is : 0.0345315\n",
      "9869-th loss is : 0.000365309\n",
      "9870-th loss is : 0.0068735\n",
      "9871-th loss is : 0.0686222\n",
      "9872-th loss is : 0.0145157\n",
      "9873-th loss is : 8.91418e-05\n",
      "9874-th loss is : 0.000675004\n",
      "9875-th loss is : 0.0377205\n",
      "9876-th loss is : 0.00762737\n",
      "9877-th loss is : 0.038827\n",
      "9878-th loss is : 0.0266043\n",
      "9879-th loss is : 0.0848009\n",
      "9880-th loss is : 0.0295784\n",
      "9881-th loss is : 0.0017586\n",
      "9882-th loss is : 0.0178486\n",
      "9883-th loss is : 0.00384689\n",
      "9884-th loss is : 0.000290114\n",
      "9885-th loss is : 0.0477301\n",
      "9886-th loss is : 0.0444577\n",
      "9887-th loss is : 0.0230096\n",
      "9888-th loss is : 0.0276893\n",
      "9889-th loss is : 0.00684886\n",
      "9890-th loss is : 0.0297856\n",
      "9891-th loss is : 0.0727165\n",
      "9892-th loss is : 0.00202173\n",
      "9893-th loss is : 0.0430833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9894-th loss is : 0.0421647\n",
      "9895-th loss is : 0.00719484\n",
      "9896-th loss is : 0.035105\n",
      "9897-th loss is : 0.0316495\n",
      "9898-th loss is : 0.000645756\n",
      "9899-th loss is : 0.0084719\n",
      "9900-th loss is : 0.00999512\n",
      "9901-th loss is : 0.0430646\n",
      "9902-th loss is : 0.0259114\n",
      "9903-th loss is : 0.000958785\n",
      "9904-th loss is : 0.00137932\n",
      "9905-th loss is : 0.0368812\n",
      "9906-th loss is : 0.00256151\n",
      "9907-th loss is : 0.00231298\n",
      "9908-th loss is : 0.00292625\n",
      "9909-th loss is : 0.00121674\n",
      "9910-th loss is : 0.0464969\n",
      "9911-th loss is : 0.000186103\n",
      "9912-th loss is : 0.00446903\n",
      "9913-th loss is : 0.00966693\n",
      "9914-th loss is : 0.000410486\n",
      "9915-th loss is : 0.0666035\n",
      "9916-th loss is : 4.70617e-06\n",
      "9917-th loss is : 0.000644678\n",
      "9918-th loss is : 0.0220945\n",
      "9919-th loss is : 0.00240183\n",
      "9920-th loss is : 0.0401899\n",
      "9921-th loss is : 0.0422958\n",
      "9922-th loss is : 7.90013e-06\n",
      "9923-th loss is : 0.0318237\n",
      "9924-th loss is : 0.00513166\n",
      "9925-th loss is : 0.0463536\n",
      "9926-th loss is : 0.00331318\n",
      "9927-th loss is : 0.0509599\n",
      "9928-th loss is : 0.00306009\n",
      "9929-th loss is : 0.000279086\n",
      "9930-th loss is : 0.0196693\n",
      "9931-th loss is : 0.00155183\n",
      "9932-th loss is : 0.00122253\n",
      "9933-th loss is : 0.000108161\n",
      "9934-th loss is : 1.42706e-06\n",
      "9935-th loss is : 0.00847784\n",
      "9936-th loss is : 0.000139452\n",
      "9937-th loss is : 0.00155904\n",
      "9938-th loss is : 0.0109157\n",
      "9939-th loss is : 0.000345516\n",
      "9940-th loss is : 0.0169487\n",
      "9941-th loss is : 4.53518e-05\n",
      "9942-th loss is : 0.0276693\n",
      "9943-th loss is : 0.0613187\n",
      "9944-th loss is : 0.00356885\n",
      "9945-th loss is : 0.0564593\n",
      "9946-th loss is : 0.00173189\n",
      "9947-th loss is : 0.0170656\n",
      "9948-th loss is : 0.076547\n",
      "9949-th loss is : 0.0101472\n",
      "9950-th loss is : 0.0627961\n",
      "9951-th loss is : 0.000317026\n",
      "9952-th loss is : 0.0745267\n",
      "9953-th loss is : 0.00731482\n",
      "9954-th loss is : 0.00240474\n",
      "9955-th loss is : 0.0692025\n",
      "9956-th loss is : 0.000906418\n",
      "9957-th loss is : 0.0442447\n",
      "9958-th loss is : 0.0491629\n",
      "9959-th loss is : 0.0245756\n",
      "9960-th loss is : 0.00458689\n",
      "9961-th loss is : 0.0246342\n",
      "9962-th loss is : 0.0360926\n",
      "9963-th loss is : 0.0770198\n",
      "9964-th loss is : 0.062858\n",
      "9965-th loss is : 0.00136212\n",
      "9966-th loss is : 0.0219306\n",
      "9967-th loss is : 0.0103704\n",
      "9968-th loss is : 1.72109e-05\n",
      "9969-th loss is : 0.00288145\n",
      "9970-th loss is : 0.00480493\n",
      "9971-th loss is : 0.00618059\n",
      "9972-th loss is : 0.0819255\n",
      "9973-th loss is : 0.00598773\n",
      "9974-th loss is : 0.0244862\n",
      "9975-th loss is : 0.0832753\n",
      "9976-th loss is : 0.0356379\n",
      "9977-th loss is : 0.0327441\n",
      "9978-th loss is : 0.0200584\n",
      "9979-th loss is : 0.00966919\n",
      "9980-th loss is : 0.0583\n",
      "9981-th loss is : 0.00605484\n",
      "9982-th loss is : 0.00312427\n",
      "9983-th loss is : 0.0337724\n",
      "9984-th loss is : 0.00859944\n",
      "9985-th loss is : 0.0448138\n",
      "9986-th loss is : 0.0178202\n",
      "9987-th loss is : 0.000495779\n",
      "9988-th loss is : 0.000717163\n",
      "9989-th loss is : 0.005465\n",
      "9990-th loss is : 0.0120799\n",
      "9991-th loss is : 3.76074e-05\n",
      "9992-th loss is : 0.0430099\n",
      "9993-th loss is : 0.0374475\n",
      "9994-th loss is : 0.0407915\n",
      "9995-th loss is : 0.0134549\n",
      "9996-th loss is : 0.0300323\n",
      "9997-th loss is : 0.0185692\n",
      "9998-th loss is : 0.0371152\n",
      "9999-th loss is : 3.97657e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# parameters: define variable and initialize\n",
    "w = tf.get_variable(\"w\",[],initializer= tf.constant_initializer(0.))\n",
    "b = tf.get_variable(\"b\",[],initializer= tf.constant_initializer(0.))\n",
    "init = tf.global_variables_initializer()\n",
    "#set up computations\n",
    "input_placeholder = tf.placeholder(tf.float32)\n",
    "output_placeholder = tf.placeholder(tf.float32)\n",
    "\n",
    "x = input_placeholder\n",
    "y = output_placeholder\n",
    "y_predict = w * x + b\n",
    "\n",
    "loss = tf.square(y - y_predict)\n",
    "# use GD  for iteration \n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-4)\n",
    "train_operation = optimizer.minimize(loss)\n",
    "# constructure session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "true_w = np.random.random()\n",
    "true_b = np.random.random()\n",
    "\n",
    "for i in range(10000):\n",
    "    input_data = np.random.random()\n",
    "    output_data = true_w * input_data + true_b\n",
    "    _loss,_ = sess.run([loss,train_operation],feed_dict = {input_placeholder:input_data,\n",
    "                                                      output_placeholder:output_data})\n",
    "    print(str(i) + \"-th loss is :\",_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以看出最后的`loss`已经非常小了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调试  \n",
    " * 我基本上都是使用`print()`方法调试，当出现错误，像`feed_dict()`有时会出现`key`和`values`不匹配，我都是使用`print()`打印跟踪，看看在哪一步  \n",
    " 出现的数据与预想的数据不一样，然后去调试所在函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
